{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardrails for HR Agent Systems\n",
        "\n",
        "**Building Secure and Compliant AI Agents with LangChain 1.0**\n",
        "\n",
        "**What you'll learn:**\n",
        "- üõ°Ô∏è PII Detection and Protection\n",
        "- ‚úÖ Input Validation Guardrails\n",
        "- üîç Output Validation Guardrails\n",
        "- üë§ Human-in-the-Loop for Sensitive Operations\n",
        "- üö¶ Rate Limiting and Throttling\n",
        "- üìã Custom Business Rule Enforcement\n",
        "- üîÑ Combining Multiple Guardrails\n",
        "\n",
        "**Real HR Use Cases:**\n",
        "- Prevent salary information leakage\n",
        "- Redact personal identifiable information (PII)\n",
        "- Require approval for sensitive operations\n",
        "- Block inappropriate requests\n",
        "- Enforce compliance requirements\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install LangChain 1.0 and required packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph langchain-community\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Configure API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "print(\"‚úÖ API Key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "print(\"‚úÖ Imports loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Understanding Guardrails üõ°Ô∏è\n",
        "\n",
        "## What are Guardrails?\n",
        "\n",
        "Guardrails are safety mechanisms that control agent behavior:\n",
        "\n",
        "```\n",
        "Without Guardrails:\n",
        "User: \"What's Priya's salary?\"\n",
        "Agent: \"Priya earns ‚Çπ15,00,000 per year\"  ‚ùå Data leak!\n",
        "\n",
        "With Guardrails:\n",
        "User: \"What's Priya's salary?\"\n",
        "Agent: \"I cannot share salary information.\"  ‚úÖ Protected!\n",
        "```\n",
        "\n",
        "## Types of Guardrails\n",
        "\n",
        "1. **Input Guardrails** - Validate before execution\n",
        "2. **Output Guardrails** - Validate after execution\n",
        "3. **PII Detection** - Protect sensitive data\n",
        "4. **Human-in-the-Loop** - Require approval\n",
        "5. **Rate Limiting** - Prevent abuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: HR Tools Setup\n",
        "\n",
        "Let's create HR tools with sensitive data that needs protection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HR Database (simulated)\n",
        "HR_DATABASE = {\n",
        "    \"101\": {\n",
        "        \"name\": \"Priya Sharma\",\n",
        "        \"department\": \"Engineering\",\n",
        "        \"position\": \"Senior Developer\",\n",
        "        \"email\": \"priya.sharma@company.com\",\n",
        "        \"phone\": \"+91-9876543210\",\n",
        "        \"salary\": \"‚Çπ15,00,000\",\n",
        "        \"aadhar\": \"1234-5678-9012\",\n",
        "        \"leave_balance\": 12\n",
        "    },\n",
        "    \"102\": {\n",
        "        \"name\": \"Rahul Verma\",\n",
        "        \"department\": \"Engineering\",\n",
        "        \"position\": \"Manager\",\n",
        "        \"email\": \"rahul.verma@company.com\",\n",
        "        \"phone\": \"+91-9876543211\",\n",
        "        \"salary\": \"‚Çπ22,00,000\",\n",
        "        \"aadhar\": \"2345-6789-0123\",\n",
        "        \"leave_balance\": 8\n",
        "    },\n",
        "    \"103\": {\n",
        "        \"name\": \"Anjali Patel\",\n",
        "        \"department\": \"HR\",\n",
        "        \"position\": \"Director\",\n",
        "        \"email\": \"anjali.patel@company.com\",\n",
        "        \"phone\": \"+91-9876543212\",\n",
        "        \"salary\": \"‚Çπ28,00,000\",\n",
        "        \"aadhar\": \"3456-7890-1234\",\n",
        "        \"leave_balance\": 15\n",
        "    },\n",
        "    \"104\": {\n",
        "        \"name\": \"Arjun Reddy\",\n",
        "        \"department\": \"Sales\",\n",
        "        \"position\": \"Team Lead\",\n",
        "        \"email\": \"arjun.reddy@company.com\",\n",
        "        \"phone\": \"+91-9876543213\",\n",
        "        \"salary\": \"‚Çπ18,00,000\",\n",
        "        \"aadhar\": \"4567-8901-2345\",\n",
        "        \"leave_balance\": 10\n",
        "    },\n",
        "    \"105\": {\n",
        "        \"name\": \"Sneha Gupta\",\n",
        "        \"department\": \"Marketing\",\n",
        "        \"position\": \"Specialist\",\n",
        "        \"email\": \"sneha.gupta@company.com\",\n",
        "        \"phone\": \"+91-9876543214\",\n",
        "        \"salary\": \"‚Çπ12,00,000\",\n",
        "        \"aadhar\": \"5678-9012-3456\",\n",
        "        \"leave_balance\": 5\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úÖ HR Database loaded with 5 employees!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic HR Tools (WITHOUT guardrails)\n",
        "\n",
        "@tool\n",
        "def get_employee_info(employee_id: Annotated[str, \"Employee ID to look up\"]) -> str:\n",
        "    \"\"\"Get basic employee information.\"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    return f\"\"\"\n",
        "Name: {emp['name']}\n",
        "Department: {emp['department']}\n",
        "Position: {emp['position']}\n",
        "Email: {emp['email']}\n",
        "Phone: {emp['phone']}\n",
        "\"\"\"\n",
        "\n",
        "@tool\n",
        "def get_salary_info(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Get employee salary information. ‚ö†Ô∏è SENSITIVE DATA!\"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    return f\"{emp['name']}'s annual salary: {emp['salary']}\"\n",
        "\n",
        "@tool\n",
        "def update_salary(\n",
        "    employee_id: Annotated[str, \"Employee ID\"],\n",
        "    new_salary: Annotated[str, \"New salary amount\"]\n",
        ") -> str:\n",
        "    \"\"\"Update employee salary. ‚ö†Ô∏è SENSITIVE OPERATION!\"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    old_salary = HR_DATABASE[employee_id]['salary']\n",
        "    HR_DATABASE[employee_id]['salary'] = new_salary\n",
        "    return f\"Salary updated for {HR_DATABASE[employee_id]['name']}: {old_salary} ‚Üí {new_salary}\"\n",
        "\n",
        "@tool\n",
        "def check_leave_balance(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Check leave balance for an employee.\"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    return f\"{emp['name']} has {emp['leave_balance']} days of leave remaining\"\n",
        "\n",
        "@tool\n",
        "def delete_employee(employee_id: Annotated[str, \"Employee ID to delete\"]) -> str:\n",
        "    \"\"\"Delete an employee from the system. ‚ö†Ô∏è CRITICAL OPERATION!\"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp_name = HR_DATABASE[employee_id]['name']\n",
        "    del HR_DATABASE[employee_id]\n",
        "    return f\"‚ùå Employee {emp_name} (ID: {employee_id}) has been deleted from the system\"\n",
        "\n",
        "print(\"‚úÖ HR Tools defined (without guardrails)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Agent Without Guardrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create agent WITHOUT guardrails\n",
        "unsafe_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, get_salary_info, check_leave_balance],\n",
        "    system_prompt=\"You are an HR assistant. Answer all questions about employees.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing UNSAFE Agent (No Guardrails)\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Test 1: PII exposure\n",
        "result = unsafe_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What's Priya's contact information?\"}]\n",
        "})\n",
        "print(\"‚ùå PII Exposed:\")\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Test 2: Salary information leak\n",
        "result = unsafe_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"How much does employee 101 earn?\"}]\n",
        "})\n",
        "print(\"‚ùå Salary Info Leaked:\")\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Without guardrails, sensitive data is exposed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: PII Detection Guardrails üîí\n",
        "\n",
        "**Goal:** Automatically detect and redact Personally Identifiable Information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain.agents import AgentState\n",
        "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
        "from typing import Sequence\n",
        "\n",
        "# PII Detection Patterns\n",
        "PII_PATTERNS = {\n",
        "    \"email\": r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",\n",
        "    \"phone_india\": r\"\\+91-\\d{10}|\\d{10}\",\n",
        "    \"aadhar\": r\"\\d{4}-\\d{4}-\\d{4}\",\n",
        "    \"pan\": r\"[A-Z]{5}\\d{4}[A-Z]\",\n",
        "    \"salary\": r\"‚Çπ[\\d,]+\"\n",
        "}\n",
        "\n",
        "def detect_and_redact_pii(text: str, strategy: str = \"redact\") -> tuple[str, list[str]]:\n",
        "    \"\"\"\n",
        "    Detect and redact PII from text.\n",
        "    \n",
        "    Args:\n",
        "        text: Text to scan for PII\n",
        "        strategy: \"redact\", \"mask\", or \"hash\"\n",
        "    \n",
        "    Returns:\n",
        "        (redacted_text, list of detected PII types)\n",
        "    \"\"\"\n",
        "    redacted_text = text\n",
        "    detected_types = []\n",
        "    \n",
        "    for pii_type, pattern in PII_PATTERNS.items():\n",
        "        matches = re.findall(pattern, text)\n",
        "        if matches:\n",
        "            detected_types.append(pii_type)\n",
        "            for match in matches:\n",
        "                if strategy == \"redact\":\n",
        "                    replacement = f\"[REDACTED_{pii_type.upper()}]\"\n",
        "                elif strategy == \"mask\":\n",
        "                    replacement = match[:2] + \"*\" * (len(match) - 4) + match[-2:]\n",
        "                else:  # hash\n",
        "                    import hashlib\n",
        "                    replacement = hashlib.md5(match.encode()).hexdigest()[:8]\n",
        "                \n",
        "                redacted_text = redacted_text.replace(match, replacement)\n",
        "    \n",
        "    return redacted_text, detected_types\n",
        "\n",
        "# Test PII detection\n",
        "test_text = \"\"\"\n",
        "Priya Sharma\n",
        "Email: priya.sharma@company.com\n",
        "Phone: +91-9876543210\n",
        "Aadhar: 1234-5678-9012\n",
        "Salary: ‚Çπ15,00,000\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(test_text)\n",
        "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "redacted, detected = detect_and_redact_pii(test_text, strategy=\"redact\")\n",
        "print(\"Redacted Text:\")\n",
        "print(redacted)\n",
        "print(f\"\\nDetected PII Types: {', '.join(detected)}\")\n",
        "print(\"\\n‚úÖ PII detection working!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implement PII Guardrail for Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pii_output_guardrail(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Post-model hook to redact PII from agent responses.\n",
        "    Runs AFTER the agent generates a response.\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return {}\n",
        "    \n",
        "    # Get the last message (agent's response)\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    if isinstance(last_message, AIMessage) and last_message.content:\n",
        "        # Redact PII from the response\n",
        "        redacted_content, detected_pii = detect_and_redact_pii(\n",
        "            last_message.content,\n",
        "            strategy=\"redact\"\n",
        "        )\n",
        "        \n",
        "        if detected_pii:\n",
        "            print(f\"‚ö†Ô∏è PII Detected and Redacted: {', '.join(detected_pii)}\")\n",
        "            # Create new message with redacted content\n",
        "            new_message = AIMessage(\n",
        "                content=redacted_content,\n",
        "                id=last_message.id\n",
        "            )\n",
        "            # Replace the last message\n",
        "            return {\"messages\": messages[:-1] + [new_message]}\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"‚úÖ PII guardrail function created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Agent With PII Guardrail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create agent WITH PII guardrail\n",
        "pii_protected_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance],\n",
        "    post_model_hook=pii_output_guardrail,  # Add PII protection!\n",
        "    system_prompt=\"You are an HR assistant. Provide employee information when requested.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Agent WITH PII Guardrail\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "result = pii_protected_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What's Priya's contact information?\"}]\n",
        "})\n",
        "\n",
        "print(\"‚úÖ PII Protected Response:\")\n",
        "print(result['messages'][-1].content)\n",
        "print(\"\\n‚úÖ Sensitive data automatically redacted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: Input Validation Guardrails ‚úÖ\n",
        "\n",
        "**Goal:** Block inappropriate or malicious requests BEFORE agent execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.exceptions import AgentException\n",
        "\n",
        "# Define blocked keywords and patterns\n",
        "BLOCKED_KEYWORDS = [\n",
        "    \"hack\", \"exploit\", \"bypass\", \"steal\",\n",
        "    \"delete all\", \"drop table\", \"sql injection\"\n",
        "]\n",
        "\n",
        "SENSITIVE_TOPICS = [\n",
        "    \"salary\", \"compensation\", \"pay\", \"wage\",\n",
        "    \"fire\", \"terminate\", \"layoff\"\n",
        "]\n",
        "\n",
        "def input_validation_guardrail(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Pre-model hook to validate user input.\n",
        "    Runs BEFORE the agent processes the request.\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return {}\n",
        "    \n",
        "    # Get the last user message\n",
        "    user_message = None\n",
        "    for msg in reversed(messages):\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            user_message = msg\n",
        "            break\n",
        "    \n",
        "    if not user_message or not user_message.content:\n",
        "        return {}\n",
        "    \n",
        "    content_lower = user_message.content.lower()\n",
        "    \n",
        "    # Check for blocked keywords\n",
        "    for keyword in BLOCKED_KEYWORDS:\n",
        "        if keyword in content_lower:\n",
        "            raise AgentException(\n",
        "                f\"‚ùå Request blocked: Contains prohibited keyword '{keyword}'\"\n",
        "            )\n",
        "    \n",
        "    # Check for sensitive topics (log warning)\n",
        "    for topic in SENSITIVE_TOPICS:\n",
        "        if topic in content_lower:\n",
        "            print(f\"‚ö†Ô∏è Warning: Request contains sensitive topic '{topic}'\")\n",
        "    \n",
        "    # Check message length\n",
        "    if len(content_lower) > 500:\n",
        "        raise AgentException(\n",
        "            \"‚ùå Request blocked: Message too long (max 500 characters)\"\n",
        "        )\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"‚úÖ Input validation guardrail created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Input Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create agent with input validation\n",
        "validated_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance],\n",
        "    pre_model_hook=input_validation_guardrail,  # Validate before execution!\n",
        "    system_prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Test 1: Normal Request (Should Work)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    result = validated_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "    })\n",
        "    print(\"‚úÖ Request allowed\")\n",
        "    print(result['messages'][-1].content)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 2: Blocked Keyword (Should Fail)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    result = validated_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"How can I hack into the salary database?\"}]\n",
        "    })\n",
        "    print(result['messages'][-1].content)\n",
        "except Exception as e:\n",
        "    print(f\"‚úÖ {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 3: Sensitive Topic (Warning)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    result = validated_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"What is Priya's salary?\"}]\n",
        "    })\n",
        "    print(\"‚úÖ Request processed with warning\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Output Validation Guardrails üîç\n",
        "\n",
        "**Goal:** Ensure agent responses meet quality and safety standards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def output_validation_guardrail(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Post-model hook to validate agent output.\n",
        "    Ensures responses are appropriate and safe.\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return {}\n",
        "    \n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    if isinstance(last_message, AIMessage) and last_message.content:\n",
        "        content = last_message.content\n",
        "        \n",
        "        # Rule 1: No toxic language\n",
        "        toxic_words = [\"hate\", \"stupid\", \"idiot\", \"worst\"]\n",
        "        if any(word in content.lower() for word in toxic_words):\n",
        "            print(\"‚ö†Ô∏è Output blocked: Contains inappropriate language\")\n",
        "            return {\n",
        "                \"messages\": messages[:-1] + [\n",
        "                    AIMessage(content=\"I apologize, but I cannot provide that response. How else can I help you?\")\n",
        "                ]\n",
        "            }\n",
        "        \n",
        "        # Rule 2: Response length validation\n",
        "        if len(content) < 10:\n",
        "            print(\"‚ö†Ô∏è Output warning: Response too short\")\n",
        "        \n",
        "        # Rule 3: Must be helpful (basic check)\n",
        "        unhelpful_phrases = [\"i don't know\", \"i can't help\", \"no idea\"]\n",
        "        if any(phrase in content.lower() for phrase in unhelpful_phrases):\n",
        "            print(\"‚ö†Ô∏è Output warning: Response may not be helpful\")\n",
        "        \n",
        "        # Rule 4: Ensure professional tone\n",
        "        if content.isupper():\n",
        "            print(\"‚ö†Ô∏è Output modified: Converting from all caps\")\n",
        "            return {\n",
        "                \"messages\": messages[:-1] + [\n",
        "                    AIMessage(content=content.capitalize())\n",
        "                ]\n",
        "            }\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"‚úÖ Output validation guardrail created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 6: Human-in-the-Loop Guardrails üë§\n",
        "\n",
        "**Goal:** Require human approval for sensitive operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.tool_node import InjectedState\n",
        "\n",
        "# List of tools requiring human approval\n",
        "APPROVAL_REQUIRED_TOOLS = [\"update_salary\", \"delete_employee\"]\n",
        "\n",
        "def human_approval_required(tool_name: str) -> bool:\n",
        "    \"\"\"Check if a tool requires human approval.\"\"\"\n",
        "    return tool_name in APPROVAL_REQUIRED_TOOLS\n",
        "\n",
        "def request_human_approval(action: str, details: str) -> bool:\n",
        "    \"\"\"\n",
        "    Simulate human approval request.\n",
        "    In production, this would integrate with a real approval system.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üîî HUMAN APPROVAL REQUIRED\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Action: {action}\")\n",
        "    print(f\"Details: {details}\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Simulate approval (in production, wait for actual human input)\n",
        "    response = input(\"Approve this action? (yes/no): \").strip().lower()\n",
        "    \n",
        "    if response == \"yes\":\n",
        "        print(\"‚úÖ Action approved by human\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"‚ùå Action rejected by human\")\n",
        "        return False\n",
        "\n",
        "# Wrap sensitive tools with approval\n",
        "@tool\n",
        "def update_salary_with_approval(\n",
        "    employee_id: Annotated[str, \"Employee ID\"],\n",
        "    new_salary: Annotated[str, \"New salary amount\"]\n",
        ") -> str:\n",
        "    \"\"\"Update employee salary with human approval.\"\"\"\n",
        "    \n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    details = f\"Update {emp['name']}'s salary from {emp['salary']} to {new_salary}\"\n",
        "    \n",
        "    # Request approval\n",
        "    approved = request_human_approval(\"Salary Update\", details)\n",
        "    \n",
        "    if not approved:\n",
        "        return \"‚ùå Salary update cancelled - approval denied\"\n",
        "    \n",
        "    # Proceed with update\n",
        "    old_salary = emp['salary']\n",
        "    HR_DATABASE[employee_id]['salary'] = new_salary\n",
        "    return f\"‚úÖ Salary updated for {emp['name']}: {old_salary} ‚Üí {new_salary}\"\n",
        "\n",
        "@tool\n",
        "def delete_employee_with_approval(\n",
        "    employee_id: Annotated[str, \"Employee ID to delete\"]\n",
        ") -> str:\n",
        "    \"\"\"Delete employee with human approval.\"\"\"\n",
        "    \n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    details = f\"Delete {emp['name']} (ID: {employee_id}) from {emp['department']} department\"\n",
        "    \n",
        "    # Request approval\n",
        "    approved = request_human_approval(\"Employee Deletion\", details)\n",
        "    \n",
        "    if not approved:\n",
        "        return \"‚ùå Employee deletion cancelled - approval denied\"\n",
        "    \n",
        "    # Proceed with deletion\n",
        "    emp_name = emp['name']\n",
        "    del HR_DATABASE[employee_id]\n",
        "    return f\"‚úÖ Employee {emp_name} (ID: {employee_id}) deleted from system\"\n",
        "\n",
        "print(\"‚úÖ Human-in-the-loop tools created!\")\n",
        "print(\"Note: In production, integrate with approval workflow system\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 7: Rate Limiting Guardrails üö¶\n",
        "\n",
        "**Goal:** Prevent abuse by limiting request frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from collections import defaultdict\n",
        "\n",
        "class RateLimiter:\n",
        "    \"\"\"\n",
        "    Simple rate limiter to prevent abuse.\n",
        "    Tracks requests per user/session.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_requests: int = 10, window_seconds: int = 60):\n",
        "        self.max_requests = max_requests\n",
        "        self.window_seconds = window_seconds\n",
        "        self.request_log = defaultdict(list)\n",
        "    \n",
        "    def is_allowed(self, user_id: str) -> tuple[bool, int]:\n",
        "        \"\"\"\n",
        "        Check if request is allowed.\n",
        "        Returns (allowed, remaining_requests)\n",
        "        \"\"\"\n",
        "        now = datetime.now()\n",
        "        cutoff = now - timedelta(seconds=self.window_seconds)\n",
        "        \n",
        "        # Remove old requests\n",
        "        self.request_log[user_id] = [\n",
        "            req_time for req_time in self.request_log[user_id]\n",
        "            if req_time > cutoff\n",
        "        ]\n",
        "        \n",
        "        current_count = len(self.request_log[user_id])\n",
        "        \n",
        "        if current_count >= self.max_requests:\n",
        "            return False, 0\n",
        "        \n",
        "        # Log this request\n",
        "        self.request_log[user_id].append(now)\n",
        "        remaining = self.max_requests - (current_count + 1)\n",
        "        \n",
        "        return True, remaining\n",
        "\n",
        "# Create rate limiter (10 requests per minute)\n",
        "rate_limiter = RateLimiter(max_requests=10, window_seconds=60)\n",
        "\n",
        "def rate_limiting_guardrail(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Pre-model hook for rate limiting.\n",
        "    \"\"\"\n",
        "    # Get user ID from state (in production, use actual user session)\n",
        "    user_id = state.get(\"user_id\", \"default_user\")\n",
        "    \n",
        "    allowed, remaining = rate_limiter.is_allowed(user_id)\n",
        "    \n",
        "    if not allowed:\n",
        "        raise AgentException(\n",
        "            \"‚ùå Rate limit exceeded. Please wait before making more requests.\"\n",
        "        )\n",
        "    \n",
        "    if remaining <= 2:\n",
        "        print(f\"‚ö†Ô∏è Rate limit warning: Only {remaining} requests remaining in this window\")\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"‚úÖ Rate limiting guardrail created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Rate Limiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test rate limiter\n",
        "print(\"Testing Rate Limiter:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "user_id = \"test_user_rajesh\"\n",
        "\n",
        "for i in range(12):\n",
        "    allowed, remaining = rate_limiter.is_allowed(user_id)\n",
        "    if allowed:\n",
        "        print(f\"‚úÖ Request {i+1}: Allowed (Remaining: {remaining})\")\n",
        "    else:\n",
        "        print(f\"‚ùå Request {i+1}: Blocked (Rate limit exceeded!)\")\n",
        "\n",
        "print(\"\\n‚úÖ Rate limiter working correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 8: Custom Business Rules Guardrails üìã\n",
        "\n",
        "**Goal:** Enforce company-specific policies and compliance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business rules configuration\n",
        "BUSINESS_RULES = {\n",
        "    \"max_salary_update_percent\": 20,  # Max 20% salary increase\n",
        "    \"min_employment_days_for_deletion\": 90,  # Can't delete employees < 90 days\n",
        "    \"allowed_departments\": [\"Engineering\", \"HR\", \"Sales\", \"Marketing\"],\n",
        "    \"working_hours\": {\"start\": 9, \"end\": 18},  # 9 AM to 6 PM\n",
        "}\n",
        "\n",
        "def enforce_business_rules(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Enforce company business rules.\n",
        "    \"\"\"\n",
        "    # Rule 1: Check working hours for sensitive operations\n",
        "    current_hour = datetime.now().hour\n",
        "    working_hours = BUSINESS_RULES[\"working_hours\"]\n",
        "    \n",
        "    if not (working_hours[\"start\"] <= current_hour < working_hours[\"end\"]):\n",
        "        print(f\"‚ö†Ô∏è Warning: Operation outside working hours ({working_hours['start']}:00-{working_hours['end']}:00)\")\n",
        "    \n",
        "    # Rule 2: Validate tool calls against business rules\n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    # Additional rule checks can be added here\n",
        "    \n",
        "    return {}\n",
        "\n",
        "# Create validation function for salary updates\n",
        "def validate_salary_update(employee_id: str, new_salary_str: str) -> tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Validate salary update against business rules.\n",
        "    \"\"\"\n",
        "    if employee_id not in HR_DATABASE:\n",
        "        return False, \"Employee not found\"\n",
        "    \n",
        "    emp = HR_DATABASE[employee_id]\n",
        "    \n",
        "    # Extract numeric values\n",
        "    old_salary = int(emp['salary'].replace('‚Çπ', '').replace(',', ''))\n",
        "    new_salary = int(new_salary_str.replace('‚Çπ', '').replace(',', ''))\n",
        "    \n",
        "    # Calculate percentage change\n",
        "    percent_change = ((new_salary - old_salary) / old_salary) * 100\n",
        "    \n",
        "    max_increase = BUSINESS_RULES[\"max_salary_update_percent\"]\n",
        "    \n",
        "    if percent_change > max_increase:\n",
        "        return False, f\"Salary increase of {percent_change:.1f}% exceeds maximum allowed {max_increase}%\"\n",
        "    \n",
        "    if percent_change < -max_increase:\n",
        "        return False, f\"Salary decrease of {abs(percent_change):.1f}% exceeds maximum allowed {max_increase}%\"\n",
        "    \n",
        "    return True, f\"Salary change of {percent_change:.1f}% within acceptable range\"\n",
        "\n",
        "# Test business rules\n",
        "print(\"Testing Business Rules Validation:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Valid salary update\n",
        "valid, msg = validate_salary_update(\"101\", \"‚Çπ17,00,000\")  # ~13% increase\n",
        "print(f\"Test 1 - Valid Update: {valid} - {msg}\")\n",
        "\n",
        "# Test 2: Invalid salary update (too high)\n",
        "valid, msg = validate_salary_update(\"101\", \"‚Çπ25,00,000\")  # ~67% increase\n",
        "print(f\"Test 2 - Invalid Update: {valid} - {msg}\")\n",
        "\n",
        "print(\"\\n‚úÖ Business rules validation working!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 9: Production Agent with All Guardrails üõ°Ô∏è\n",
        "\n",
        "**Combining all guardrails for maximum protection!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "# Enhanced state with user context\n",
        "class SecureHRState(AgentState):\n",
        "    user_id: str = \"default_user\"\n",
        "    user_role: str = \"employee\"  # \"employee\", \"manager\", \"hr_admin\"\n",
        "    employee_id: str = \"\"\n",
        "\n",
        "# Combined guardrail hook\n",
        "def combined_pre_guardrails(state: SecureHRState) -> dict:\n",
        "    \"\"\"Run all pre-execution guardrails.\"\"\"\n",
        "    # 1. Rate limiting\n",
        "    rate_limiting_guardrail(state)\n",
        "    \n",
        "    # 2. Input validation\n",
        "    input_validation_guardrail(state)\n",
        "    \n",
        "    # 3. Business rules\n",
        "    enforce_business_rules(state)\n",
        "    \n",
        "    return {}\n",
        "\n",
        "def combined_post_guardrails(state: SecureHRState) -> dict:\n",
        "    \"\"\"Run all post-execution guardrails.\"\"\"\n",
        "    # 1. Output validation\n",
        "    result1 = output_validation_guardrail(state)\n",
        "    if result1:\n",
        "        return result1\n",
        "    \n",
        "    # 2. PII redaction\n",
        "    result2 = pii_output_guardrail(state)\n",
        "    if result2:\n",
        "        return result2\n",
        "    \n",
        "    return {}\n",
        "\n",
        "# Create production agent with all guardrails\n",
        "production_secure_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[\n",
        "        get_employee_info,\n",
        "        check_leave_balance,\n",
        "        update_salary_with_approval,  # Human-in-the-loop version\n",
        "    ],\n",
        "    state_schema=SecureHRState,\n",
        "    pre_model_hook=combined_pre_guardrails,\n",
        "    post_model_hook=combined_post_guardrails,\n",
        "    checkpointer=InMemorySaver(),\n",
        "    system_prompt=\"\"\"You are a secure HR assistant with strict compliance guardrails.\n",
        "    \n",
        "    Your capabilities:\n",
        "    - Provide employee information (PII-protected)\n",
        "    - Check leave balances\n",
        "    - Assist with HR queries\n",
        "    \n",
        "    Important:\n",
        "    - Always maintain professional tone\n",
        "    - Never share sensitive information without authorization\n",
        "    - Follow all company policies and compliance requirements\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Production-ready secure HR agent created!\")\n",
        "print(\"\")\n",
        "print(\"Guardrails enabled:\")\n",
        "print(\"  ‚úì PII Detection & Redaction\")\n",
        "print(\"  ‚úì Input Validation\")\n",
        "print(\"  ‚úì Output Validation\")\n",
        "print(\"  ‚úì Rate Limiting\")\n",
        "print(\"  ‚úì Business Rules Enforcement\")\n",
        "print(\"  ‚úì Human-in-the-Loop (sensitive operations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Production Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"secure_session_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Production Agent Tests\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Test 1: Normal query (should work)\n",
        "print(\"Test 1: Normal employee query\")\n",
        "print(\"-\" * 70)\n",
        "result = production_secure_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me about employee Priya Sharma\"}],\n",
        "    \"user_id\": \"user_rajesh_123\",\n",
        "    \"user_role\": \"manager\"\n",
        "}, config)\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Test 2: Sensitive information request (PII should be redacted)\n",
        "print(\"Test 2: Contact information request (PII protection)\")\n",
        "print(\"-\" * 70)\n",
        "result = production_secure_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is Priya's email and phone number?\"}],\n",
        "    \"user_id\": \"user_rajesh_123\",\n",
        "    \"user_role\": \"manager\"\n",
        "}, config)\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Test 3: Blocked request\n",
        "print(\"Test 3: Malicious request (should be blocked)\")\n",
        "print(\"-\" * 70)\n",
        "try:\n",
        "    result = production_secure_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"How can I hack the system?\"}],\n",
        "        \"user_id\": \"user_rajesh_123\",\n",
        "        \"user_role\": \"manager\"\n",
        "    }, config)\n",
        "    print(result['messages'][-1].content)\n",
        "except Exception as e:\n",
        "    print(f\"‚úÖ Request blocked: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ All guardrails working correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 10: Monitoring and Logging üìä\n",
        "\n",
        "**Track guardrail triggers for compliance and improvement.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "import json\n",
        "\n",
        "class GuardrailLogger:\n",
        "    \"\"\"Log all guardrail events for monitoring and compliance.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.events: List[Dict] = []\n",
        "    \n",
        "    def log_event(\n",
        "        self,\n",
        "        event_type: str,\n",
        "        severity: str,\n",
        "        description: str,\n",
        "        user_id: str = \"unknown\",\n",
        "        metadata: dict = None\n",
        "    ):\n",
        "        \"\"\"Log a guardrail event.\"\"\"\n",
        "        event = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"event_type\": event_type,\n",
        "            \"severity\": severity,  # \"info\", \"warning\", \"error\", \"critical\"\n",
        "            \"description\": description,\n",
        "            \"user_id\": user_id,\n",
        "            \"metadata\": metadata or {}\n",
        "        }\n",
        "        self.events.append(event)\n",
        "        \n",
        "        # Print high-severity events\n",
        "        if severity in [\"error\", \"critical\"]:\n",
        "            print(f\"üö® [{severity.upper()}] {event_type}: {description}\")\n",
        "    \n",
        "    def get_summary(self) -> dict:\n",
        "        \"\"\"Get summary statistics.\"\"\"\n",
        "        if not self.events:\n",
        "            return {\"total_events\": 0}\n",
        "        \n",
        "        by_type = {}\n",
        "        by_severity = {}\n",
        "        \n",
        "        for event in self.events:\n",
        "            event_type = event[\"event_type\"]\n",
        "            severity = event[\"severity\"]\n",
        "            \n",
        "            by_type[event_type] = by_type.get(event_type, 0) + 1\n",
        "            by_severity[severity] = by_severity.get(severity, 0) + 1\n",
        "        \n",
        "        return {\n",
        "            \"total_events\": len(self.events),\n",
        "            \"by_type\": by_type,\n",
        "            \"by_severity\": by_severity\n",
        "        }\n",
        "    \n",
        "    def export_logs(self, filename: str = \"guardrail_logs.json\"):\n",
        "        \"\"\"Export logs to file.\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.events, f, indent=2)\n",
        "        print(f\"‚úÖ Logs exported to {filename}\")\n",
        "\n",
        "# Create global logger\n",
        "guardrail_logger = GuardrailLogger()\n",
        "\n",
        "# Example usage\n",
        "guardrail_logger.log_event(\n",
        "    event_type=\"pii_detected\",\n",
        "    severity=\"warning\",\n",
        "    description=\"Email address redacted from response\",\n",
        "    user_id=\"user_kavya_456\",\n",
        "    metadata={\"pii_types\": [\"email\"]}\n",
        ")\n",
        "\n",
        "guardrail_logger.log_event(\n",
        "    event_type=\"input_blocked\",\n",
        "    severity=\"error\",\n",
        "    description=\"Request blocked due to prohibited keyword\",\n",
        "    user_id=\"user_amit_789\",\n",
        "    metadata={\"keyword\": \"hack\"}\n",
        ")\n",
        "\n",
        "guardrail_logger.log_event(\n",
        "    event_type=\"human_approval_requested\",\n",
        "    severity=\"info\",\n",
        "    description=\"Salary update requires approval\",\n",
        "    user_id=\"user_meera_321\",\n",
        "    metadata={\"action\": \"update_salary\"}\n",
        ")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Guardrail Event Summary\")\n",
        "print(\"=\" * 70)\n",
        "summary = guardrail_logger.get_summary()\n",
        "print(json.dumps(summary, indent=2))\n",
        "print(\"\\n‚úÖ Logging system ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary & Best Practices\n",
        "\n",
        "## Guardrails Comparison\n",
        "\n",
        "| Guardrail Type | When to Use | Execution Point | Example Use Case |\n",
        "|----------------|-------------|-----------------|------------------|\n",
        "| **PII Detection** | Protect sensitive data | Post-execution | Redact emails, phones, Aadhar |\n",
        "| **Input Validation** | Block bad requests | Pre-execution | Filter malicious queries |\n",
        "| **Output Validation** | Ensure quality | Post-execution | Remove toxic language |\n",
        "| **Human-in-the-Loop** | Sensitive operations | During tool execution | Approve salary changes |\n",
        "| **Rate Limiting** | Prevent abuse | Pre-execution | Limit requests per user |\n",
        "| **Business Rules** | Enforce policies | Pre/Post-execution | Validate salary increases |\n",
        "\n",
        "## Implementation Checklist\n",
        "\n",
        "‚úÖ **Layer multiple guardrails** for defense in depth  \n",
        "‚úÖ **Log all guardrail events** for compliance and monitoring  \n",
        "‚úÖ **Test guardrails thoroughly** before production  \n",
        "‚úÖ **Review logs regularly** to improve guardrails  \n",
        "‚úÖ **Make guardrails configurable** per environment  \n",
        "‚úÖ **Document all guardrail rules** for team  \n",
        "‚úÖ **Set up alerts** for critical violations  \n",
        "\n",
        "## Production Architecture\n",
        "\n",
        "```\n",
        "User Request\n",
        "    ‚Üì\n",
        "[Rate Limiting] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Log\n",
        "    ‚Üì\n",
        "[Input Validation] ‚îÄ‚îÄ‚Üí Log\n",
        "    ‚Üì\n",
        "[Business Rules] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Log\n",
        "    ‚Üì\n",
        "Agent Execution\n",
        "    ‚Üì\n",
        "[Human Approval?] ‚îÄ‚îÄ‚îÄ‚Üí Notification\n",
        "    ‚Üì\n",
        "[Output Validation] ‚îÄ‚Üí Log\n",
        "    ‚Üì\n",
        "[PII Redaction] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Log\n",
        "    ‚Üì\n",
        "Response to User\n",
        "```\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Defense in Depth**: Multiple guardrails provide better protection than any single guardrail\n",
        "2. **Fail Secure**: When in doubt, block the request\n",
        "3. **Log Everything**: Compliance requires detailed audit trails\n",
        "4. **Test Thoroughly**: Guardrails must work under all conditions\n",
        "5. **Monitor Continuously**: Review logs and adjust guardrails\n",
        "\n",
        "## Common Pitfalls to Avoid\n",
        "\n",
        "‚ùå **Don't**: Rely on a single guardrail  \n",
        "‚úÖ **Do**: Layer multiple complementary guardrails\n",
        "\n",
        "‚ùå **Don't**: Ignore logging  \n",
        "‚úÖ **Do**: Log all events for compliance\n",
        "\n",
        "‚ùå **Don't**: Hard-code guardrail rules  \n",
        "‚úÖ **Do**: Make rules configurable\n",
        "\n",
        "‚ùå **Don't**: Skip testing edge cases  \n",
        "‚úÖ **Do**: Test adversarial inputs\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Integrate with production logging systems\n",
        "- Add model-based guardrails (LLM safety checks)\n",
        "- Implement advanced PII detection with NER models\n",
        "- Set up real-time monitoring dashboards\n",
        "- Create approval workflow system\n",
        "\n",
        "---\n",
        "\n",
        "**Remember**: Guardrails are not optional - they're essential for production AI systems!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Exercises üéØ\n",
        "\n",
        "## Exercise 1: Enhanced PII Detection\n",
        "Extend the PII detection to include:\n",
        "- Bank account numbers (Indian format)\n",
        "- PAN card numbers\n",
        "- Passport numbers\n",
        "- Credit card numbers\n",
        "\n",
        "Test with sample data.\n",
        "\n",
        "## Exercise 2: Role-Based Access Control\n",
        "Implement a guardrail that:\n",
        "- Employees can only view their own data\n",
        "- Managers can view their team's data\n",
        "- HR admins can view all data\n",
        "\n",
        "## Exercise 3: Content Moderation\n",
        "Create a guardrail that uses an LLM to:\n",
        "- Detect inappropriate requests\n",
        "- Classify request sensitivity\n",
        "- Provide alternative responses\n",
        "\n",
        "## Exercise 4: Audit Trail System\n",
        "Build a comprehensive audit system that:\n",
        "- Logs all tool executions\n",
        "- Tracks who accessed what data\n",
        "- Generates compliance reports\n",
        "- Alerts on suspicious patterns\n",
        "\n",
        "## Bonus Challenge: Multi-Layer Guardrail System\n",
        "Create a production-ready system with:\n",
        "- 5+ different guardrail types\n",
        "- Configurable guardrail policies\n",
        "- Real-time monitoring dashboard\n",
        "- Automated incident response\n",
        "- Integration with external approval systems"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
