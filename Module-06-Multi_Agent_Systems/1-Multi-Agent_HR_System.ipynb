{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent HR System - Complete Labs\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates various multi-agent patterns for HR use cases using LangChain 1.0 and OpenAI:\n",
        "\n",
        "- **Lab 1**: Basic Multi-Agent (No Tools, No Memory) - Resume Screening\n",
        "- **Lab 2**: Multi-Agent with Tools (No Memory) - Candidate Processing  \n",
        "- **Lab 3**: Multi-Agent with Tools and Memory - Interview Coordination\n",
        "- **Lab 4**: Human-in-the-Loop - Offer Approval Workflow\n",
        "- **Lab 5**: LangGraph Subgraphs - Complete Hiring Pipeline\n",
        "\n",
        "### HR Use Case\n",
        "**Scenario**: TechCorp India - Automated Hiring System\n",
        "- Multiple specialized agents handle different hiring stages\n",
        "- Integration with HR tools (database, calendar, email)\n",
        "- Collaborative decision-making with human oversight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-openai langgraph langchain-core python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import TypedDict, List, Annotated, Literal\n",
        "import operator\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Verify OpenAI API key\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise ValueError(\"Please set OPENAI_API_KEY in your environment\")\n",
        "\n",
        "print(\"âœ“ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample HR Data - TechCorp India\n",
        "\n",
        "Realistic Indian HR dataset for our labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample candidate resume\n",
        "SAMPLE_RESUME = \"\"\"\n",
        "PRIYA SHARMA\n",
        "Senior Software Engineer\n",
        "priya.sharma@email.com | +91-98765-43210 | Bengaluru, Karnataka\n",
        "LinkedIn: linkedin.com/in/priyasharma | GitHub: github.com/priyasharma\n",
        "\n",
        "SUMMARY\n",
        "Results-driven software engineer with 6 years of experience in full-stack development,\n",
        "specializing in Python, React, and cloud-native architectures. Proven track record of\n",
        "building scalable microservices and leading agile teams. Passionate about mentoring\n",
        "and delivering high-quality software solutions.\n",
        "\n",
        "EXPERIENCE\n",
        "\n",
        "Senior Software Engineer | InfoTech Solutions Pvt Ltd, Bengaluru | Jan 2021 - Present\n",
        "- Led a team of 4 developers in building a microservices-based e-commerce platform\n",
        "- Reduced API latency by 45% through optimization and caching strategies\n",
        "- Implemented CI/CD pipeline using Jenkins and Docker, reducing deployment time by 50%\n",
        "- Mentored 3 junior developers and conducted technical interviews\n",
        "- Tech Stack: Python, FastAPI, React, PostgreSQL, Redis, AWS, Docker, Kubernetes\n",
        "\n",
        "Software Engineer | Digital Innovations India, Pune | Jun 2018 - Dec 2020\n",
        "- Developed customer-facing web applications serving 500K+ monthly active users\n",
        "- Built RESTful APIs and integrated third-party payment gateways (Razorpay, PayU)\n",
        "- Collaborated with cross-functional teams in Agile/Scrum environment\n",
        "- Tech Stack: Python, Django, JavaScript, MySQL, AWS EC2, S3\n",
        "\n",
        "Junior Developer | CodeCraft Technologies, Hyderabad | Jul 2016 - May 2018\n",
        "- Maintained and enhanced legacy applications\n",
        "- Developed internal tools to automate manual processes\n",
        "- Participated in code reviews and testing activities\n",
        "\n",
        "EDUCATION\n",
        "B.Tech in Computer Science and Engineering | BITS Pilani | 2016\n",
        "CGPA: 8.5/10\n",
        "\n",
        "SKILLS\n",
        "Languages: Python, JavaScript, TypeScript, SQL, Java\n",
        "Frameworks: FastAPI, Django, React, Next.js, Flask\n",
        "Cloud & DevOps: AWS (EC2, S3, Lambda, RDS), Docker, Kubernetes, Jenkins\n",
        "Databases: PostgreSQL, MySQL, MongoDB, Redis\n",
        "Tools: Git, JIRA, Confluence, Postman\n",
        "\n",
        "CERTIFICATIONS\n",
        "- AWS Certified Solutions Architect - Associate (2022)\n",
        "- Python for Data Science - NPTEL (2020)\n",
        "\"\"\"\n",
        "\n",
        "JOB_DESCRIPTION = \"\"\"\n",
        "Senior Backend Engineer\n",
        "TechCorp India Pvt Ltd | Bengaluru\n",
        "\n",
        "About the Role:\n",
        "We are seeking an experienced Senior Backend Engineer to join our growing engineering team.\n",
        "You will be responsible for designing and building scalable backend systems that power our\n",
        "fintech applications serving millions of users across India.\n",
        "\n",
        "Key Responsibilities:\n",
        "- Design and develop high-performance backend services using Python/FastAPI\n",
        "- Build and maintain microservices architecture on AWS/GCP\n",
        "- Lead technical discussions and mentor junior engineers\n",
        "- Ensure code quality, testing, and documentation standards\n",
        "- Collaborate with product and frontend teams\n",
        "\n",
        "Required Qualifications:\n",
        "- 5+ years of backend development experience\n",
        "- Strong proficiency in Python and related frameworks (FastAPI/Django)\n",
        "- Experience with cloud platforms (AWS/GCP)\n",
        "- Solid understanding of databases (SQL and NoSQL)\n",
        "- Experience with containerization (Docker/Kubernetes)\n",
        "- Knowledge of CI/CD pipelines\n",
        "\n",
        "Preferred Qualifications:\n",
        "- Experience in fintech or payment systems\n",
        "- AWS/GCP certifications\n",
        "- Contribution to open-source projects\n",
        "- Experience leading small teams\n",
        "\n",
        "What We Offer:\n",
        "- Competitive salary (â‚¹25-35 LPA)\n",
        "- Stock options\n",
        "- Health insurance for family\n",
        "- Flexible work arrangements\n",
        "- Learning and development budget\n",
        "\"\"\"\n",
        "\n",
        "# Mock HR Database\n",
        "HR_DATABASE = {\n",
        "    \"employees\": [\n",
        "        {\"id\": \"EMP001\", \"name\": \"Rahul Verma\", \"role\": \"Engineering Manager\", \"email\": \"rahul.verma@techcorp.in\"},\n",
        "        {\"id\": \"EMP002\", \"name\": \"Anjali Patel\", \"role\": \"HR Manager\", \"email\": \"anjali.patel@techcorp.in\"},\n",
        "        {\"id\": \"EMP003\", \"name\": \"Vikram Singh\", \"role\": \"Tech Lead\", \"email\": \"vikram.singh@techcorp.in\"},\n",
        "        {\"id\": \"EMP004\", \"name\": \"Sneha Reddy\", \"role\": \"Senior Engineer\", \"email\": \"sneha.reddy@techcorp.in\"},\n",
        "    ],\n",
        "    \"candidates\": [\n",
        "        {\n",
        "            \"id\": \"CAN001\",\n",
        "            \"name\": \"Priya Sharma\",\n",
        "            \"email\": \"priya.sharma@email.com\",\n",
        "            \"phone\": \"+91-98765-43210\",\n",
        "            \"position\": \"Senior Backend Engineer\",\n",
        "            \"status\": \"screening\",\n",
        "            \"resume_url\": \"https://storage.techcorp.in/resumes/priya_sharma.pdf\"\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"CAN002\",\n",
        "            \"name\": \"Arjun Mehta\",\n",
        "            \"email\": \"arjun.mehta@email.com\",\n",
        "            \"phone\": \"+91-98123-45678\",\n",
        "            \"position\": \"Senior Backend Engineer\",\n",
        "            \"status\": \"interview_scheduled\",\n",
        "            \"resume_url\": \"https://storage.techcorp.in/resumes/arjun_mehta.pdf\"\n",
        "        }\n",
        "    ],\n",
        "    \"interview_slots\": [\n",
        "        {\"date\": \"2025-10-15\", \"time\": \"10:00 AM\", \"interviewer\": \"Rahul Verma\", \"available\": True},\n",
        "        {\"date\": \"2025-10-15\", \"time\": \"2:00 PM\", \"interviewer\": \"Vikram Singh\", \"available\": True},\n",
        "        {\"date\": \"2025-10-16\", \"time\": \"11:00 AM\", \"interviewer\": \"Sneha Reddy\", \"available\": True},\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"HR Database initialized with:\")\n",
        "print(f\"- {len(HR_DATABASE['employees'])} employees\")\n",
        "print(f\"- {len(HR_DATABASE['candidates'])} candidates\")\n",
        "print(f\"- {len(HR_DATABASE['interview_slots'])} interview slots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 1: Basic Multi-Agent (No Tools, No Memory)\n",
        "\n",
        "**Pattern**: Simple agent coordination using LangChain 1.0\n",
        "\n",
        "**Use Case**: Resume screening with specialized agents:\n",
        "- **Resume Reviewer**: Analyzes experience and qualifications\n",
        "- **Skills Assessor**: Evaluates technical skills match\n",
        "- **Culture Fit Analyst**: Assesses company culture alignment\n",
        "- **Hiring Coordinator**: Synthesizes recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Define state for agent collaboration\n",
        "class ScreeningState(TypedDict):\n",
        "    candidate_name: str\n",
        "    position: str\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    resume_analysis: str\n",
        "    skills_assessment: str\n",
        "    culture_fit: str\n",
        "    final_decision: str\n",
        "    messages: List[str]\n",
        "\n",
        "# Agent 1: Resume Reviewer\n",
        "def resume_reviewer_agent(state: ScreeningState) -> ScreeningState:\n",
        "    \"\"\"\n",
        "    Analyzes resume for relevant experience and qualifications\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are an expert Resume Reviewer for TechCorp India.\n",
        "\n",
        "Position: {state['position']}\n",
        "Candidate: {state['candidate_name']}\n",
        "\n",
        "Resume:\n",
        "{state['resume']}\n",
        "\n",
        "Job Requirements:\n",
        "{state['job_description']}\n",
        "\n",
        "Provide a structured analysis:\n",
        "1. Years of relevant experience\n",
        "2. Educational background match\n",
        "3. Key qualifications aligning with role\n",
        "4. Notable achievements\n",
        "5. Any concerns or gaps\n",
        "\n",
        "Keep your analysis concise and professional.\n",
        "\"\"\"\n",
        "    \n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    state['resume_analysis'] = response.content\n",
        "    state['messages'].append(f\"[Resume Reviewer] Analysis complete\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Agent 2: Skills Assessor\n",
        "def skills_assessor_agent(state: ScreeningState) -> ScreeningState:\n",
        "    \"\"\"\n",
        "    Evaluates technical skills against job requirements\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a Technical Skills Assessor for TechCorp India.\n",
        "\n",
        "Position: {state['position']}\n",
        "Candidate: {state['candidate_name']}\n",
        "\n",
        "Resume:\n",
        "{state['resume']}\n",
        "\n",
        "Job Requirements:\n",
        "{state['job_description']}\n",
        "\n",
        "Previous Analysis:\n",
        "{state['resume_analysis']}\n",
        "\n",
        "Evaluate the candidate's technical skills:\n",
        "1. Programming languages proficiency match\n",
        "2. Framework and technology stack alignment\n",
        "3. Cloud platform experience (AWS/GCP)\n",
        "4. DevOps and tooling knowledge\n",
        "5. Skills gap analysis\n",
        "6. Overall technical fit score (1-10)\n",
        "\n",
        "Be specific and objective.\n",
        "\"\"\"\n",
        "    \n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    state['skills_assessment'] = response.content\n",
        "    state['messages'].append(f\"[Skills Assessor] Assessment complete\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Agent 3: Culture Fit Analyst\n",
        "def culture_fit_analyst(state: ScreeningState) -> ScreeningState:\n",
        "    \"\"\"\n",
        "    Assesses candidate's alignment with company culture\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a Culture Fit Analyst for TechCorp India.\n",
        "\n",
        "Position: {state['position']}\n",
        "Candidate: {state['candidate_name']}\n",
        "\n",
        "Resume:\n",
        "{state['resume']}\n",
        "\n",
        "Previous Analyses:\n",
        "Resume Review: {state['resume_analysis']}\n",
        "Skills Assessment: {state['skills_assessment']}\n",
        "\n",
        "Company Culture: Collaborative, innovation-driven, mentorship-focused, \n",
        "fast-paced startup environment, values continuous learning.\n",
        "\n",
        "Assess culture fit based on:\n",
        "1. Leadership and mentoring experience\n",
        "2. Collaboration indicators\n",
        "3. Learning and growth mindset\n",
        "4. Startup/fast-paced environment experience\n",
        "5. Innovation and contribution indicators\n",
        "6. Culture fit score (1-10)\n",
        "\n",
        "Provide insights, not just scores.\n",
        "\"\"\"\n",
        "    \n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    state['culture_fit'] = response.content\n",
        "    state['messages'].append(f\"[Culture Fit Analyst] Analysis complete\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Agent 4: Hiring Coordinator (Synthesizer)\n",
        "def hiring_coordinator(state: ScreeningState) -> ScreeningState:\n",
        "    \"\"\"\n",
        "    Synthesizes all analyses and makes final recommendation\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are the Hiring Coordinator for TechCorp India.\n",
        "\n",
        "Position: {state['position']}\n",
        "Candidate: {state['candidate_name']}\n",
        "\n",
        "You have received the following analyses:\n",
        "\n",
        "RESUME ANALYSIS:\n",
        "{state['resume_analysis']}\n",
        "\n",
        "SKILLS ASSESSMENT:\n",
        "{state['skills_assessment']}\n",
        "\n",
        "CULTURE FIT ANALYSIS:\n",
        "{state['culture_fit']}\n",
        "\n",
        "Synthesize the above analyses and provide:\n",
        "1. Overall summary\n",
        "2. Key strengths\n",
        "3. Areas of concern (if any)\n",
        "4. Final recommendation (STRONG PROCEED / PROCEED / MAYBE / REJECT)\n",
        "5. Next steps if proceeding\n",
        "\n",
        "Be decisive and clear in your recommendation.\n",
        "\"\"\"\n",
        "    \n",
        "    messages = [HumanMessage(content=prompt)]\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    state['final_decision'] = response.content\n",
        "    state['messages'].append(f\"[Hiring Coordinator] Final decision ready\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Orchestrate the multi-agent workflow\n",
        "def run_screening_workflow(candidate_name: str, resume: str, job_desc: str, position: str):\n",
        "    \"\"\"\n",
        "    Run the complete screening workflow\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Starting Resume Screening for: {candidate_name}\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    # Initialize state\n",
        "    state: ScreeningState = {\n",
        "        \"candidate_name\": candidate_name,\n",
        "        \"position\": position,\n",
        "        \"resume\": resume,\n",
        "        \"job_description\": job_desc,\n",
        "        \"resume_analysis\": \"\",\n",
        "        \"skills_assessment\": \"\",\n",
        "        \"culture_fit\": \"\",\n",
        "        \"final_decision\": \"\",\n",
        "        \"messages\": []\n",
        "    }\n",
        "    \n",
        "    # Execute agents in sequence\n",
        "    state = resume_reviewer_agent(state)\n",
        "    print(state['messages'][-1])\n",
        "    \n",
        "    state = skills_assessor_agent(state)\n",
        "    print(state['messages'][-1])\n",
        "    \n",
        "    state = culture_fit_analyst(state)\n",
        "    print(state['messages'][-1])\n",
        "    \n",
        "    state = hiring_coordinator(state)\n",
        "    print(state['messages'][-1])\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Test Lab 1\n",
        "print(\"\\nðŸ§ª Lab 1: Basic Multi-Agent (No Tools, No Memory)\\n\")\n",
        "result = run_screening_workflow(\n",
        "    candidate_name=\"Priya Sharma\",\n",
        "    resume=SAMPLE_RESUME,\n",
        "    job_desc=JOB_DESCRIPTION,\n",
        "    position=\"Senior Backend Engineer\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL HIRING DECISION\")\n",
        "print(\"=\"*80)\n",
        "print(result['final_decision'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 2: Multi-Agent with Tools (No Memory)\n",
        "\n",
        "**Pattern**: Tool Calling - agents use tools to access HR systems\n",
        "\n",
        "**Tools**:\n",
        "- `search_hr_database`: Query employee and candidate information\n",
        "- `check_interview_slots`: Check interviewer availability\n",
        "- `send_email`: Send email notifications\n",
        "- `update_candidate_status`: Update candidate status in ATS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define HR Tools\n",
        "\n",
        "@tool\n",
        "def search_hr_database(query_type: str, search_term: str) -> str:\n",
        "    \"\"\"\n",
        "    Search the HR database for employee or candidate information.\n",
        "    \n",
        "    Args:\n",
        "        query_type: Type of search - 'employee' or 'candidate'\n",
        "        search_term: Name, ID, or role to search for\n",
        "    \n",
        "    Returns:\n",
        "        JSON string of matching results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    if query_type == \"employee\":\n",
        "        for emp in HR_DATABASE[\"employees\"]:\n",
        "            if search_term.lower() in emp[\"name\"].lower() or search_term.lower() in emp[\"role\"].lower():\n",
        "                results.append(emp)\n",
        "    \n",
        "    elif query_type == \"candidate\":\n",
        "        for cand in HR_DATABASE[\"candidates\"]:\n",
        "            if search_term.lower() in cand[\"name\"].lower() or search_term.lower() in cand[\"position\"].lower():\n",
        "                results.append(cand)\n",
        "    \n",
        "    return json.dumps(results, indent=2)\n",
        "\n",
        "@tool\n",
        "def check_interview_slots(interviewer_name: str = None, date: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Check available interview slots.\n",
        "    \n",
        "    Args:\n",
        "        interviewer_name: Optional - filter by interviewer name\n",
        "        date: Optional - filter by date (YYYY-MM-DD)\n",
        "    \n",
        "    Returns:\n",
        "        JSON string of available slots\n",
        "    \"\"\"\n",
        "    slots = HR_DATABASE[\"interview_slots\"]\n",
        "    \n",
        "    if interviewer_name:\n",
        "        slots = [s for s in slots if interviewer_name.lower() in s[\"interviewer\"].lower()]\n",
        "    \n",
        "    if date:\n",
        "        slots = [s for s in slots if s[\"date\"] == date]\n",
        "    \n",
        "    available_slots = [s for s in slots if s[\"available\"]]\n",
        "    \n",
        "    return json.dumps(available_slots, indent=2)\n",
        "\n",
        "@tool\n",
        "def send_email(to_email: str, subject: str, body: str) -> str:\n",
        "    \"\"\"\n",
        "    Send an email notification.\n",
        "    \n",
        "    Args:\n",
        "        to_email: Recipient email address\n",
        "        subject: Email subject\n",
        "        body: Email body content\n",
        "    \n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    # In real scenario, this would send actual email\n",
        "    return f\"Email sent successfully to {to_email}\\nSubject: {subject}\\n\\n[SIMULATED - No actual email sent]\"\n",
        "\n",
        "@tool\n",
        "def update_candidate_status(candidate_id: str, new_status: str, notes: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Update candidate status in the ATS (Applicant Tracking System).\n",
        "    \n",
        "    Args:\n",
        "        candidate_id: Candidate ID (e.g., CAN001)\n",
        "        new_status: New status (screening, interview_scheduled, offer, rejected)\n",
        "        notes: Optional notes about the status change\n",
        "    \n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    for candidate in HR_DATABASE[\"candidates\"]:\n",
        "        if candidate[\"id\"] == candidate_id:\n",
        "            old_status = candidate[\"status\"]\n",
        "            candidate[\"status\"] = new_status\n",
        "            return f\"Updated {candidate['name']}: {old_status} â†’ {new_status}\\nNotes: {notes}\"\n",
        "    \n",
        "    return f\"Candidate {candidate_id} not found\"\n",
        "\n",
        "# List of all tools\n",
        "hr_tools = [search_hr_database, check_interview_slots, send_email, update_candidate_status]\n",
        "\n",
        "print(\"âœ“ HR Tools defined:\")\n",
        "for tool in hr_tools:\n",
        "    print(f\"  - {tool.name}: {tool.description}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Tool-Calling Agents\n",
        "\n",
        "# Agent 1: Recruitment Coordinator with Tools\n",
        "recruitment_coordinator_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are a Recruitment Coordinator at TechCorp India.\n",
        "\n",
        "Your responsibilities:\n",
        "- Search for candidate information in HR database\n",
        "- Check interviewer availability\n",
        "- Schedule interviews\n",
        "- Send email notifications to candidates and interviewers\n",
        "- Update candidate status in the system\n",
        "\n",
        "Always use the available tools to get accurate, real-time information.\n",
        "Be professional and efficient in your communication.\n",
        "\"\"\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "recruitment_agent = create_tool_calling_agent(llm, hr_tools, recruitment_coordinator_prompt)\n",
        "recruitment_executor = AgentExecutor(agent=recruitment_agent, tools=hr_tools, verbose=True)\n",
        "\n",
        "print(\"âœ“ Recruitment Coordinator Agent created with HR tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 2: Multi-Agent with Tools\n",
        "\n",
        "print(\"\\nðŸ§ª Lab 2: Multi-Agent with Tools (No Memory)\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Task 1: Find candidate and schedule interview\n",
        "task1 = \"\"\"\n",
        "I need to schedule an interview for candidate Priya Sharma (ID: CAN001) for the \n",
        "Senior Backend Engineer position.\n",
        "\n",
        "Please:\n",
        "1. Look up the candidate details\n",
        "2. Find available interview slots with Rahul Verma or Vikram Singh\n",
        "3. Schedule the interview for the earliest available slot\n",
        "4. Update the candidate status to 'interview_scheduled'\n",
        "5. Send confirmation emails to both the candidate and interviewer\n",
        "\"\"\"\n",
        "\n",
        "result1 = recruitment_executor.invoke({\"input\": task1})\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Task Result:\")\n",
        "print(result1[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 3: Multi-Agent with Tools and Memory\n",
        "\n",
        "**Pattern**: Persistent memory with checkpointing using LangGraph\n",
        "\n",
        "**Features**:\n",
        "- Conversation memory across interactions\n",
        "- State persistence using checkpointing\n",
        "- Context retention for multi-turn conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Define state with memory\n",
        "class HRAgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    candidate_context: dict\n",
        "\n",
        "# Create agent with memory\n",
        "memory = MemorySaver()\n",
        "\n",
        "hr_agent_with_memory = create_react_agent(\n",
        "    llm,\n",
        "    tools=hr_tools,\n",
        "    state_schema=HRAgentState,\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "print(\"âœ“ HR Agent with memory created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 3: Multi-turn conversation with memory\n",
        "\n",
        "print(\"\\nðŸ§ª Lab 3: Multi-Agent with Tools and Memory\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Configuration for thread-based memory\n",
        "config = {\"configurable\": {\"thread_id\": \"hiring_thread_priya_001\"}}\n",
        "\n",
        "# Turn 1: Initial query\n",
        "print(\"\\n--- Turn 1: Initial Query ---\")\n",
        "response1 = hr_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you find information about candidate Priya Sharma?\")]},\n",
        "    config\n",
        ")\n",
        "print(response1[\"messages\"][-1].content)\n",
        "\n",
        "# Turn 2: Follow-up (agent remembers context)\n",
        "print(\"\\n--- Turn 2: Follow-up Question (Testing Memory) ---\")\n",
        "response2 = hr_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What interview slots are available for her next week?\")]},\n",
        "    config\n",
        ")\n",
        "print(response2[\"messages\"][-1].content)\n",
        "\n",
        "# Turn 3: Action based on previous context\n",
        "print(\"\\n--- Turn 3: Action with Context ---\")\n",
        "response3 = hr_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Schedule her for the first available slot and send her a confirmation email.\")]},\n",
        "    config\n",
        ")\n",
        "print(response3[\"messages\"][-1].content)\n",
        "\n",
        "# Turn 4: Verify agent remembers everything\n",
        "print(\"\\n--- Turn 4: Memory Verification ---\")\n",
        "response4 = hr_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you summarize what we've done for this candidate so far?\")]},\n",
        "    config\n",
        ")\n",
        "print(response4[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 4: Human-in-the-Loop Workflow\n",
        "\n",
        "**Pattern**: Approval workflow with human intervention\n",
        "\n",
        "**Use Case**: Offer approval process\n",
        "- Agent prepares offer details\n",
        "- Human reviews and approves/rejects\n",
        "- Agent proceeds based on approval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Define state for offer approval workflow\n",
        "class OfferApprovalState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    candidate_name: str\n",
        "    position: str\n",
        "    proposed_salary: str\n",
        "    offer_details: str\n",
        "    approval_status: str\n",
        "    human_feedback: str\n",
        "\n",
        "# Node 1: Prepare Offer\n",
        "def prepare_offer(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    AI agent prepares offer details\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are an HR Compensation Specialist at TechCorp India.\n",
        "\n",
        "Prepare a job offer for:\n",
        "- Candidate: {state.get('candidate_name', 'Priya Sharma')}\n",
        "- Position: {state.get('position', 'Senior Backend Engineer')}\n",
        "- Proposed Salary: {state.get('proposed_salary', 'â‚¹30 LPA')}\n",
        "\n",
        "Create a comprehensive offer package including:\n",
        "1. Base salary\n",
        "2. Performance bonus structure\n",
        "3. Stock options (if applicable)\n",
        "4. Benefits (health insurance, learning budget, etc.)\n",
        "5. Start date\n",
        "6. Other perks\n",
        "\n",
        "Format it professionally for management review.\n",
        "\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"offer_details\": response.content,\n",
        "        \"approval_status\": \"pending\",\n",
        "        \"messages\": [HumanMessage(content=\"Offer prepared and ready for approval\")]\n",
        "    }\n",
        "\n",
        "# Node 2: Human Approval (This is where we pause for human input)\n",
        "def human_approval(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    Pause for human approval\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"OFFER PENDING APPROVAL\")\n",
        "    print(\"=\"*80)\n",
        "    print(state[\"offer_details\"])\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    \n",
        "    # In real implementation, this would trigger an interrupt\n",
        "    # For demo, we'll simulate human input\n",
        "    approval = input(\"\\nApprove this offer? (yes/no/modify): \").strip().lower()\n",
        "    \n",
        "    if approval == \"yes\":\n",
        "        return {\n",
        "            \"approval_status\": \"approved\",\n",
        "            \"human_feedback\": \"Offer approved\",\n",
        "            \"messages\": [HumanMessage(content=\"Offer approved by manager\")]\n",
        "        }\n",
        "    elif approval == \"no\":\n",
        "        feedback = input(\"Reason for rejection: \")\n",
        "        return {\n",
        "            \"approval_status\": \"rejected\",\n",
        "            \"human_feedback\": feedback,\n",
        "            \"messages\": [HumanMessage(content=f\"Offer rejected: {feedback}\")]\n",
        "        }\n",
        "    else:\n",
        "        feedback = input(\"What modifications are needed?: \")\n",
        "        return {\n",
        "            \"approval_status\": \"needs_modification\",\n",
        "            \"human_feedback\": feedback,\n",
        "            \"messages\": [HumanMessage(content=f\"Modifications requested: {feedback}\")]\n",
        "        }\n",
        "\n",
        "# Node 3: Process Approval\n",
        "def process_approval(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    Take action based on approval status\n",
        "    \"\"\"\n",
        "    if state[\"approval_status\"] == \"approved\":\n",
        "        # Send offer letter\n",
        "        action = f\"\"\"Offer approved! Next steps:\n",
        "1. Generate formal offer letter\n",
        "2. Send to candidate: {state.get('candidate_name', 'Priya Sharma')}\n",
        "3. Update ATS status to 'offer_sent'\n",
        "4. Set follow-up reminder for 3 days\n",
        "\"\"\"\n",
        "    elif state[\"approval_status\"] == \"rejected\":\n",
        "        action = f\"\"\"Offer rejected. Reason: {state['human_feedback']}\n",
        "No further action taken. Candidate remains in pipeline.\n",
        "\"\"\"\n",
        "    else:\n",
        "        action = f\"\"\"Modifications requested: {state['human_feedback']}\n",
        "Sending back to compensation team for revision.\n",
        "\"\"\"\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [HumanMessage(content=action)]\n",
        "    }\n",
        "\n",
        "# Build workflow graph\n",
        "def should_continue(state: OfferApprovalState) -> Literal[\"process\", \"end\"]:\n",
        "    if state.get(\"approval_status\") in [\"approved\", \"rejected\"]:\n",
        "        return \"process\"\n",
        "    return \"end\"\n",
        "\n",
        "# Create graph\n",
        "workflow = StateGraph(OfferApprovalState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"prepare\", prepare_offer)\n",
        "workflow.add_node(\"approve\", human_approval)\n",
        "workflow.add_node(\"process\", process_approval)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(START, \"prepare\")\n",
        "workflow.add_edge(\"prepare\", \"approve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"approve\",\n",
        "    should_continue,\n",
        "    {\"process\": \"process\", \"end\": END}\n",
        ")\n",
        "workflow.add_edge(\"process\", END)\n",
        "\n",
        "# Compile\n",
        "hitl_app = workflow.compile()\n",
        "\n",
        "print(\"âœ“ Human-in-the-Loop workflow created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 4: Human-in-the-Loop\n",
        "\n",
        "print(\"\\nðŸ§ª Lab 4: Human-in-the-Loop Workflow\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [],\n",
        "    \"candidate_name\": \"Priya Sharma\",\n",
        "    \"position\": \"Senior Backend Engineer\",\n",
        "    \"proposed_salary\": \"â‚¹32 LPA\",\n",
        "    \"offer_details\": \"\",\n",
        "    \"approval_status\": \"\",\n",
        "    \"human_feedback\": \"\"\n",
        "}\n",
        "\n",
        "# Run workflow (will pause for human input)\n",
        "result = hitl_app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"WORKFLOW COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "for msg in result[\"messages\"]:\n",
        "    print(f\"\\n{msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 5: LangGraph Subgraphs - Complete Hiring Pipeline\n",
        "\n",
        "**Pattern**: Multi-agent system using subgraphs\n",
        "\n",
        "**Architecture**:\n",
        "- **Parent Graph**: Overall hiring orchestration\n",
        "- **Subgraph 1**: Screening Team (multiple specialized agents)\n",
        "- **Subgraph 2**: Interview Coordination Team\n",
        "- **Subgraph 3**: Offer Management Team\n",
        "\n",
        "This demonstrates the full power of LangGraph with nested agent teams!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import Literal\n",
        "\n",
        "# ============================================================================\n",
        "# SUBGRAPH 1: Screening Team\n",
        "# ============================================================================\n",
        "\n",
        "class ScreeningSubgraphState(TypedDict):\n",
        "    candidate_name: str\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    screening_result: str  # shared key with parent\n",
        "    technical_score: int\n",
        "    culture_score: int\n",
        "\n",
        "def resume_screener(state: ScreeningSubgraphState):\n",
        "    \"\"\"Quick resume screening\"\"\"\n",
        "    prompt = f\"\"\"Quickly screen this resume for {state['candidate_name']}:\n",
        "{state['resume'][:500]}...\n",
        "\n",
        "Job: {state['job_description'][:300]}...\n",
        "\n",
        "Provide: PASS/FAIL and brief reason (2 sentences max).\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return {\"screening_result\": response.content}\n",
        "\n",
        "def technical_evaluator(state: ScreeningSubgraphState):\n",
        "    \"\"\"Evaluate technical skills\"\"\"\n",
        "    if \"FAIL\" in state.get(\"screening_result\", \"\"):\n",
        "        return {\"technical_score\": 0}\n",
        "    \n",
        "    prompt = f\"\"\"Rate technical skills (1-10) for:\n",
        "{state['resume'][:400]}...\n",
        "\n",
        "Just give a score and one-line justification.\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    # Extract score (simplified)\n",
        "    score = 7  # In real scenario, parse from response\n",
        "    return {\"technical_score\": score}\n",
        "\n",
        "def culture_evaluator(state: ScreeningSubgraphState):\n",
        "    \"\"\"Evaluate culture fit\"\"\"\n",
        "    if \"FAIL\" in state.get(\"screening_result\", \"\"):\n",
        "        return {\"culture_score\": 0}\n",
        "    \n",
        "    score = 8  # Simplified\n",
        "    return {\"culture_score\": score}\n",
        "\n",
        "def screening_decision(state: ScreeningSubgraphState):\n",
        "    \"\"\"Make final screening decision\"\"\"\n",
        "    tech_score = state.get(\"technical_score\", 0)\n",
        "    culture_score = state.get(\"culture_score\", 0)\n",
        "    avg_score = (tech_score + culture_score) / 2\n",
        "    \n",
        "    if avg_score >= 6:\n",
        "        result = f\"PROCEED TO INTERVIEW (Tech: {tech_score}/10, Culture: {culture_score}/10)\"\n",
        "    else:\n",
        "        result = f\"REJECT (Tech: {tech_score}/10, Culture: {culture_score}/10)\"\n",
        "    \n",
        "    return {\"screening_result\": result}\n",
        "\n",
        "# Build screening subgraph\n",
        "screening_builder = StateGraph(ScreeningSubgraphState)\n",
        "screening_builder.add_node(\"screen\", resume_screener)\n",
        "screening_builder.add_node(\"tech_eval\", technical_evaluator)\n",
        "screening_builder.add_node(\"culture_eval\", culture_evaluator)\n",
        "screening_builder.add_node(\"decision\", screening_decision)\n",
        "\n",
        "screening_builder.add_edge(START, \"screen\")\n",
        "screening_builder.add_edge(\"screen\", \"tech_eval\")\n",
        "screening_builder.add_edge(\"tech_eval\", \"culture_eval\")\n",
        "screening_builder.add_edge(\"culture_eval\", \"decision\")\n",
        "\n",
        "screening_subgraph = screening_builder.compile()\n",
        "\n",
        "print(\"âœ“ Screening Subgraph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SUBGRAPH 2: Interview Coordination Team\n",
        "# ============================================================================\n",
        "\n",
        "class InterviewSubgraphState(TypedDict):\n",
        "    candidate_name: str\n",
        "    interview_scheduled: bool  # shared with parent\n",
        "    interview_details: str\n",
        "\n",
        "def find_interviewers(state: InterviewSubgraphState):\n",
        "    \"\"\"Find available interviewers\"\"\"\n",
        "    # Simulated\n",
        "    interviewers = \"Rahul Verma, Vikram Singh\"\n",
        "    return {\"interview_details\": f\"Interviewers available: {interviewers}\"}\n",
        "\n",
        "def schedule_interview(state: InterviewSubgraphState):\n",
        "    \"\"\"Schedule the interview\"\"\"\n",
        "    details = f\"\"\"\n",
        "Interview scheduled for {state['candidate_name']}\n",
        "Date: 2025-10-15\n",
        "Time: 10:00 AM IST\n",
        "Panel: Rahul Verma (Technical), Vikram Singh (System Design)\n",
        "Duration: 90 minutes\n",
        "\"\"\"\n",
        "    return {\n",
        "        \"interview_scheduled\": True,\n",
        "        \"interview_details\": details\n",
        "    }\n",
        "\n",
        "# Build interview subgraph\n",
        "interview_builder = StateGraph(InterviewSubgraphState)\n",
        "interview_builder.add_node(\"find_panel\", find_interviewers)\n",
        "interview_builder.add_node(\"schedule\", schedule_interview)\n",
        "\n",
        "interview_builder.add_edge(START, \"find_panel\")\n",
        "interview_builder.add_edge(\"find_panel\", \"schedule\")\n",
        "\n",
        "interview_subgraph = interview_builder.compile()\n",
        "\n",
        "print(\"âœ“ Interview Subgraph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PARENT GRAPH: Overall Hiring Pipeline\n",
        "# ============================================================================\n",
        "\n",
        "class HiringPipelineState(TypedDict):\n",
        "    candidate_name: str\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    screening_result: str  # shared with screening subgraph\n",
        "    interview_scheduled: bool  # shared with interview subgraph\n",
        "    interview_details: str\n",
        "    final_status: str\n",
        "\n",
        "def start_pipeline(state: HiringPipelineState):\n",
        "    \"\"\"Initialize the hiring pipeline\"\"\"\n",
        "    return {\n",
        "        \"final_status\": f\"Starting hiring pipeline for {state['candidate_name']}\"\n",
        "    }\n",
        "\n",
        "def should_interview(state: HiringPipelineState) -> Literal[\"interview\", \"reject\"]:\n",
        "    \"\"\"Route based on screening result\"\"\"\n",
        "    if \"PROCEED\" in state.get(\"screening_result\", \"\"):\n",
        "        return \"interview\"\n",
        "    return \"reject\"\n",
        "\n",
        "def reject_candidate(state: HiringPipelineState):\n",
        "    \"\"\"Handle rejection\"\"\"\n",
        "    return {\n",
        "        \"final_status\": f\"Candidate {state['candidate_name']} rejected at screening stage.\\nReason: {state['screening_result']}\"\n",
        "    }\n",
        "\n",
        "def finalize_pipeline(state: HiringPipelineState):\n",
        "    \"\"\"Finalize the pipeline\"\"\"\n",
        "    if state.get(\"interview_scheduled\"):\n",
        "        status = f\"\"\"\n",
        "âœ“ Candidate {state['candidate_name']} successfully processed!\n",
        "\n",
        "Screening: {state['screening_result']}\n",
        "\n",
        "Interview Details:\n",
        "{state.get('interview_details', 'Not scheduled')}\n",
        "\n",
        "Next steps: Interview panel will evaluate and provide feedback.\n",
        "\"\"\"\n",
        "    else:\n",
        "        status = state.get(\"final_status\", \"Pipeline complete\")\n",
        "    \n",
        "    return {\"final_status\": status}\n",
        "\n",
        "# Build parent graph\n",
        "parent_builder = StateGraph(HiringPipelineState)\n",
        "\n",
        "# Add nodes (including subgraphs)\n",
        "parent_builder.add_node(\"start\", start_pipeline)\n",
        "parent_builder.add_node(\"screening_team\", screening_subgraph)  # Subgraph as node!\n",
        "parent_builder.add_node(\"interview_team\", interview_subgraph)  # Subgraph as node!\n",
        "parent_builder.add_node(\"reject\", reject_candidate)\n",
        "parent_builder.add_node(\"finalize\", finalize_pipeline)\n",
        "\n",
        "# Add edges\n",
        "parent_builder.add_edge(START, \"start\")\n",
        "parent_builder.add_edge(\"start\", \"screening_team\")\n",
        "\n",
        "# Conditional routing after screening\n",
        "parent_builder.add_conditional_edges(\n",
        "    \"screening_team\",\n",
        "    should_interview,\n",
        "    {\n",
        "        \"interview\": \"interview_team\",\n",
        "        \"reject\": \"reject\"\n",
        "    }\n",
        ")\n",
        "\n",
        "parent_builder.add_edge(\"interview_team\", \"finalize\")\n",
        "parent_builder.add_edge(\"reject\", \"finalize\")\n",
        "parent_builder.add_edge(\"finalize\", END)\n",
        "\n",
        "# Compile the complete pipeline\n",
        "hiring_pipeline = parent_builder.compile()\n",
        "\n",
        "print(\"âœ“ Complete Hiring Pipeline with Subgraphs created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 5: Complete Pipeline with Subgraphs\n",
        "\n",
        "print(\"\\nðŸ§ª Lab 5: LangGraph Subgraphs - Complete Hiring Pipeline\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Test Case 1: Successful candidate\n",
        "print(\"\\nTest Case 1: Processing Priya Sharma\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "pipeline_input = {\n",
        "    \"candidate_name\": \"Priya Sharma\",\n",
        "    \"resume\": SAMPLE_RESUME,\n",
        "    \"job_description\": JOB_DESCRIPTION,\n",
        "    \"screening_result\": \"\",\n",
        "    \"interview_scheduled\": False,\n",
        "    \"interview_details\": \"\",\n",
        "    \"final_status\": \"\"\n",
        "}\n",
        "\n",
        "# Run the complete pipeline\n",
        "result = hiring_pipeline.invoke(pipeline_input)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PIPELINE RESULT\")\n",
        "print(\"=\"*80)\n",
        "print(result[\"final_status\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Summary of Labs\n",
        "\n",
        "We've built a complete progression of multi-agent systems:\n",
        "\n",
        "### Lab 1: Basic Multi-Agent\n",
        "- âœ“ Multiple specialized agents working in sequence\n",
        "- âœ“ No external tools or memory\n",
        "- âœ“ Simple state passing between agents\n",
        "\n",
        "### Lab 2: Multi-Agent with Tools\n",
        "- âœ“ Agents using external tools (HR database, email, calendar)\n",
        "- âœ“ Tool-calling pattern with LangChain\n",
        "- âœ“ Real-world HR operations\n",
        "\n",
        "### Lab 3: Multi-Agent with Tools and Memory\n",
        "- âœ“ Persistent conversation memory\n",
        "- âœ“ Context retention across multiple turns\n",
        "- âœ“ Checkpointing with MemorySaver\n",
        "\n",
        "### Lab 4: Human-in-the-Loop\n",
        "- âœ“ Approval workflows\n",
        "- âœ“ Human oversight and intervention\n",
        "- âœ“ Conditional workflow based on human decisions\n",
        "\n",
        "### Lab 5: LangGraph Subgraphs\n",
        "- âœ“ Complex multi-agent architecture\n",
        "- âœ“ Nested subgraphs for team organization\n",
        "- âœ“ Parent-child graph communication\n",
        "- âœ“ Complete hiring pipeline orchestration\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "\n",
        "1. **Add Real Integrations**: Connect to actual HR systems (ATS, HRIS)\n",
        "2. **Enhance Tools**: Add more sophisticated HR tools (background checks, assessments)\n",
        "3. **Improve Memory**: Use persistent databases (PostgreSQL, MongoDB)\n",
        "4. **Add Evaluation**: Implement metrics to measure agent performance\n",
        "5. **Deploy**: Move to production with proper error handling and monitoring\n",
        "\n",
        "## ðŸ“š References\n",
        "\n",
        "- [LangChain Multi-Agent Docs](https://docs.langchain.com/oss/python/langchain/multi-agent)\n",
        "- [LangGraph Subgraphs](https://docs.langchain.com/oss/python/langgraph/use-subgraphs)\n",
        "- [Human-in-the-Loop](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
        "- [LangChain Tools](https://docs.langchain.com/oss/python/langchain/tools)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
