{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent HR System - LangGraph & LangChain 1.0\n",
        "\n",
        "## Overview\n",
        "Modern multi-agent patterns using **LangGraph** and **LangChain 1.0**:\n",
        "\n",
        "- **Lab 1**: Basic Multi-Agent with StateGraph (No Tools, No Memory)\n",
        "- **Lab 2**: Tool Calling Pattern (With Tools, No Memory)  \n",
        "- **Lab 3**: Handoffs Pattern (With Tools and Memory)\n",
        "- **Lab 4**: Human-in-the-Loop with Interrupts\n",
        "- **Lab 5**: Subgraphs - Nested Agent Teams\n",
        "\n",
        "### Architecture\n",
        "Using latest LangGraph patterns:\n",
        "- `StateGraph` for workflow orchestration\n",
        "- `create_react_agent` for tool-calling agents\n",
        "- `MemorySaver` for persistence\n",
        "- `interrupt()` for human-in-the-loop\n",
        "- Subgraphs for complex multi-agent systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -U langchain-openai langgraph langchain-core python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import TypedDict, Annotated, Literal\n",
        "import operator\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import Command, interrupt\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Verify OpenAI API key\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise ValueError(\"Please set OPENAI_API_KEY in your environment\")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "print(\"✓ Setup complete with LangGraph + LangChain 1.0!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample HR Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample candidate data\n",
        "SAMPLE_RESUME = \"\"\"\n",
        "PRIYA SHARMA\n",
        "Senior Software Engineer\n",
        "priya.sharma@email.com | +91-98765-43210 | Bengaluru, Karnataka\n",
        "\n",
        "SUMMARY\n",
        "6+ years in full-stack development, specializing in Python, React, and AWS.\n",
        "Led teams, built microservices, mentored developers.\n",
        "\n",
        "EXPERIENCE\n",
        "Senior Software Engineer | InfoTech Solutions, Bengaluru | 2021-Present\n",
        "- Led 4-member team building microservices architecture\n",
        "- Reduced API latency by 45% through optimization\n",
        "- Implemented CI/CD pipeline (Jenkins, Docker, K8s)\n",
        "- Tech: Python, FastAPI, React, PostgreSQL, AWS\n",
        "\n",
        "Software Engineer | Digital Innovations, Pune | 2018-2020\n",
        "- Built web apps serving 500K+ users\n",
        "- Integrated payment gateways (Razorpay, PayU)\n",
        "- Tech: Python, Django, MySQL, AWS\n",
        "\n",
        "EDUCATION\n",
        "B.Tech CSE | BITS Pilani | 2016 | CGPA: 8.5/10\n",
        "\n",
        "SKILLS\n",
        "Python, JavaScript, FastAPI, React, AWS, Docker, Kubernetes, PostgreSQL\n",
        "\n",
        "CERTIFICATIONS\n",
        "AWS Solutions Architect - Associate (2022)\n",
        "\"\"\"\n",
        "\n",
        "JOB_DESCRIPTION = \"\"\"\n",
        "Senior Backend Engineer - TechCorp India, Bengaluru\n",
        "\n",
        "Requirements:\n",
        "- 5+ years backend development\n",
        "- Python/FastAPI expertise\n",
        "- AWS/cloud experience\n",
        "- Microservices architecture\n",
        "- Team leadership skills\n",
        "\n",
        "Offer: ₹28-35 LPA + equity\n",
        "\"\"\"\n",
        "\n",
        "# Mock HR Database\n",
        "HR_DATABASE = {\n",
        "    \"candidates\": {\n",
        "        \"CAN001\": {\n",
        "            \"name\": \"Priya Sharma\",\n",
        "            \"email\": \"priya.sharma@email.com\",\n",
        "            \"phone\": \"+91-98765-43210\",\n",
        "            \"position\": \"Senior Backend Engineer\",\n",
        "            \"status\": \"screening\",\n",
        "            \"resume\": SAMPLE_RESUME\n",
        "        },\n",
        "        \"CAN002\": {\n",
        "            \"name\": \"Arjun Mehta\",\n",
        "            \"email\": \"arjun.mehta@email.com\",\n",
        "            \"phone\": \"+91-98123-45678\",\n",
        "            \"position\": \"Senior Backend Engineer\",\n",
        "            \"status\": \"interview_scheduled\"\n",
        "        }\n",
        "    },\n",
        "    \"employees\": {\n",
        "        \"EMP001\": {\"name\": \"Rahul Verma\", \"role\": \"Engineering Manager\", \"email\": \"rahul.verma@techcorp.in\"},\n",
        "        \"EMP002\": {\"name\": \"Anjali Patel\", \"role\": \"HR Manager\", \"email\": \"anjali.patel@techcorp.in\"},\n",
        "        \"EMP003\": {\"name\": \"Vikram Singh\", \"role\": \"Tech Lead\", \"email\": \"vikram.singh@techcorp.in\"}\n",
        "    },\n",
        "    \"interview_slots\": [\n",
        "        {\"date\": \"2025-10-15\", \"time\": \"10:00\", \"interviewer\": \"Rahul Verma\", \"available\": True},\n",
        "        {\"date\": \"2025-10-15\", \"time\": \"14:00\", \"interviewer\": \"Vikram Singh\", \"available\": True},\n",
        "        {\"date\": \"2025-10-16\", \"time\": \"11:00\", \"interviewer\": \"Anjali Patel\", \"available\": True}\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(f\"✓ HR Database loaded: {len(HR_DATABASE['candidates'])} candidates, {len(HR_DATABASE['employees'])} employees\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 1: Basic Multi-Agent with StateGraph (No Tools, No Memory)\n",
        "\n",
        "**Pattern**: Using LangGraph's StateGraph to coordinate multiple agents\n",
        "\n",
        "**Flow**:\n",
        "1. Resume Reviewer → analyzes experience\n",
        "2. Skills Assessor → evaluates technical fit\n",
        "3. Decision Maker → final recommendation\n",
        "\n",
        "Each node is an agent with a specific role."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state using MessagesState (LangGraph pattern)\n",
        "class ScreeningState(MessagesState):\n",
        "    candidate_name: str\n",
        "    resume: str\n",
        "    job_description: str\n",
        "    resume_score: int\n",
        "    skills_score: int\n",
        "    final_decision: str\n",
        "\n",
        "# Agent 1: Resume Reviewer\n",
        "def resume_reviewer_node(state: ScreeningState):\n",
        "    \"\"\"\n",
        "    Reviews resume and assigns a score\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a Resume Reviewer at TechCorp India.\n",
        "\n",
        "Candidate: {state['candidate_name']}\n",
        "\n",
        "Resume:\n",
        "{state['resume']}\n",
        "\n",
        "Job Requirements:\n",
        "{state['job_description']}\n",
        "\n",
        "Analyze the resume and provide:\n",
        "1. Score out of 10 for experience match\n",
        "2. Key strengths (2-3 points)\n",
        "3. Concerns (if any)\n",
        "\n",
        "Start your response with \"SCORE: X/10\" then provide analysis.\n",
        "\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    # Extract score (simplified parsing)\n",
        "    score = 7  # In production, parse from response.content\n",
        "    if \"SCORE: \" in response.content:\n",
        "        try:\n",
        "            score = int(response.content.split(\"SCORE: \")[1].split(\"/\")[0])\n",
        "        except:\n",
        "            score = 7\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"[Resume Reviewer]\\n{response.content}\", name=\"resume_reviewer\")],\n",
        "        \"resume_score\": score\n",
        "    }\n",
        "\n",
        "# Agent 2: Skills Assessor\n",
        "def skills_assessor_node(state: ScreeningState):\n",
        "    \"\"\"\n",
        "    Assesses technical skills match\n",
        "    \"\"\"\n",
        "    # Get previous analysis from messages\n",
        "    previous_analysis = state['messages'][-1].content if state['messages'] else \"No previous analysis\"\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "You are a Technical Skills Assessor at TechCorp India.\n",
        "\n",
        "Candidate: {state['candidate_name']}\n",
        "Resume Score: {state.get('resume_score', 'N/A')}/10\n",
        "\n",
        "Previous Analysis:\n",
        "{previous_analysis}\n",
        "\n",
        "Resume:\n",
        "{state['resume']}\n",
        "\n",
        "Job Requirements:\n",
        "{state['job_description']}\n",
        "\n",
        "Evaluate technical skills:\n",
        "1. Python/FastAPI proficiency\n",
        "2. AWS/Cloud experience\n",
        "3. Microservices knowledge\n",
        "4. Overall technical fit score (1-10)\n",
        "\n",
        "Start with \"SCORE: X/10\" then provide detailed assessment.\n",
        "\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    # Extract score\n",
        "    score = 8\n",
        "    if \"SCORE: \" in response.content:\n",
        "        try:\n",
        "            score = int(response.content.split(\"SCORE: \")[1].split(\"/\")[0])\n",
        "        except:\n",
        "            score = 8\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"[Skills Assessor]\\n{response.content}\", name=\"skills_assessor\")],\n",
        "        \"skills_score\": score\n",
        "    }\n",
        "\n",
        "# Agent 3: Decision Maker\n",
        "def decision_maker_node(state: ScreeningState):\n",
        "    \"\"\"\n",
        "    Makes final hiring decision based on all analyses\n",
        "    \"\"\"\n",
        "    resume_score = state.get('resume_score', 0)\n",
        "    skills_score = state.get('skills_score', 0)\n",
        "    avg_score = (resume_score + skills_score) / 2\n",
        "    \n",
        "    # Get all previous messages\n",
        "    all_analyses = \"\\n\\n\".join([msg.content for msg in state['messages']])\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "You are the Hiring Manager at TechCorp India.\n",
        "\n",
        "Candidate: {state['candidate_name']}\n",
        "Resume Score: {resume_score}/10\n",
        "Skills Score: {skills_score}/10\n",
        "Average Score: {avg_score:.1f}/10\n",
        "\n",
        "All Analyses:\n",
        "{all_analyses}\n",
        "\n",
        "Make final decision:\n",
        "- If avg_score >= 7: STRONG PROCEED to interview\n",
        "- If avg_score >= 5: PROCEED with caution\n",
        "- If avg_score < 5: REJECT\n",
        "\n",
        "Provide clear recommendation with reasoning.\n",
        "\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    # Determine decision\n",
        "    if avg_score >= 7:\n",
        "        decision = \"STRONG_PROCEED\"\n",
        "    elif avg_score >= 5:\n",
        "        decision = \"PROCEED\"\n",
        "    else:\n",
        "        decision = \"REJECT\"\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"[Hiring Manager]\\n{response.content}\", name=\"hiring_manager\")],\n",
        "        \"final_decision\": decision\n",
        "    }\n",
        "\n",
        "# Build the StateGraph\n",
        "workflow = StateGraph(ScreeningState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"resume_reviewer\", resume_reviewer_node)\n",
        "workflow.add_node(\"skills_assessor\", skills_assessor_node)\n",
        "workflow.add_node(\"decision_maker\", decision_maker_node)\n",
        "\n",
        "# Add edges (sequential flow)\n",
        "workflow.add_edge(START, \"resume_reviewer\")\n",
        "workflow.add_edge(\"resume_reviewer\", \"skills_assessor\")\n",
        "workflow.add_edge(\"skills_assessor\", \"decision_maker\")\n",
        "workflow.add_edge(\"decision_maker\", END)\n",
        "\n",
        "# Compile\n",
        "lab1_app = workflow.compile()\n",
        "\n",
        "print(\"✓ Lab 1 StateGraph compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 1\n",
        "print(\"\\n🧪 Lab 1: Basic Multi-Agent with StateGraph\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "input_state = {\n",
        "    \"messages\": [],\n",
        "    \"candidate_name\": \"Priya Sharma\",\n",
        "    \"resume\": SAMPLE_RESUME,\n",
        "    \"job_description\": JOB_DESCRIPTION,\n",
        "    \"resume_score\": 0,\n",
        "    \"skills_score\": 0,\n",
        "    \"final_decision\": \"\"\n",
        "}\n",
        "\n",
        "result = lab1_app.invoke(input_state)\n",
        "\n",
        "print(\"\\nWorkflow Results:\")\n",
        "print(\"-\" * 80)\n",
        "for msg in result['messages']:\n",
        "    print(f\"\\n{msg.content}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\n✓ Final Decision: {result['final_decision']}\")\n",
        "print(f\"✓ Resume Score: {result['resume_score']}/10\")\n",
        "print(f\"✓ Skills Score: {result['skills_score']}/10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 2: Tool Calling Pattern (With Tools, No Memory)\n",
        "\n",
        "**Pattern**: LangChain 1.0 Tool Calling - agent uses tools as needed\n",
        "\n",
        "Using `create_react_agent` from LangGraph which creates a ReAct-style agent that can call tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define HR Tools\n",
        "\n",
        "@tool\n",
        "def get_candidate_info(candidate_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Get candidate information from HR database.\n",
        "    \n",
        "    Args:\n",
        "        candidate_id: Candidate ID like CAN001\n",
        "    \n",
        "    Returns:\n",
        "        JSON string with candidate details\n",
        "    \"\"\"\n",
        "    candidate = HR_DATABASE[\"candidates\"].get(candidate_id)\n",
        "    if candidate:\n",
        "        return json.dumps(candidate, indent=2)\n",
        "    return f\"Candidate {candidate_id} not found\"\n",
        "\n",
        "@tool\n",
        "def search_candidates(position: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for candidates by position.\n",
        "    \n",
        "    Args:\n",
        "        position: Job position to search for\n",
        "    \n",
        "    Returns:\n",
        "        List of matching candidates\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for cid, cand in HR_DATABASE[\"candidates\"].items():\n",
        "        if position.lower() in cand[\"position\"].lower():\n",
        "            results.append({\"id\": cid, \"name\": cand[\"name\"], \"status\": cand[\"status\"]})\n",
        "    return json.dumps(results, indent=2)\n",
        "\n",
        "@tool\n",
        "def check_interview_availability(interviewer_name: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Check available interview slots.\n",
        "    \n",
        "    Args:\n",
        "        interviewer_name: Optional filter by interviewer\n",
        "    \n",
        "    Returns:\n",
        "        Available interview slots\n",
        "    \"\"\"\n",
        "    slots = HR_DATABASE[\"interview_slots\"]\n",
        "    \n",
        "    if interviewer_name:\n",
        "        slots = [s for s in slots if interviewer_name.lower() in s[\"interviewer\"].lower()]\n",
        "    \n",
        "    available = [s for s in slots if s[\"available\"]]\n",
        "    return json.dumps(available, indent=2)\n",
        "\n",
        "@tool\n",
        "def update_candidate_status(candidate_id: str, new_status: str) -> str:\n",
        "    \"\"\"\n",
        "    Update candidate status in ATS.\n",
        "    \n",
        "    Args:\n",
        "        candidate_id: Candidate ID\n",
        "        new_status: New status (screening, interview_scheduled, offer, rejected)\n",
        "    \n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    if candidate_id in HR_DATABASE[\"candidates\"]:\n",
        "        old_status = HR_DATABASE[\"candidates\"][candidate_id][\"status\"]\n",
        "        HR_DATABASE[\"candidates\"][candidate_id][\"status\"] = new_status\n",
        "        return f\"✓ Updated {HR_DATABASE['candidates'][candidate_id]['name']}: {old_status} → {new_status}\"\n",
        "    return f\"❌ Candidate {candidate_id} not found\"\n",
        "\n",
        "@tool\n",
        "def send_email_notification(to_email: str, subject: str, message: str) -> str:\n",
        "    \"\"\"\n",
        "    Send email notification.\n",
        "    \n",
        "    Args:\n",
        "        to_email: Recipient email\n",
        "        subject: Email subject\n",
        "        message: Email body\n",
        "    \n",
        "    Returns:\n",
        "        Confirmation\n",
        "    \"\"\"\n",
        "    return f\"✓ Email sent to {to_email}\\nSubject: {subject}\\n[SIMULATED]\"\n",
        "\n",
        "# Collect all tools\n",
        "hr_tools = [\n",
        "    get_candidate_info,\n",
        "    search_candidates,\n",
        "    check_interview_availability,\n",
        "    update_candidate_status,\n",
        "    send_email_notification\n",
        "]\n",
        "\n",
        "print(\"✓ HR Tools defined:\")\n",
        "for t in hr_tools:\n",
        "    print(f\"  - {t.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ReAct agent with tools (LangGraph pattern)\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a Recruitment Coordinator at TechCorp India.\n",
        "\n",
        "Your role:\n",
        "- Search for candidates\n",
        "- Check candidate information\n",
        "- Schedule interviews\n",
        "- Update candidate status\n",
        "- Send notifications\n",
        "\n",
        "Use the available tools to complete tasks efficiently.\n",
        "Always provide clear, professional responses.\n",
        "\"\"\"\n",
        "\n",
        "# Create agent using create_react_agent\n",
        "lab2_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=hr_tools,\n",
        "    state_modifier=system_prompt\n",
        ")\n",
        "\n",
        "print(\"✓ Lab 2 ReAct Agent created with tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 2\n",
        "print(\"\\n🧪 Lab 2: Tool Calling Pattern\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Task: Schedule interview for a candidate\n",
        "task = \"\"\"\n",
        "Please help me schedule an interview for candidate CAN001 (Priya Sharma).\n",
        "\n",
        "Steps needed:\n",
        "1. Get the candidate's information\n",
        "2. Check available interview slots with Rahul Verma\n",
        "3. Update candidate status to 'interview_scheduled'\n",
        "4. Send email confirmation to the candidate\n",
        "\"\"\"\n",
        "\n",
        "result = lab2_agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=task)]}\n",
        ")\n",
        "\n",
        "print(\"\\nAgent Execution:\")\n",
        "print(\"-\" * 80)\n",
        "for msg in result['messages']:\n",
        "    if isinstance(msg, AIMessage) and msg.content:\n",
        "        print(f\"\\n🤖 Agent: {msg.content}\")\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(f\"\\n🔧 Tool ({msg.name}): {msg.content[:200]}...\" if len(msg.content) > 200 else f\"\\n🔧 Tool ({msg.name}): {msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 3: Handoffs Pattern (With Tools and Memory)\n",
        "\n",
        "**Pattern**: LangChain 1.0 Handoffs - agents pass control to each other\n",
        "\n",
        "**Features**:\n",
        "- Multiple specialized agents\n",
        "- Agents can hand off to each other\n",
        "- Persistent memory with checkpointing\n",
        "- Multi-turn conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define handoff tool to pass control between agents\n",
        "\n",
        "@tool\n",
        "def transfer_to_screening_agent() -> str:\n",
        "    \"\"\"Transfer the conversation to the Screening Agent who handles resume reviews and initial assessments.\"\"\"\n",
        "    return \"Transferring to Screening Agent...\"\n",
        "\n",
        "@tool\n",
        "def transfer_to_interview_agent() -> str:\n",
        "    \"\"\"Transfer to Interview Coordinator who handles interview scheduling and logistics.\"\"\"\n",
        "    return \"Transferring to Interview Coordinator...\"\n",
        "\n",
        "@tool\n",
        "def transfer_to_offer_agent() -> str:\n",
        "    \"\"\"Transfer to Offer Manager who handles offer preparation and negotiation.\"\"\"\n",
        "    return \"Transferring to Offer Manager...\"\n",
        "\n",
        "# Agent 1: Screening Agent\n",
        "screening_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=[get_candidate_info, search_candidates, update_candidate_status, transfer_to_interview_agent],\n",
        "    state_modifier=\"\"\"\n",
        "You are the Screening Agent at TechCorp India.\n",
        "\n",
        "Your responsibilities:\n",
        "- Review resumes and assess candidates\n",
        "- Search for candidates in the database\n",
        "- Update candidate status after screening\n",
        "\n",
        "When a candidate passes screening and needs interview scheduling, \n",
        "use transfer_to_interview_agent to hand off.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Agent 2: Interview Coordinator\n",
        "interview_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=[check_interview_availability, update_candidate_status, send_email_notification, transfer_to_offer_agent],\n",
        "    state_modifier=\"\"\"\n",
        "You are the Interview Coordinator at TechCorp India.\n",
        "\n",
        "Your responsibilities:\n",
        "- Check interview slot availability\n",
        "- Schedule interviews\n",
        "- Send interview confirmations\n",
        "- Update candidate status\n",
        "\n",
        "When interview is successful and it's time for offer, \n",
        "use transfer_to_offer_agent to hand off.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Agent 3: Offer Manager\n",
        "offer_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=[get_candidate_info, send_email_notification, update_candidate_status],\n",
        "    state_modifier=\"\"\"\n",
        "You are the Offer Manager at TechCorp India.\n",
        "\n",
        "Your responsibilities:\n",
        "- Prepare job offers\n",
        "- Send offer letters\n",
        "- Handle offer negotiations\n",
        "- Update final candidate status\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(\"✓ Three specialized agents created with handoff capabilities\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build multi-agent system with handoffs using StateGraph\n",
        "\n",
        "class MultiAgentState(MessagesState):\n",
        "    current_agent: str\n",
        "\n",
        "def route_after_agent(state: MultiAgentState) -> Literal[\"screening\", \"interview\", \"offer\", \"__end__\"]:\n",
        "    \"\"\"\n",
        "    Route based on the last tool call\n",
        "    \"\"\"\n",
        "    messages = state['messages']\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    # Check if last message was a tool call for handoff\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        tool_call = last_message.tool_calls[-1]\n",
        "        if 'transfer_to_interview' in tool_call['name']:\n",
        "            return \"interview\"\n",
        "        elif 'transfer_to_offer' in tool_call['name']:\n",
        "            return \"offer\"\n",
        "        elif 'transfer_to_screening' in tool_call['name']:\n",
        "            return \"screening\"\n",
        "    \n",
        "    # Check tool messages for handoff indicators\n",
        "    if isinstance(last_message, ToolMessage):\n",
        "        if \"Interview Coordinator\" in last_message.content:\n",
        "            return \"interview\"\n",
        "        elif \"Offer Manager\" in last_message.content:\n",
        "            return \"offer\"\n",
        "    \n",
        "    # Default: end conversation\n",
        "    return \"__end__\"\n",
        "\n",
        "# Build workflow\n",
        "handoff_workflow = StateGraph(MultiAgentState)\n",
        "\n",
        "# Add agent nodes\n",
        "handoff_workflow.add_node(\"screening\", screening_agent)\n",
        "handoff_workflow.add_node(\"interview\", interview_agent)\n",
        "handoff_workflow.add_node(\"offer\", offer_agent)\n",
        "\n",
        "# Set entry point\n",
        "handoff_workflow.add_edge(START, \"screening\")\n",
        "\n",
        "# Add conditional edges for handoffs\n",
        "handoff_workflow.add_conditional_edges(\n",
        "    \"screening\",\n",
        "    route_after_agent,\n",
        "    {\"screening\": \"screening\", \"interview\": \"interview\", \"offer\": \"offer\", \"__end__\": END}\n",
        ")\n",
        "\n",
        "handoff_workflow.add_conditional_edges(\n",
        "    \"interview\",\n",
        "    route_after_agent,\n",
        "    {\"screening\": \"screening\", \"interview\": \"interview\", \"offer\": \"offer\", \"__end__\": END}\n",
        ")\n",
        "\n",
        "handoff_workflow.add_conditional_edges(\n",
        "    \"offer\",\n",
        "    route_after_agent,\n",
        "    {\"screening\": \"screening\", \"interview\": \"interview\", \"offer\": \"offer\", \"__end__\": END}\n",
        ")\n",
        "\n",
        "# Compile with memory\n",
        "memory = MemorySaver()\n",
        "lab3_app = handoff_workflow.compile(checkpointer=memory)\n",
        "\n",
        "print(\"✓ Lab 3 Multi-Agent Handoff System compiled with memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 3: Multi-turn conversation with handoffs\n",
        "print(\"\\n🧪 Lab 3: Handoffs Pattern with Memory\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"hiring_session_001\"}}\n",
        "\n",
        "# Turn 1: Start with screening\n",
        "print(\"\\n--- Turn 1: Initial Screening Request ---\")\n",
        "response1 = lab3_app.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"Please screen candidate CAN001 for the Senior Backend Engineer position.\")],\n",
        "        \"current_agent\": \"screening\"\n",
        "    },\n",
        "    config\n",
        ")\n",
        "\n",
        "print(\"\\nLast AI Response:\")\n",
        "for msg in reversed(response1['messages']):\n",
        "    if isinstance(msg, AIMessage) and msg.content:\n",
        "        print(msg.content)\n",
        "        break\n",
        "\n",
        "# Turn 2: Continue conversation (agent remembers context)\n",
        "print(\"\\n\\n--- Turn 2: Request Interview Scheduling (Tests Memory) ---\")\n",
        "response2 = lab3_app.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"Great! Now schedule an interview for this candidate with Rahul Verma.\")]\n",
        "    },\n",
        "    config\n",
        ")\n",
        "\n",
        "print(\"\\nLast AI Response:\")\n",
        "for msg in reversed(response2['messages']):\n",
        "    if isinstance(msg, AIMessage) and msg.content:\n",
        "        print(msg.content)\n",
        "        break\n",
        "\n",
        "print(\"\\n\\n--- Conversation History ---\")\n",
        "print(f\"Total messages in thread: {len(response2['messages'])}\")\n",
        "print(\"✓ Agent maintains context across turns using checkpointing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 4: Human-in-the-Loop with Interrupts\n",
        "\n",
        "**Pattern**: LangGraph `interrupt()` for human approval\n",
        "\n",
        "**Use Case**: Offer approval workflow\n",
        "- Agent prepares offer\n",
        "- Graph interrupts for human approval\n",
        "- Human provides feedback\n",
        "- Agent continues based on approval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for HITL workflow\n",
        "class OfferApprovalState(MessagesState):\n",
        "    candidate_id: str\n",
        "    offer_details: dict\n",
        "    approval_status: str\n",
        "    human_feedback: str\n",
        "\n",
        "# Node 1: Prepare Offer\n",
        "def prepare_offer_node(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    Prepare job offer for candidate\n",
        "    \"\"\"\n",
        "    candidate = HR_DATABASE[\"candidates\"].get(state['candidate_id'], {})\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "You are an HR Compensation Specialist at TechCorp India.\n",
        "\n",
        "Prepare a job offer for:\n",
        "- Candidate: {candidate.get('name', 'Unknown')}\n",
        "- Position: {candidate.get('position', 'Unknown')}\n",
        "\n",
        "Create offer package with:\n",
        "1. Base salary: ₹30 LPA\n",
        "2. Performance bonus: Up to 20%\n",
        "3. Stock options: 1000 shares (4-year vesting)\n",
        "4. Benefits: Health insurance, learning budget ₹50k/year\n",
        "5. Start date: Within 30 days\n",
        "\n",
        "Format professionally for management review.\n",
        "\"\"\"\n",
        "    \n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    offer = {\n",
        "        \"candidate\": candidate.get('name'),\n",
        "        \"position\": candidate.get('position'),\n",
        "        \"base_salary\": \"₹30 LPA\",\n",
        "        \"bonus\": \"20%\",\n",
        "        \"equity\": \"1000 shares\",\n",
        "        \"details\": response.content\n",
        "    }\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"Offer prepared:\\n\\n{response.content}\", name=\"offer_preparer\")],\n",
        "        \"offer_details\": offer,\n",
        "        \"approval_status\": \"pending\"\n",
        "    }\n",
        "\n",
        "# Node 2: Request Human Approval (using interrupt)\n",
        "def request_approval_node(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    Interrupt workflow for human approval\n",
        "    \"\"\"\n",
        "    offer = state['offer_details']\n",
        "    \n",
        "    # This will pause the graph execution\n",
        "    approval_request = {\n",
        "        \"type\": \"offer_approval\",\n",
        "        \"candidate\": offer.get('candidate'),\n",
        "        \"offer_details\": offer,\n",
        "        \"question\": \"Do you approve this offer? (approve/reject/modify)\"\n",
        "    }\n",
        "    \n",
        "    # Use interrupt to pause for human input\n",
        "    human_response = interrupt(approval_request)\n",
        "    \n",
        "    return {\n",
        "        \"approval_status\": human_response.get(\"decision\", \"pending\"),\n",
        "        \"human_feedback\": human_response.get(\"feedback\", \"\")\n",
        "    }\n",
        "\n",
        "# Node 3: Process Approval\n",
        "def process_approval_node(state: OfferApprovalState):\n",
        "    \"\"\"\n",
        "    Take action based on approval decision\n",
        "    \"\"\"\n",
        "    status = state['approval_status']\n",
        "    feedback = state.get('human_feedback', '')\n",
        "    candidate_id = state['candidate_id']\n",
        "    \n",
        "    if status == \"approve\":\n",
        "        # Update candidate status\n",
        "        update_candidate_status.invoke({\"candidate_id\": candidate_id, \"new_status\": \"offer_sent\"})\n",
        "        \n",
        "        message = f\"\"\"\n",
        "✓ Offer APPROVED!\n",
        "\n",
        "Next steps:\n",
        "1. Generate formal offer letter\n",
        "2. Send to candidate\n",
        "3. Set follow-up reminder for 3 days\n",
        "\n",
        "Feedback: {feedback}\n",
        "\"\"\"\n",
        "    elif status == \"reject\":\n",
        "        message = f\"\"\"\n",
        "❌ Offer REJECTED\n",
        "\n",
        "Reason: {feedback}\n",
        "No further action taken.\n",
        "\"\"\"\n",
        "    else:\n",
        "        message = f\"\"\"\n",
        "⚠️ Modifications requested: {feedback}\n",
        "Sending back to compensation team for revision.\n",
        "\"\"\"\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=message, name=\"approval_processor\")]\n",
        "    }\n",
        "\n",
        "# Build HITL workflow\n",
        "hitl_workflow = StateGraph(OfferApprovalState)\n",
        "\n",
        "hitl_workflow.add_node(\"prepare_offer\", prepare_offer_node)\n",
        "hitl_workflow.add_node(\"request_approval\", request_approval_node)\n",
        "hitl_workflow.add_node(\"process_approval\", process_approval_node)\n",
        "\n",
        "hitl_workflow.add_edge(START, \"prepare_offer\")\n",
        "hitl_workflow.add_edge(\"prepare_offer\", \"request_approval\")\n",
        "hitl_workflow.add_edge(\"request_approval\", \"process_approval\")\n",
        "hitl_workflow.add_edge(\"process_approval\", END)\n",
        "\n",
        "# Compile with checkpointer (required for interrupts)\n",
        "hitl_memory = MemorySaver()\n",
        "lab4_app = hitl_workflow.compile(\n",
        "    checkpointer=hitl_memory,\n",
        "    interrupt_before=[\"request_approval\"]  # Interrupt before this node\n",
        ")\n",
        "\n",
        "print(\"✓ Lab 4 HITL workflow compiled with interrupt capability\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 4: Human-in-the-Loop\n",
        "print(\"\\n🧪 Lab 4: Human-in-the-Loop with Interrupts\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"offer_approval_001\"}}\n",
        "\n",
        "# Step 1: Start workflow (will run until interrupt)\n",
        "print(\"\\nStep 1: Preparing offer...\")\n",
        "result1 = lab4_app.invoke(\n",
        "    {\n",
        "        \"messages\": [],\n",
        "        \"candidate_id\": \"CAN001\",\n",
        "        \"offer_details\": {},\n",
        "        \"approval_status\": \"\",\n",
        "        \"human_feedback\": \"\"\n",
        "    },\n",
        "    config\n",
        ")\n",
        "\n",
        "print(\"\\nOffer Prepared:\")\n",
        "print(\"-\" * 80)\n",
        "for msg in result1['messages']:\n",
        "    if isinstance(msg, AIMessage):\n",
        "        print(msg.content)\n",
        "\n",
        "# Check if interrupted\n",
        "state_snapshot = lab4_app.get_state(config)\n",
        "print(f\"\\nWorkflow Status: {'INTERRUPTED (awaiting approval)' if state_snapshot.next else 'COMPLETED'}\")\n",
        "\n",
        "if state_snapshot.next:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"HUMAN APPROVAL REQUIRED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nSimulating human approval...\")\n",
        "    \n",
        "    # Step 2: Resume with human feedback\n",
        "    # In production, this would come from a UI/API\n",
        "    human_decision = {\n",
        "        \"decision\": \"approve\",\n",
        "        \"feedback\": \"Offer looks good. Approved by management.\"\n",
        "    }\n",
        "    \n",
        "    # Update state with human response and continue\n",
        "    result2 = lab4_app.invoke(\n",
        "        Command(\n",
        "            update={\n",
        "                \"approval_status\": human_decision[\"decision\"],\n",
        "                \"human_feedback\": human_decision[\"feedback\"]\n",
        "            }\n",
        "        ),\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    print(\"\\nFinal Result After Approval:\")\n",
        "    print(\"-\" * 80)\n",
        "    for msg in result2['messages']:\n",
        "        if isinstance(msg, AIMessage) and msg.name == \"approval_processor\":\n",
        "            print(msg.content)\n",
        "\n",
        "print(\"\\n✓ HITL workflow demonstrates proper interrupt and resume pattern!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# LAB 5: Subgraphs - Nested Agent Teams\n",
        "\n",
        "**Pattern**: LangGraph Subgraphs for complex multi-agent systems\n",
        "\n",
        "**Architecture**:\n",
        "- **Parent Graph**: Overall hiring pipeline orchestration\n",
        "- **Subgraph 1**: Screening Team (resume review → skills assessment → decision)\n",
        "- **Subgraph 2**: Interview Team (panel selection → scheduling → confirmation)\n",
        "\n",
        "Subgraphs share state with parent graph through common keys."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SUBGRAPH 1: Screening Team\n",
        "# ============================================================================\n",
        "\n",
        "class ScreeningTeamState(MessagesState):\n",
        "    candidate_id: str\n",
        "    resume: str\n",
        "    screening_decision: str  # Shared with parent\n",
        "    screening_notes: str\n",
        "\n",
        "def quick_screen_node(state: ScreeningTeamState):\n",
        "    \"\"\"Quick resume screening\"\"\"\n",
        "    prompt = f\"Screen resume quickly (PASS/FAIL only):\\n{state['resume'][:400]}...\"\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    decision = \"PASS\" if \"pass\" in response.content.lower() else \"FAIL\"\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"Quick Screen: {response.content}\", name=\"quick_screener\")],\n",
        "        \"screening_notes\": response.content\n",
        "    }\n",
        "\n",
        "def detailed_assessment_node(state: ScreeningTeamState):\n",
        "    \"\"\"Detailed skills assessment\"\"\"\n",
        "    if \"FAIL\" in state.get('screening_notes', ''):\n",
        "        return {\"screening_decision\": \"REJECT\"}\n",
        "    \n",
        "    prompt = f\"Assess technical skills (score 1-10):\\n{state['resume'][:400]}...\"\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"Skills Assessment: {response.content}\", name=\"skills_assessor\")]\n",
        "    }\n",
        "\n",
        "def screening_decision_node(state: ScreeningTeamState):\n",
        "    \"\"\"Final screening decision\"\"\"\n",
        "    # Analyze all messages in screening team\n",
        "    notes = \"\\n\".join([m.content for m in state['messages'] if isinstance(m, AIMessage)])\n",
        "    \n",
        "    # Simple decision logic\n",
        "    if \"FAIL\" in notes or \"fail\" in notes.lower():\n",
        "        decision = \"REJECT\"\n",
        "    elif any(word in notes.lower() for word in [\"strong\", \"excellent\", \"pass\"]):\n",
        "        decision = \"PROCEED_TO_INTERVIEW\"\n",
        "    else:\n",
        "        decision = \"PROCEED_WITH_CAUTION\"\n",
        "    \n",
        "    return {\n",
        "        \"screening_decision\": decision,\n",
        "        \"messages\": [AIMessage(content=f\"Screening Decision: {decision}\", name=\"decision_maker\")]\n",
        "    }\n",
        "\n",
        "# Build screening subgraph\n",
        "screening_team = StateGraph(ScreeningTeamState)\n",
        "screening_team.add_node(\"quick_screen\", quick_screen_node)\n",
        "screening_team.add_node(\"detailed_assessment\", detailed_assessment_node)\n",
        "screening_team.add_node(\"make_decision\", screening_decision_node)\n",
        "\n",
        "screening_team.add_edge(START, \"quick_screen\")\n",
        "screening_team.add_edge(\"quick_screen\", \"detailed_assessment\")\n",
        "screening_team.add_edge(\"detailed_assessment\", \"make_decision\")\n",
        "screening_team.add_edge(\"make_decision\", END)\n",
        "\n",
        "screening_subgraph = screening_team.compile()\n",
        "\n",
        "print(\"✓ Screening Team Subgraph compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SUBGRAPH 2: Interview Team  \n",
        "# ============================================================================\n",
        "\n",
        "class InterviewTeamState(MessagesState):\n",
        "    candidate_id: str\n",
        "    candidate_name: str\n",
        "    interview_scheduled: bool  # Shared with parent\n",
        "    interview_details: str  # Shared with parent\n",
        "\n",
        "def select_panel_node(state: InterviewTeamState):\n",
        "    \"\"\"Select interview panel\"\"\"\n",
        "    panel = \"Rahul Verma (Engineering Manager), Vikram Singh (Tech Lead)\"\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=f\"Panel selected: {panel}\", name=\"panel_selector\")]\n",
        "    }\n",
        "\n",
        "def schedule_interview_node(state: InterviewTeamState):\n",
        "    \"\"\"Schedule interview\"\"\"\n",
        "    # Use the tool to check availability\n",
        "    slots = check_interview_availability.invoke({\"interviewer_name\": \"Rahul\"})\n",
        "    \n",
        "    details = f\"\"\"\n",
        "Interview Scheduled for {state.get('candidate_name', 'Candidate')}\n",
        "Date: 2025-10-15\n",
        "Time: 10:00 AM IST  \n",
        "Duration: 90 minutes\n",
        "Panel: Rahul Verma, Vikram Singh\n",
        "Meeting Link: https://meet.google.com/abc-defg-hij\n",
        "\"\"\"\n",
        "    \n",
        "    return {\n",
        "        \"interview_scheduled\": True,\n",
        "        \"interview_details\": details,\n",
        "        \"messages\": [AIMessage(content=f\"Interview scheduled:\\n{details}\", name=\"scheduler\")]\n",
        "    }\n",
        "\n",
        "def send_confirmations_node(state: InterviewTeamState):\n",
        "    \"\"\"Send interview confirmations\"\"\"\n",
        "    candidate = HR_DATABASE[\"candidates\"].get(state['candidate_id'], {})\n",
        "    \n",
        "    # Send emails (simulated)\n",
        "    send_email_notification.invoke({\n",
        "        \"to_email\": candidate.get('email', ''),\n",
        "        \"subject\": \"Interview Invitation - TechCorp India\",\n",
        "        \"message\": state['interview_details']\n",
        "    })\n",
        "    \n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=\"Confirmations sent to candidate and panel\", name=\"notifier\")]\n",
        "    }\n",
        "\n",
        "# Build interview subgraph\n",
        "interview_team = StateGraph(InterviewTeamState)\n",
        "interview_team.add_node(\"select_panel\", select_panel_node)\n",
        "interview_team.add_node(\"schedule\", schedule_interview_node)\n",
        "interview_team.add_node(\"send_confirmations\", send_confirmations_node)\n",
        "\n",
        "interview_team.add_edge(START, \"select_panel\")\n",
        "interview_team.add_edge(\"select_panel\", \"schedule\")\n",
        "interview_team.add_edge(\"schedule\", \"send_confirmations\")\n",
        "interview_team.add_edge(\"send_confirmations\", END)\n",
        "\n",
        "interview_subgraph = interview_team.compile()\n",
        "\n",
        "print(\"✓ Interview Team Subgraph compiled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PARENT GRAPH: Complete Hiring Pipeline\n",
        "# ============================================================================\n",
        "\n",
        "class HiringPipelineState(MessagesState):\n",
        "    candidate_id: str\n",
        "    candidate_name: str\n",
        "    resume: str\n",
        "    screening_decision: str  # Shared with screening subgraph\n",
        "    screening_notes: str\n",
        "    interview_scheduled: bool  # Shared with interview subgraph\n",
        "    interview_details: str  # Shared with interview subgraph\n",
        "    pipeline_status: str\n",
        "\n",
        "def initialize_pipeline_node(state: HiringPipelineState):\n",
        "    \"\"\"Initialize the hiring pipeline\"\"\"\n",
        "    candidate = HR_DATABASE[\"candidates\"].get(state['candidate_id'], {})\n",
        "    \n",
        "    return {\n",
        "        \"candidate_name\": candidate.get('name', 'Unknown'),\n",
        "        \"resume\": candidate.get('resume', SAMPLE_RESUME),\n",
        "        \"messages\": [AIMessage(content=f\"Starting pipeline for {candidate.get('name')}\", name=\"coordinator\")],\n",
        "        \"pipeline_status\": \"initialized\"\n",
        "    }\n",
        "\n",
        "def route_after_screening(state: HiringPipelineState) -> Literal[\"interview_team\", \"reject\"]:\n",
        "    \"\"\"Route based on screening decision\"\"\"\n",
        "    decision = state.get('screening_decision', '')\n",
        "    \n",
        "    if 'PROCEED' in decision:\n",
        "        return \"interview_team\"\n",
        "    return \"reject\"\n",
        "\n",
        "def reject_candidate_node(state: HiringPipelineState):\n",
        "    \"\"\"Handle candidate rejection\"\"\"\n",
        "    return {\n",
        "        \"pipeline_status\": \"rejected\",\n",
        "        \"messages\": [AIMessage(\n",
        "            content=f\"Candidate {state['candidate_name']} rejected at screening.\\nReason: {state['screening_decision']}\",\n",
        "            name=\"coordinator\"\n",
        "        )]\n",
        "    }\n",
        "\n",
        "def finalize_pipeline_node(state: HiringPipelineState):\n",
        "    \"\"\"Finalize the pipeline\"\"\"\n",
        "    if state.get('interview_scheduled'):\n",
        "        status = \"interview_scheduled\"\n",
        "        message = f\"\"\"\n",
        "✓ Pipeline Complete for {state['candidate_name']}\n",
        "\n",
        "Screening: {state['screening_decision']}\n",
        "Interview: {state['interview_details']}\n",
        "\n",
        "Status: Ready for interview\n",
        "\"\"\"\n",
        "    else:\n",
        "        status = state.get('pipeline_status', 'completed')\n",
        "        message = f\"Pipeline completed with status: {status}\"\n",
        "    \n",
        "    return {\n",
        "        \"pipeline_status\": status,\n",
        "        \"messages\": [AIMessage(content=message, name=\"coordinator\")]\n",
        "    }\n",
        "\n",
        "# Build parent graph\n",
        "parent_graph = StateGraph(HiringPipelineState)\n",
        "\n",
        "# Add nodes (including subgraphs as nodes!)\n",
        "parent_graph.add_node(\"initialize\", initialize_pipeline_node)\n",
        "parent_graph.add_node(\"screening_team\", screening_subgraph)  # SUBGRAPH!\n",
        "parent_graph.add_node(\"interview_team\", interview_subgraph)  # SUBGRAPH!\n",
        "parent_graph.add_node(\"reject\", reject_candidate_node)\n",
        "parent_graph.add_node(\"finalize\", finalize_pipeline_node)\n",
        "\n",
        "# Add edges\n",
        "parent_graph.add_edge(START, \"initialize\")\n",
        "parent_graph.add_edge(\"initialize\", \"screening_team\")\n",
        "\n",
        "# Conditional routing after screening\n",
        "parent_graph.add_conditional_edges(\n",
        "    \"screening_team\",\n",
        "    route_after_screening,\n",
        "    {\"interview_team\": \"interview_team\", \"reject\": \"reject\"}\n",
        ")\n",
        "\n",
        "parent_graph.add_edge(\"interview_team\", \"finalize\")\n",
        "parent_graph.add_edge(\"reject\", \"finalize\")\n",
        "parent_graph.add_edge(\"finalize\", END)\n",
        "\n",
        "# Compile\n",
        "lab5_app = parent_graph.compile()\n",
        "\n",
        "print(\"✓ Lab 5 Complete Pipeline with Subgraphs compiled!\")\n",
        "print(\"  - Parent Graph: Hiring Pipeline Orchestrator\")\n",
        "print(\"  - Subgraph 1: Screening Team (3 agents)\")\n",
        "print(\"  - Subgraph 2: Interview Team (3 agents)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Lab 5: Complete Pipeline with Subgraphs\n",
        "print(\"\\n🧪 Lab 5: Subgraphs - Complete Hiring Pipeline\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Run complete pipeline\n",
        "result = lab5_app.invoke(\n",
        "    {\n",
        "        \"messages\": [],\n",
        "        \"candidate_id\": \"CAN001\",\n",
        "        \"candidate_name\": \"\",\n",
        "        \"resume\": \"\",\n",
        "        \"screening_decision\": \"\",\n",
        "        \"screening_notes\": \"\",\n",
        "        \"interview_scheduled\": False,\n",
        "        \"interview_details\": \"\",\n",
        "        \"pipeline_status\": \"\"\n",
        "    },\n",
        "    {\"configurable\": {\"thread_id\": \"pipeline_001\"}}\n",
        ")\n",
        "\n",
        "print(\"\\n📊 Pipeline Execution Flow:\")\n",
        "print(\"-\" * 80)\n",
        "for i, msg in enumerate(result['messages'], 1):\n",
        "    if isinstance(msg, AIMessage):\n",
        "        agent_name = msg.name if hasattr(msg, 'name') else 'Unknown'\n",
        "        print(f\"\\n{i}. [{agent_name}]\")\n",
        "        print(f\"   {msg.content[:200]}...\" if len(msg.content) > 200 else f\"   {msg.content}\")\n",
        "\n",
        "print(\"\\n\\n📈 Final Pipeline State:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"Candidate: {result['candidate_name']}\")\n",
        "print(f\"Screening Decision: {result['screening_decision']}\")\n",
        "print(f\"Interview Scheduled: {result['interview_scheduled']}\")\n",
        "print(f\"Pipeline Status: {result['pipeline_status']}\")\n",
        "\n",
        "print(\"\\n✓ Demonstrates parent graph coordinating multiple specialized subgraph teams!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 🎯 Summary: LangGraph + LangChain 1.0 Patterns\n",
        "\n",
        "### Lab 1: Basic Multi-Agent with StateGraph ✅\n",
        "- Pure LangGraph `StateGraph` orchestration\n",
        "- Sequential agent coordination\n",
        "- State sharing between agents\n",
        "- No external dependencies\n",
        "\n",
        "### Lab 2: Tool Calling Pattern ✅\n",
        "- `create_react_agent` for tool-enabled agents\n",
        "- ReAct-style reasoning with tools\n",
        "- Dynamic tool selection by LLM\n",
        "- Real HR operations simulation\n",
        "\n",
        "### Lab 3: Handoffs Pattern with Memory ✅\n",
        "- Multiple specialized agents\n",
        "- Agent-to-agent handoffs\n",
        "- `MemorySaver` for persistent state\n",
        "- Multi-turn conversation context\n",
        "- Thread-based checkpointing\n",
        "\n",
        "### Lab 4: Human-in-the-Loop ✅\n",
        "- LangGraph `interrupt()` mechanism\n",
        "- Workflow pause for human input\n",
        "- `interrupt_before` configuration\n",
        "- Resume execution with `Command`\n",
        "- Production-ready approval patterns\n",
        "\n",
        "### Lab 5: Subgraphs (Advanced) ✅\n",
        "- Nested graph architecture\n",
        "- Subgraphs as nodes in parent graph\n",
        "- State sharing through common keys\n",
        "- Complex multi-team coordination\n",
        "- Scalable agent system design\n",
        "\n",
        "## 🚀 Key Technologies\n",
        "\n",
        "- **LangGraph**: StateGraph, create_react_agent, MemorySaver, interrupt()\n",
        "- **LangChain 1.0**: Tool calling, message types, state management\n",
        "- **OpenAI**: GPT-4o for agent reasoning\n",
        "- **Patterns**: Tool calling, handoffs, HITL, subgraphs\n",
        "\n",
        "## 📚 References\n",
        "\n",
        "- [LangChain Multi-Agent](https://docs.langchain.com/oss/python/langchain/multi-agent)\n",
        "- [LangGraph Subgraphs](https://docs.langchain.com/oss/python/langgraph/use-subgraphs)\n",
        "- [Human-in-the-Loop](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "\n",
        "All labs use **modern LangGraph and LangChain 1.0 patterns** as documented! 🎉"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
