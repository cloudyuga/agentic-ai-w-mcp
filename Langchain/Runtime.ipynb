{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.0 Runtime Examples\n",
    "\n",
    "This notebook demonstrates using Runtime in **Tools** and **Middleware** based on official LangChain 1.0 documentation.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Context**: Static information like user ID, DB connections, API keys\n",
    "- **Store**: Long-term memory for persisting data across conversations\n",
    "- **ToolRuntime**: Access to runtime information inside tools\n",
    "- **Middleware**: Pre/post model hooks and dynamic prompts\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "pip install langchain langgraph langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.messages import AnyMessage\n",
    "from langchain.agents.middleware import (\n",
    "    dynamic_prompt, \n",
    "    before_model, \n",
    "    after_model,\n",
    "    ModelRequest\n",
    ")\n",
    "from langgraph.runtime import Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Context Schema\n",
    "\n",
    "Using dataclass to define the context structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Context schema with user information\"\"\"\n",
    "    user_id: str\n",
    "    user_name: str\n",
    "    database_url: str\n",
    "    organization_id: str\n",
    "    api_key: str\n",
    "\n",
    "# Create a sample context\n",
    "sample_context = Context(\n",
    "    user_id=\"user_12345\",\n",
    "    user_name=\"John Smith\",\n",
    "    database_url=\"postgresql://localhost:5432/mydb\",\n",
    "    organization_id=\"org_789\",\n",
    "    api_key=\"sk-abc123xyz\"\n",
    ")\n",
    "\n",
    "print(\"Context Schema:\")\n",
    "print(sample_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Example: Simple Context Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimpleContext:\n",
    "    user_name: str\n",
    "\n",
    "# This is a minimal example from the docs\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4\",\n",
    "    tools=[],\n",
    "    context_schema=SimpleContext  \n",
    ")\n",
    "\n",
    "# Invoke with context\n",
    "# result = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "#     context=SimpleContext(user_name=\"John Smith\")  \n",
    "# )\n",
    "\n",
    "print(\"Basic agent with simple context created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tools with ToolRuntime\n",
    "\n",
    "### Example 1: Accessing Context in Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_user_name(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Get the current user's name from context.\"\"\"\n",
    "    user_name = runtime.context.user_name\n",
    "    return f\"The user's name is {user_name}\"\n",
    "\n",
    "@tool\n",
    "def get_database_connection(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Get database connection information from context.\"\"\"\n",
    "    db_url = runtime.context.database_url\n",
    "    org_id = runtime.context.organization_id\n",
    "    return f\"Database URL: {db_url}, Organization: {org_id}\"\n",
    "\n",
    "print(\"Context access tools created!\")\n",
    "print(f\"Tool 1: {get_user_name.name}\")\n",
    "print(f\"Tool 2: {get_database_connection.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Using Store for Long-term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Fetch the user's email preferences from the store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    # Default preferences\n",
    "    preferences: str = \"The user prefers you to write a brief and polite email.\"\n",
    "    \n",
    "    # Try to fetch from store if available\n",
    "    if runtime.store:\n",
    "        if memory := runtime.store.get((\"users\",), user_id):\n",
    "            preferences = memory.value[\"preferences\"]\n",
    "    \n",
    "    return preferences\n",
    "\n",
    "@tool\n",
    "def save_user_preferences(preferences: str, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save user preferences to the store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    if runtime.store:\n",
    "        runtime.store.put(\n",
    "            (\"users\",), \n",
    "            user_id, \n",
    "            {\"preferences\": preferences}\n",
    "        )\n",
    "        return f\"Saved preferences for user {user_id}\"\n",
    "    \n",
    "    return \"Store not available\"\n",
    "\n",
    "print(\"Store-based tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Tool with Multiple Store Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save_conversation_summary(summary: str, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Save a conversation summary to long-term memory.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    if runtime.store:\n",
    "        namespace = (\"conversations\", user_id)\n",
    "        key = f\"summary_{runtime.context.organization_id}\"\n",
    "        \n",
    "        runtime.store.put(namespace, key, {\n",
    "            \"summary\": summary,\n",
    "            \"user_name\": runtime.context.user_name,\n",
    "            \"timestamp\": \"2025-10-21\"\n",
    "        })\n",
    "        \n",
    "        return f\"Saved summary for {runtime.context.user_name}\"\n",
    "    \n",
    "    return \"Store not available\"\n",
    "\n",
    "@tool\n",
    "def retrieve_past_summaries(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve past conversation summaries from long-term memory.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    if runtime.store:\n",
    "        namespace = (\"conversations\", user_id)\n",
    "        items = runtime.store.search(namespace, limit=5)\n",
    "        \n",
    "        summaries = [item.value.get(\"summary\") for item in items]\n",
    "        return f\"Found {len(summaries)} summaries: {summaries}\"\n",
    "    \n",
    "    return \"Store not available\"\n",
    "\n",
    "print(\"Conversation tools created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Tool with API Key Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def call_external_api(endpoint: str, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Call an external API using the API key from context.\"\"\"\n",
    "    api_key = runtime.context.api_key\n",
    "    org_id = runtime.context.organization_id\n",
    "    user_name = runtime.context.user_name\n",
    "    \n",
    "    # Simulate API call\n",
    "    print(f\"Calling API: {endpoint}\")\n",
    "    print(f\"Organization: {org_id}\")\n",
    "    print(f\"API Key: {api_key[:8]}...\")\n",
    "    print(f\"User: {user_name}\")\n",
    "    \n",
    "    return f\"API call to {endpoint} successful for {user_name}\"\n",
    "\n",
    "print(\"API tool created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Middleware: Dynamic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Create a dynamic system prompt based on user context.\"\"\"\n",
    "    user_name = request.runtime.context.user_name\n",
    "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "    return system_prompt\n",
    "\n",
    "@dynamic_prompt\n",
    "def personalized_greeting_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Add personalized greeting based on organization.\"\"\"\n",
    "    user_name = request.runtime.context.user_name\n",
    "    org_id = request.runtime.context.organization_id\n",
    "    return f\"Hello {user_name} from {org_id}! How can I help you today?\"\n",
    "\n",
    "print(\"Dynamic prompt functions created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Middleware: Before Model Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"Log information before the model is called.\"\"\"\n",
    "    user_name = runtime.context.user_name\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"BEFORE MODEL: Processing request for user: {user_name} (ID: {user_id})\")\n",
    "    print(f\"Message count: {len(state.get('messages', []))}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "@before_model\n",
    "def check_rate_limit(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"Check rate limits before calling the model.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    if runtime.store:\n",
    "        namespace = (\"rate_limits\", user_id)\n",
    "        rate_data = runtime.store.get(namespace, \"requests\")\n",
    "        \n",
    "        if rate_data:\n",
    "            count = rate_data.value.get(\"count\", 0)\n",
    "            if count > 100:\n",
    "                raise Exception(f\"Rate limit exceeded for user {user_id}\")\n",
    "            runtime.store.put(namespace, \"requests\", {\"count\": count + 1})\n",
    "        else:\n",
    "            runtime.store.put(namespace, \"requests\", {\"count\": 1})\n",
    "    \n",
    "    print(f\"Rate limit check passed for user {user_id}\")\n",
    "    return None\n",
    "\n",
    "print(\"Before model hooks created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Middleware: After Model Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@after_model\n",
    "def log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"Log information after the model generates a response.\"\"\"\n",
    "    user_name = runtime.context.user_name\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"AFTER MODEL: Completed request for user: {user_name}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "@after_model\n",
    "def save_response_to_store(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    \"\"\"Save the model response to long-term memory.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    \n",
    "    if runtime.store:\n",
    "        namespace = (\"model_responses\", user_id)\n",
    "        messages = state.get(\"messages\", [])\n",
    "        \n",
    "        if messages:\n",
    "            last_message = str(messages[-1])[:200]\n",
    "            runtime.store.put(namespace, \"last_response\", {\n",
    "                \"content\": last_message,\n",
    "                \"timestamp\": \"2025-10-21\",\n",
    "                \"user_name\": runtime.context.user_name\n",
    "            })\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"After model hooks created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Example: Agent with All Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "all_tools = [\n",
    "    get_user_name,\n",
    "    get_database_connection,\n",
    "    fetch_user_email_preferences,\n",
    "    save_user_preferences,\n",
    "    save_conversation_summary,\n",
    "    retrieve_past_summaries,\n",
    "    call_external_api\n",
    "]\n",
    "\n",
    "# Collect all middleware\n",
    "all_middleware = [\n",
    "    dynamic_system_prompt,\n",
    "    log_before_model,\n",
    "    check_rate_limit,\n",
    "    log_after_model,\n",
    "    save_response_to_store\n",
    "]\n",
    "\n",
    "# Create the agent\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4\",\n",
    "    tools=all_tools,\n",
    "    middleware=all_middleware,\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "print(\"Complete agent with all tools and middleware created!\")\n",
    "print(f\"Tools: {len(all_tools)}\")\n",
    "print(f\"Middleware: {len(all_middleware)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Invoke the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key first\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Create context\n",
    "context = Context(\n",
    "    user_id=\"user_12345\",\n",
    "    user_name=\"John Smith\",\n",
    "    database_url=\"postgresql://localhost:5432/mydb\",\n",
    "    organization_id=\"org_789\",\n",
    "    api_key=\"sk-abc123xyz\"\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "# result = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name and can you check my preferences?\"}]},\n",
    "#     context=context\n",
    "# )\n",
    "\n",
    "# print(\"\\nAgent Response:\")\n",
    "# print(result)\n",
    "\n",
    "print(\"Agent is ready to invoke!\")\n",
    "print(\"Uncomment the code above and set your OpenAI API key to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Example: Different Contexts for Different Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User 1\n",
    "context_user1 = Context(\n",
    "    user_id=\"user_001\",\n",
    "    user_name=\"Alice Johnson\",\n",
    "    database_url=\"postgresql://localhost:5432/alice_db\",\n",
    "    organization_id=\"org_alpha\",\n",
    "    api_key=\"sk-alice123\"\n",
    ")\n",
    "\n",
    "# User 2\n",
    "context_user2 = Context(\n",
    "    user_id=\"user_002\",\n",
    "    user_name=\"Bob Williams\",\n",
    "    database_url=\"postgresql://localhost:5432/bob_db\",\n",
    "    organization_id=\"org_beta\",\n",
    "    api_key=\"sk-bob456\"\n",
    ")\n",
    "\n",
    "# Same agent, different contexts\n",
    "# result1 = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "#     context=context_user1\n",
    "# )\n",
    "\n",
    "# result2 = agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "#     context=context_user2\n",
    "# )\n",
    "\n",
    "print(\"Multiple user contexts created!\")\n",
    "print(f\"User 1: {context_user1.user_name}\")\n",
    "print(f\"User 2: {context_user2.user_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Minimal Working Example from Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the exact example from the docs\n",
    "@dataclass\n",
    "class MinimalContext:\n",
    "    user_name: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def minimal_system_prompt(request: ModelRequest) -> str:\n",
    "    user_name = request.runtime.context.user_name\n",
    "    return f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "\n",
    "@before_model\n",
    "def minimal_log_before(state: AgentState, runtime: Runtime[MinimalContext]) -> dict | None:\n",
    "    print(f\"Processing request for user: {runtime.context.user_name}\")\n",
    "    return None\n",
    "\n",
    "@after_model\n",
    "def minimal_log_after(state: AgentState, runtime: Runtime[MinimalContext]) -> dict | None:\n",
    "    print(f\"Completed request for user: {runtime.context.user_name}\")\n",
    "    return None\n",
    "\n",
    "minimal_agent = create_agent(\n",
    "    model=\"openai:gpt-4\",\n",
    "    tools=[],\n",
    "    middleware=[minimal_system_prompt, minimal_log_before, minimal_log_after],\n",
    "    context_schema=MinimalContext\n",
    ")\n",
    "\n",
    "# Invoke\n",
    "# result = minimal_agent.invoke(\n",
    "#     {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "#     context=MinimalContext(user_name=\"John Smith\")\n",
    "# )\n",
    "\n",
    "print(\"Minimal example from docs created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated LangChain 1.0 Runtime patterns from the official documentation:\n",
    "\n",
    "### **Tools with ToolRuntime:**\n",
    "```python\n",
    "@tool\n",
    "def my_tool(runtime: ToolRuntime[Context]) -> str:\n",
    "    user_id = runtime.context.user_id\n",
    "    if runtime.store:\n",
    "        data = runtime.store.get(namespace, key)\n",
    "    return result\n",
    "```\n",
    "\n",
    "### **Middleware Decorators:**\n",
    "```python\n",
    "@dynamic_prompt\n",
    "def my_prompt(request: ModelRequest) -> str:\n",
    "    return f\"Hello {request.runtime.context.user_name}\"\n",
    "\n",
    "@before_model\n",
    "def before_hook(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    # Pre-processing\n",
    "    return None\n",
    "\n",
    "@after_model\n",
    "def after_hook(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
    "    # Post-processing\n",
    "    return None\n",
    "```\n",
    "\n",
    "### **Agent Creation:**\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4\",\n",
    "    tools=[...],\n",
    "    middleware=[...],\n",
    "    context_schema=Context\n",
    ")\n",
    "```\n",
    "\n",
    "### **Invocation:**\n",
    "```python\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]},\n",
    "    context=Context(...)\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
