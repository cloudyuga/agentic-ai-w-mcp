{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_4N1cZ4ZXS2"
      },
      "source": [
        "# Custom State with Memory - LangChain 1.0\n",
        "\n",
        "Advanced pattern: Custom agent state that persists across conversation.\n",
        "\n",
        "**Features:**\n",
        "- Custom state schema with employee data\n",
        "- State persists across conversation\n",
        "- Persistent conversation memory\n",
        "- Production-ready pattern\n",
        "- Gradio interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hHjLMZkVZXS4",
        "outputId": "da92ed05-1b5c-45d8-d556-cc0768fb64b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.0rc2)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.0a4)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.0rc1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (6.0.0.dev0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0rc3 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.0rc3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt==0.7.0rc1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.7.0rc1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==2.0.0-dev.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.0.dev0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.0-dev.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0rc3->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0rc3->langchain) (0.4.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0rc3->langchain) (8.5.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0rc3->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0rc3->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0rc3->langchain) (0.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install --pre -U langchain langchain-openai langgraph gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gbUfaH9xZXS5"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I_v0SPwPZXS5",
        "outputId": "64cf48ea-b5fa-4053-bbe0-b0e7de0f09fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tools created!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "\n",
        "# Employee database\n",
        "EMPLOYEE_DB = {\n",
        "    \"101\": {\"name\": \"Priya Sharma\", \"department\": \"Engineering\", \"leave\": 12},\n",
        "    \"102\": {\"name\": \"Rahul Verma\", \"department\": \"Engineering\", \"leave\": 8},\n",
        "    \"103\": {\"name\": \"Anjali Patel\", \"department\": \"HR\", \"leave\": 15},\n",
        "}\n",
        "\n",
        "# Global state for current session (in production, use proper state management)\n",
        "current_session = {\n",
        "    \"employee_id\": None,\n",
        "    \"employee_name\": None,\n",
        "    \"department\": None,\n",
        "    \"leave_balance\": 0\n",
        "}\n",
        "\n",
        "# Tools that work with session state\n",
        "@tool\n",
        "def set_employee_context(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Set the current employee context for the session.\"\"\"\n",
        "    if employee_id in EMPLOYEE_DB:\n",
        "        emp = EMPLOYEE_DB[employee_id]\n",
        "        current_session[\"employee_id\"] = employee_id\n",
        "        current_session[\"employee_name\"] = emp[\"name\"]\n",
        "        current_session[\"department\"] = emp[\"department\"]\n",
        "        current_session[\"leave_balance\"] = emp[\"leave\"]\n",
        "        return f\"✅ Context set for {emp['name']} (ID: {employee_id}, Department: {emp['department']})\"\n",
        "    return f\"❌ Employee ID {employee_id} not found.\"\n",
        "\n",
        "@tool\n",
        "def get_my_info() -> str:\n",
        "    \"\"\"Get information about the current employee.\"\"\"\n",
        "    if not current_session[\"employee_id\"]:\n",
        "        return \"⚠️ No employee context set. Please identify yourself first.\"\n",
        "\n",
        "    return f\"\"\"Your Information:\n",
        "📋 Name: {current_session['employee_name']}\n",
        "🆔 ID: {current_session['employee_id']}\n",
        "🏢 Department: {current_session['department']}\n",
        "🌴 Leave Balance: {current_session['leave_balance']} days\"\"\"\n",
        "\n",
        "@tool\n",
        "def check_leave_balance() -> str:\n",
        "    \"\"\"Check leave balance for current employee.\"\"\"\n",
        "    if not current_session[\"employee_id\"]:\n",
        "        return \"⚠️ No employee context set. Please identify yourself first.\"\n",
        "\n",
        "    name = current_session['employee_name']\n",
        "    leave = current_session['leave_balance']\n",
        "    return f\"{name}, you have {leave} days of leave available.\"\n",
        "\n",
        "@tool\n",
        "def request_leave(days: Annotated[int, \"Number of days\"]) -> str:\n",
        "    \"\"\"Request leave days. Checks against available balance.\"\"\"\n",
        "    if not current_session[\"employee_id\"]:\n",
        "        return \"⚠️ No employee context set. Please identify yourself first.\"\n",
        "\n",
        "    name = current_session['employee_name']\n",
        "    current_leave = current_session['leave_balance']\n",
        "\n",
        "    if days > current_leave:\n",
        "        return f\"❌ Sorry {name}, you only have {current_leave} days available. Cannot approve {days} days.\"\n",
        "\n",
        "    return f\"✅ Leave request submitted for {name}: {days} days. Pending manager approval.\"\n",
        "\n",
        "print(\"✅ Tools created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zv22Wd1sZXS6",
        "outputId": "cb3c91cb-3bca-4542-8fa5-2b5fc55fe04b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Employee agent created!\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "# Create agent with memory\n",
        "employee_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[set_employee_context, get_my_info, check_leave_balance, request_leave],\n",
        "    checkpointer=InMemorySaver(),\n",
        "    system_prompt=\"\"\"You are a helpful HR assistant.\n",
        "\n",
        "    When an employee introduces themselves or mentions their employee ID,\n",
        "    use the set_employee_context tool to set up their session.\n",
        "\n",
        "    After that, you can use other tools to help them without needing their ID again.\n",
        "\n",
        "    Be professional and helpful.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"✅ Employee agent created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5jTilVfFZXS6",
        "outputId": "e62e761b-4481-4646-a6e0-6f266fe94f91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Testing Employee Agent with Context\n",
            "======================================================================\n",
            "\n",
            "User: Hi, I'm employee 101, Priya Sharma\n",
            "Agent: Hello Priya Sharma! How can I assist you today?\n",
            "\n",
            "User: How much leave do I have?\n",
            "Agent: You have 12 days of leave available. If you need assistance with anything else, feel free to ask!\n",
            "\n",
            "User: I want to apply for 5 days of leave\n",
            "Agent: Your leave request for 5 days has been submitted and is pending manager approval. If you need further assistance or have any questions, feel free to let me know!\n",
            "\n",
            "User: Show me my full information\n",
            "Agent: Here is your full information:\n",
            "\n",
            "- **Name:** Priya Sharma\n",
            "- **Employee ID:** 101\n",
            "- **Department:** Engineering\n",
            "- **Leave Balance:** 12 days\n",
            "\n",
            "If there’s anything else you need, just let me know!\n",
            "\n",
            "✅ Agent maintained context throughout conversation!\n"
          ]
        }
      ],
      "source": [
        "# Test the agent\n",
        "config = {\"configurable\": {\"thread_id\": \"employee_session_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Employee Agent with Context\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Turn 1: Employee introduces themselves\n",
        "result = employee_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, I'm employee 101, Priya Sharma\"}]},\n",
        "    config\n",
        ")\n",
        "print(\"User: Hi, I'm employee 101, Priya Sharma\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\\n\")\n",
        "\n",
        "# Turn 2: Ask about leave\n",
        "result = employee_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"How much leave do I have?\"}]},\n",
        "    config\n",
        ")\n",
        "print(\"User: How much leave do I have?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\\n\")\n",
        "\n",
        "# Turn 3: Apply for leave\n",
        "result = employee_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"I want to apply for 5 days of leave\"}]},\n",
        "    config\n",
        ")\n",
        "print(\"User: I want to apply for 5 days of leave\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\\n\")\n",
        "\n",
        "# Turn 4: Check info\n",
        "result = employee_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Show me my full information\"}]},\n",
        "    config\n",
        ")\n",
        "print(\"User: Show me my full information\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n✅ Agent maintained context throughout conversation!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8JtigIojZXS6",
        "outputId": "72228148-da80-4c52-a94c-9025003912b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session ID: e77893e1-1c09-49ee-aace-945685ec8baf\n",
            "\n",
            "Available employees:\n",
            "  - 101: Priya Sharma (Engineering, 12 days leave)\n",
            "  - 102: Rahul Verma (Engineering, 8 days leave)\n",
            "  - 103: Anjali Patel (HR, 15 days leave)\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://072a2ad20ee59d5751.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://072a2ad20ee59d5751.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import uuid\n",
        "\n",
        "# Session management\n",
        "session_id = str(uuid.uuid4())\n",
        "\n",
        "def reset_session():\n",
        "    \"\"\"Reset the current session.\"\"\"\n",
        "    global current_session\n",
        "    current_session = {\n",
        "        \"employee_id\": None,\n",
        "        \"employee_name\": None,\n",
        "        \"department\": None,\n",
        "        \"leave_balance\": 0\n",
        "    }\n",
        "    return \"Session reset. Please introduce yourself again.\"\n",
        "\n",
        "def chat_with_context(message, history):\n",
        "    \"\"\"Chat with employee context.\"\"\"\n",
        "    try:\n",
        "        config = {\"configurable\": {\"thread_id\": session_id}}\n",
        "\n",
        "        result = employee_agent.invoke(\n",
        "            {\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
        "            config\n",
        "        )\n",
        "        return result['messages'][-1].content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 👤 Employee Portal with Context - LangChain 1.0\")\n",
        "    gr.Markdown(\"\"\"This demonstrates context management with memory.\n",
        "\n",
        "    **How it works:**\n",
        "    1. Introduce yourself with your employee ID (101, 102, or 103)\n",
        "    2. Agent sets your context automatically\n",
        "    3. All future queries use this context\n",
        "    4. No need to repeat your ID!\n",
        "\n",
        "    **Try it:**\n",
        "    - \"Hi, I'm employee 101\"\n",
        "    - \"How much leave do I have?\"\n",
        "    - \"Show me my information\"\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        reset_btn = gr.Button(\"Reset Session\", variant=\"secondary\")\n",
        "\n",
        "    reset_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "    chatbot = gr.ChatInterface(\n",
        "        fn=chat_with_context,\n",
        "        examples=[\n",
        "            \"Hi, I'm employee 101, Priya Sharma\",\n",
        "            \"How much leave do I have?\",\n",
        "            \"I want to request 3 days of leave\",\n",
        "            \"Show me my full information\",\n",
        "            \"What department am I in?\"\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    reset_btn.click(reset_session, outputs=[reset_output])\n",
        "\n",
        "    gr.Markdown(\"### 📋 Available Employees\")\n",
        "    employee_list = \"\\n\".join([f\"- **{emp_id}**: {emp['name']} ({emp['department']}, {emp['leave']} days leave)\"\n",
        "                               for emp_id, emp in EMPLOYEE_DB.items()])\n",
        "    gr.Markdown(employee_list)\n",
        "\n",
        "print(f\"Session ID: {session_id}\")\n",
        "print(\"\\nAvailable employees:\")\n",
        "for emp_id, emp in EMPLOYEE_DB.items():\n",
        "    print(f\"  - {emp_id}: {emp['name']} ({emp['department']}, {emp['leave']} days leave)\")\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFlIZawrZXS7"
      },
      "source": [
        "## How This Pattern Works\n",
        "\n",
        "### 1. Session Context Management\n",
        "Instead of using complex state injection, we use a simple session dictionary:\n",
        "```python\n",
        "current_session = {\n",
        "    \"employee_id\": None,\n",
        "    \"employee_name\": None,\n",
        "    \"department\": None,\n",
        "    \"leave_balance\": 0\n",
        "}\n",
        "```\n",
        "\n",
        "### 2. Context Setting Tool\n",
        "```python\n",
        "@tool\n",
        "def set_employee_context(employee_id: str):\n",
        "    # Load employee data\n",
        "    # Update session context\n",
        "    current_session[\"employee_id\"] = employee_id\n",
        "    # ...\n",
        "```\n",
        "\n",
        "### 3. Context-Aware Tools\n",
        "All other tools check the session context:\n",
        "```python\n",
        "@tool\n",
        "def check_leave_balance():\n",
        "    if not current_session[\"employee_id\"]:\n",
        "        return \"Please identify yourself first\"\n",
        "    # Use session data\n",
        "    return f\"You have {current_session['leave_balance']} days\"\n",
        "```\n",
        "\n",
        "### 4. Conversation Memory\n",
        "LangChain's checkpointer handles conversation history:\n",
        "```python\n",
        "agent = create_agent(\n",
        "    checkpointer=InMemorySaver(),  # Remembers conversation\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "## Benefits of This Approach\n",
        "\n",
        "✅ **Simple** - No complex state injection  \n",
        "✅ **Works** - Compatible with current LangChain  \n",
        "✅ **Clear** - Easy to understand and debug  \n",
        "✅ **Flexible** - Easy to extend with more context  \n",
        "\n",
        "## Production Considerations\n",
        "\n",
        "### For Multi-User Production Systems\n",
        "\n",
        "Replace the global `current_session` with:\n",
        "\n",
        "**Option 1: Thread-based storage**\n",
        "```python\n",
        "session_store = {}  # {thread_id: session_data}\n",
        "\n",
        "@tool\n",
        "def get_my_info():\n",
        "    thread_id = get_current_thread_id()  # From context\n",
        "    session = session_store.get(thread_id, {})\n",
        "    return session.get(\"employee_name\")\n",
        "```\n",
        "\n",
        "**Option 2: Database storage**\n",
        "```python\n",
        "@tool\n",
        "def get_my_info():\n",
        "    thread_id = get_current_thread_id()\n",
        "    session = db.get_session(thread_id)\n",
        "    return session.employee_name\n",
        "```\n",
        "\n",
        "**Option 3: Redis for distributed systems**\n",
        "```python\n",
        "@tool\n",
        "def get_my_info():\n",
        "    thread_id = get_current_thread_id()\n",
        "    session = redis.get(f\"session:{thread_id}\")\n",
        "    return json.loads(session)[\"employee_name\"]\n",
        "```\n",
        "\n",
        "## Example Conversation Flow\n",
        "\n",
        "```\n",
        "User: Hi, I'm employee 102\n",
        "Agent: [Calls set_employee_context(\"102\")]\n",
        "      ✅ Context set for Rahul Verma\n",
        "      Hello Rahul! How can I help you today?\n",
        "\n",
        "User: How much leave do I have?\n",
        "Agent: [Calls check_leave_balance()]\n",
        "      [Tool reads from current_session]\n",
        "      Rahul Verma, you have 8 days of leave available.\n",
        "\n",
        "User: I want 3 days off\n",
        "Agent: [Calls request_leave(3)]\n",
        "      [Tool reads from current_session]\n",
        "      ✅ Leave request submitted for Rahul Verma: 3 days\n",
        "```\n",
        "\n",
        "## Why This Works Better\n",
        "\n",
        "1. **No Import Errors** - Uses standard Python patterns\n",
        "2. **Easy Testing** - Simple to test and debug\n",
        "3. **Maintainable** - Clear code structure\n",
        "4. **Upgradable** - Easy to switch to database storage\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Implement thread-safe session storage\n",
        "- Add session expiration\n",
        "- Store in database for persistence\n",
        "- Add authentication\n",
        "- Implement session cleanup"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}