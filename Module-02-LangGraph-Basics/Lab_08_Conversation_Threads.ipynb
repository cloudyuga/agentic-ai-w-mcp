{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# # Lab 8: Threads & Conversation Management\n",
        "#\n",
        "# **Goal:** Understand how to manage multiple, independent runs of a graph concurrently using \"threads\". This is essential for any real-world application where you need to handle multiple users or tasks at the same time.\n",
        "#\n",
        "# ---\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Setup\n",
        "#\n",
        "# Let's create a simple, linear graph to use for our demonstration. This is the same graph we built in Lab 5.\n",
        "\n",
        "# %%\n",
        "# Install required packages\n",
        "!pip install langgraph --quiet\n",
        "print(\"Libraries installed.\")\n",
        "\n",
        "# Basic imports\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List\n",
        "\n",
        "# Define the state and nodes\n",
        "class ResumeState(TypedDict):\n",
        "    resume_text: str\n",
        "    decision: str\n",
        "\n",
        "def process_resume(state: ResumeState) -> dict:\n",
        "    \"\"\"A simple node that makes a decision based on resume content.\"\"\"\n",
        "    print(f\"---Processing Resume: '{state['resume_text']}'---\")\n",
        "    if \"senior\" in state[\"resume_text\"].lower():\n",
        "        decision = \"Interview\"\n",
        "    else:\n",
        "        decision = \"Reject\"\n",
        "    print(f\"Decision: {decision}\")\n",
        "    return {\"decision\": decision}\n",
        "\n",
        "# Build and compile the graph\n",
        "workflow = StateGraph(ResumeState)\n",
        "workflow.add_node(\"process\", process_resume)\n",
        "workflow.set_entry_point(\"process\")\n",
        "workflow.add_edge(\"process\", END)\n",
        "app = workflow.compile()\n",
        "print(\"\\nSimple graph compiled and ready.\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Part A: Understanding Threads\n",
        "#\n",
        "# In LangGraph, a \"thread\" is simply an independent sequence of operations within the same graph. Each thread has its own unique ID and its own separate state history.\n",
        "#\n",
        "# Think of it like a multi-lane highway:\n",
        "# -   The **Graph** is the highway itself.\n",
        "# -   Each **Thread** is a car driving on that highway.\n",
        "# -   The **State** is the car's current position and status.\n",
        "#\n",
        "# Each car (thread) can be in a different lane, at a different speed, and at a different point on the highway, but they are all following the same road rules (the graph's structure).\n",
        "#\n",
        "# You manage threads by passing a `config` dictionary with a `thread_id` to the `invoke` or `stream` method.\n",
        "\n",
        "# %% [markdown]\n",
        "# ---\n",
        "# ## Part B: A Single Thread Example\n",
        "#\n",
        "# Let's process one candidate's resume. We'll assign this process a unique `thread_id`. LangGraph will now store the history of this specific run under that ID.\n",
        "\n",
        "# %%\n",
        "# Define the input for our first candidate\n",
        "candidate_john = {\n",
        "    \"resume_text\": \"John Doe is a senior Python developer.\"\n",
        "}\n",
        "\n",
        "# Define the configuration for this thread\n",
        "config_john = {\"thread_id\": \"candidate_john_doe_123\"}\n",
        "\n",
        "# Invoke the graph with the input and the thread-specific config\n",
        "result_john = app.invoke(candidate_john, config=config_john)\n",
        "\n",
        "print(f\"\\nResult for {config_john['thread_id']}: {result_john['decision']}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# Behind the scenes, LangGraph has now stored the state transitions for the thread `\"candidate_john_doe_123\"`. If we were to invoke the graph again with the same `thread_id`, it would be a continuation of this run (useful for conversational agents).\n",
        "#\n",
        "# ---\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Part C: Multiple Concurrent Threads\n",
        "#\n",
        "# Now, let's process a list of candidates. We will loop through them and invoke the *same* compiled graph (`app`) for each one, but we will give each invocation a *different* `thread_id`. This ensures that each candidate's process is handled independently and their states do not interfere with each other.\n",
        "\n",
        "# %%\n",
        "# A list of candidates to process\n",
        "candidates = [\n",
        "    {\n",
        "        \"id\": \"candidate_jane_456\",\n",
        "        \"resume\": \"Jane Smith is a senior Java engineer.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"candidate_bob_789\",\n",
        "        \"resume\": \"Bob Wilson is a junior developer.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"candidate_alice_012\",\n",
        "        \"resume\": \"Alice Williams is a senior project manager.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "final_results = []\n",
        "\n",
        "print(\"---Processing Multiple Candidates Concurrently---\")\n",
        "\n",
        "# Process each candidate in their own independent thread\n",
        "for candidate in candidates:\n",
        "    # Prepare the input state for this candidate\n",
        "    input_state = {\"resume_text\": candidate[\"resume\"]}\n",
        "\n",
        "    # Create a unique config for this candidate's thread\n",
        "    config = {\"thread_id\": candidate[\"id\"]}\n",
        "\n",
        "    # Invoke the graph\n",
        "    result = app.invoke(input_state, config=config)\n",
        "\n",
        "    # Store the final decision\n",
        "    final_results.append({\n",
        "        \"id\": candidate[\"id\"],\n",
        "        \"decision\": result[\"decision\"]\n",
        "    })\n",
        "\n",
        "print(\"\\n---All Candidates Processed---\")\n",
        "for res in final_results:\n",
        "    print(f\"Thread ID: {res['id']}, Final Decision: {res['decision']}\")\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Key Benefits of Using Threads:\n",
        "#\n",
        "# * **Isolation:** The state of one candidate's application will never affect another's.\n",
        "# * **Concurrency:** You can process many candidates at the same time (especially with `astream`).\n",
        "# * **Stateful Conversations:** For a single user, you can use the same `thread_id` over multiple interactions to maintain memory and context, allowing you to pause and resume complex workflows.\n",
        "# * **Debugging:** It is much easier to trace the history of a specific run when it has a unique ID."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "At1xAwefBQHw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}