{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "module3_title"
      },
      "source": [
        "# Module 3: From LangGraph Nodes to LangChain Tools with @tool Decorator\n",
        "\n",
        "**Building on Modules 1 & 2**:\n",
        "- Module 1: Built agents using `create_agent()` with plain Python functions\n",
        "- Module 2: Learned LangGraph fundamentals with nodes and edges\n",
        "- Module 3: **Transform nodes into professional tools using @tool decorator**\n",
        "\n",
        "**Why use @tool decorator?**\n",
        "- Automatic schema generation for LLM tool calling\n",
        "- Better documentation and type validation\n",
        "- Seamless integration with LangChain ecosystem\n",
        "- Enhanced error handling and debugging\n",
        "- Industry-standard approach for LangChain 1.0\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_title"
      },
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install_deps",
        "outputId": "b743dc44-8bd9-43f2-83e6-a1210229c445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.0a15-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.0a4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.0a4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0a7 (from langchain)\n",
            "  Downloading langchain_core-1.0.0rc1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt==0.7.0a2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.7.0a2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (0.4.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0a7->langchain) (4.15.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0a7->langchain) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0a7->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain-1.0.0a15-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.0.0a4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.0a4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.7.0a2-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-1.0.0rc1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m467.8/467.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.78\n",
            "    Uninstalling langchain-core-0.3.78:\n",
            "      Successfully uninstalled langchain-core-0.3.78\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-1.0.0a15 langchain-core-1.0.0rc1 langchain-openai-1.0.0a4 langgraph-1.0.0a4 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.7.0a2 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain 1.0 alpha packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api_key_title"
      },
      "source": [
        "## Setup: Configure OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "setup_api_key",
        "outputId": "629aa94d-5dec-4746-a0c9-d331bf29d59b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API Key configured!\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the API key from Colab's secrets\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "print(\"âœ… API Key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_title"
      },
      "source": [
        "---\n",
        "# Lab 1: Understanding the Difference - Plain Functions vs @tool\n",
        "\n",
        "**Objective:** Compare plain Python functions (used as nodes) with @tool decorated functions.\n",
        "\n",
        "**Scenario:** Same HR tools from Module 1, but showing the evolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_imports"
      },
      "source": [
        "## Part 1: Plain Functions (The Old Way)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plain_functions"
      },
      "outputs": [],
      "source": [
        "# Old approach: Plain Python functions\n",
        "def get_employee_info(employee_id: str) -> str:\n",
        "    \"\"\"Get employee information by ID.\"\"\"\n",
        "    employees = {\n",
        "        \"101\": \"Priya Sharma - Engineering - Senior Developer\",\n",
        "        \"102\": \"Rahul Verma - Engineering - Manager\",\n",
        "        \"103\": \"Anjali Patel - HR - Director\",\n",
        "        \"104\": \"Arjun Reddy - Sales - Team Lead\",\n",
        "        \"105\": \"Sneha Gupta - Marketing - Specialist\"\n",
        "    }\n",
        "    return employees.get(employee_id, f\"Employee {employee_id} not found\")\n",
        "\n",
        "def check_leave_balance(employee_id: str) -> str:\n",
        "    \"\"\"Check remaining leave days for an employee by ID.\"\"\"\n",
        "    leave_data = {\n",
        "        \"101\": \"Priya Sharma has 12 days of leave remaining\",\n",
        "        \"102\": \"Rahul Verma has 8 days of leave remaining\",\n",
        "        \"103\": \"Anjali Patel has 15 days of leave remaining\",\n",
        "        \"104\": \"Arjun Reddy has 10 days of leave remaining\",\n",
        "        \"105\": \"Sneha Gupta has 5 days of leave remaining\"\n",
        "    }\n",
        "    return leave_data.get(employee_id, f\"Leave data for employee {employee_id} not found\")\n",
        "\n",
        "# Test plain functions\n",
        "print(\"Plain Function Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(get_employee_info(\"101\"))\n",
        "print(check_leave_balance(\"101\"))\n",
        "print(\"\\nâš ï¸  Problem: No automatic schema, no validation, no integration with LLM tool calling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tool_decorator_intro"
      },
      "source": [
        "## Part 2: @tool Decorator (The New Way) âœ¨\n",
        "\n",
        "**Key Benefits:**\n",
        "- Automatic schema generation from type hints\n",
        "- Built-in documentation from docstrings\n",
        "- Ready for LLM tool calling\n",
        "- Better error handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tool_decorator_code",
        "outputId": "45da0e06-56b9-4938-e1a0-fd9a3b639794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@tool Decorated Function Properties:\n",
            "==================================================\n",
            "Tool Name: get_employee_info_tool\n",
            "Description: Get employee information by ID. Returns name, department, and position.\n",
            "Args Schema: {'employee_id': {'description': 'The unique employee ID to look up', 'title': 'Employee Id', 'type': 'string'}}\n",
            "\n",
            "âœ… Benefits: Auto schema, validation, LLM-ready!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "\n",
        "# New approach: @tool decorator\n",
        "@tool\n",
        "def get_employee_info_tool(employee_id: Annotated[str, \"The unique employee ID to look up\"]) -> str:\n",
        "    \"\"\"Get employee information by ID. Returns name, department, and position.\"\"\"\n",
        "    employees = {\n",
        "        \"101\": \"Priya Sharma - Engineering - Senior Developer\",\n",
        "        \"102\": \"Rahul Verma - Engineering - Manager\",\n",
        "        \"103\": \"Anjali Patel - HR - Director\",\n",
        "        \"104\": \"Arjun Reddy - Sales - Team Lead\",\n",
        "        \"105\": \"Sneha Gupta - Marketing - Specialist\"\n",
        "    }\n",
        "    return employees.get(employee_id, f\"Employee {employee_id} not found\")\n",
        "\n",
        "@tool\n",
        "def check_leave_balance_tool(employee_id: Annotated[str, \"The employee ID to check leave balance for\"]) -> str:\n",
        "    \"\"\"Check remaining leave days for an employee. Returns the number of leave days available.\"\"\"\n",
        "    leave_data = {\n",
        "        \"101\": \"Priya Sharma has 12 days of leave remaining\",\n",
        "        \"102\": \"Rahul Verma has 8 days of leave remaining\",\n",
        "        \"103\": \"Anjali Patel has 15 days of leave remaining\",\n",
        "        \"104\": \"Arjun Reddy has 10 days of leave remaining\",\n",
        "        \"105\": \"Sneha Gupta has 5 days of leave remaining\"\n",
        "    }\n",
        "    return leave_data.get(employee_id, f\"Leave data for employee {employee_id} not found\")\n",
        "\n",
        "# Inspect the tool properties\n",
        "print(\"@tool Decorated Function Properties:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Tool Name: {get_employee_info_tool.name}\")\n",
        "print(f\"Description: {get_employee_info_tool.description}\")\n",
        "print(f\"Args Schema: {get_employee_info_tool.args}\")\n",
        "print(\"\\nâœ… Benefits: Auto schema, validation, LLM-ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tool_usage"
      },
      "source": [
        "## Part 3: Using Tools - Same Interface!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tool_usage_code",
        "outputId": "04d80f99-ff49-4a92-df2c-7aa4eebf0fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Direct Tool Invocation:\n",
            "==================================================\n",
            "Priya Sharma - Engineering - Senior Developer\n",
            "Priya Sharma has 12 days of leave remaining\n",
            "\n",
            "âœ… Same functionality, but now with schema and validation!\n"
          ]
        }
      ],
      "source": [
        "# Tools can be called just like regular functions\n",
        "print(\"Direct Tool Invocation:\")\n",
        "print(\"=\" * 50)\n",
        "result1 = get_employee_info_tool.invoke({\"employee_id\": \"101\"})\n",
        "print(result1)\n",
        "\n",
        "result2 = check_leave_balance_tool.invoke({\"employee_id\": \"101\"})\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nâœ… Same functionality, but now with schema and validation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agent_integration_title"
      },
      "source": [
        "---\n",
        "# Lab 2: Using @tool with LangChain Agents\n",
        "\n",
        "**Objective:** Integrate @tool decorated functions with LangChain agents.\n",
        "\n",
        "**This is the power of @tool!** LLMs can now understand and use these tools automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "agent_setup",
        "outputId": "e68fc143-a98b-43c9-92e7-2f4cb6b637f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Agent created with @tool decorated functions!\n",
            "Number of tools available: 2\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Create agent with @tool decorated functions\n",
        "tools = [get_employee_info_tool, check_leave_balance_tool]\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    system_prompt=\"You are an HR assistant. Help users with employee information and leave balance queries.\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Agent created with @tool decorated functions!\")\n",
        "print(f\"Number of tools available: {len(tools)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agent_test"
      },
      "source": [
        "## Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "agent_test_code",
        "outputId": "516d8103-f156-4f84-dfbe-ab2f626a0a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1: Who is employee 101?\n",
            "======================================================================\n",
            "Employee 101 is Priya Sharma. She works in the Engineering department as a Senior Developer.\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Test 2: Tell me about employee 102 and their leave balance\n",
            "======================================================================\n",
            "Employee 102 is Rahul Verma, who works in the Engineering department as a Manager. He has 8 days of leave remaining.\n",
            "\n",
            "âœ… Agent automatically selected the right tools!\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Simple query\n",
        "print(\"Test 1: Who is employee 101?\")\n",
        "print(\"=\" * 70)\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "})\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Test 2: Complex query requiring multiple tools\n",
        "print(\"\\nTest 2: Tell me about employee 102 and their leave balance\")\n",
        "print(\"=\" * 70)\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me about employee 102 and their leave balance\"}]\n",
        "})\n",
        "print(result['messages'][-1].content)\n",
        "\n",
        "print(\"\\nâœ… Agent automatically selected the right tools!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_tools_title"
      },
      "source": [
        "---\n",
        "# Lab 3: Advanced @tool Features\n",
        "\n",
        "**Objective:** Explore advanced @tool decorator features:\n",
        "- Custom tool names\n",
        "- Custom descriptions\n",
        "- Pydantic models for complex inputs\n",
        "- Error handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_names"
      },
      "source": [
        "## Part 1: Custom Names and Descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "custom_names_code",
        "outputId": "a7c75149-52f1-47e3-b26e-7def6c6b1f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Name: search_employee\n",
            "Description: Search for an employee by name or ID. Returns detailed employee information.\n",
            "\n",
            "âœ… Custom name makes it clearer for LLMs to choose the right tool!\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Custom tool with explicit name\n",
        "@tool(\"search_employee\")\n",
        "def find_employee(query: Annotated[str, \"Employee name or ID to search for\"]) -> str:\n",
        "    \"\"\"Search for an employee by name or ID. Returns detailed employee information.\"\"\"\n",
        "    employees = {\n",
        "        \"priya\": \"Employee ID: 101 - Priya Sharma - Engineering - Senior Developer\",\n",
        "        \"rahul\": \"Employee ID: 102 - Rahul Verma - Engineering - Manager\",\n",
        "        \"101\": \"Employee ID: 101 - Priya Sharma - Engineering - Senior Developer\",\n",
        "        \"102\": \"Employee ID: 102 - Rahul Verma - Engineering - Manager\"\n",
        "    }\n",
        "    query_lower = query.lower()\n",
        "    return employees.get(query_lower, f\"No employee found matching '{query}'\")\n",
        "\n",
        "print(f\"Tool Name: {find_employee.name}\")\n",
        "print(f\"Description: {find_employee.description}\")\n",
        "print(\"\\nâœ… Custom name makes it clearer for LLMs to choose the right tool!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pydantic_models"
      },
      "source": [
        "## Part 2: Using Pydantic Models for Complex Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pydantic_code",
        "outputId": "c0c07f7d-dbb3-441f-ff8d-8048c7b4ff05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool with Pydantic Schema:\n",
            "==================================================\n",
            "Tool Name: submit_leave_request\n",
            "Args Schema: {'employee_id': {'description': 'The employee ID submitting the leave request', 'title': 'Employee Id', 'type': 'string'}, 'start_date': {'description': 'Leave start date in YYYY-MM-DD format', 'title': 'Start Date', 'type': 'string'}, 'end_date': {'description': 'Leave end date in YYYY-MM-DD format', 'title': 'End Date', 'type': 'string'}, 'reason': {'description': 'Reason for the leave request', 'title': 'Reason', 'type': 'string'}}\n",
            "\n",
            "âœ… Pydantic provides rich validation and documentation!\n"
          ]
        }
      ],
      "source": [
        "class LeaveRequestInput(BaseModel):\n",
        "    \"\"\"Input schema for submitting a leave request.\"\"\"\n",
        "    employee_id: str = Field(description=\"The employee ID submitting the leave request\")\n",
        "    start_date: str = Field(description=\"Leave start date in YYYY-MM-DD format\")\n",
        "    end_date: str = Field(description=\"Leave end date in YYYY-MM-DD format\")\n",
        "    reason: str = Field(description=\"Reason for the leave request\")\n",
        "\n",
        "@tool(args_schema=LeaveRequestInput)\n",
        "def submit_leave_request(employee_id: str, start_date: str, end_date: str, reason: str) -> str:\n",
        "    \"\"\"Submit a leave request for an employee. Returns confirmation with request ID.\"\"\"\n",
        "    import random\n",
        "    request_id = f\"LR-{random.randint(1000, 9999)}\"\n",
        "    return f\"Leave request {request_id} submitted successfully for employee {employee_id} from {start_date} to {end_date}. Reason: {reason}\"\n",
        "\n",
        "# Inspect the schema\n",
        "print(\"Tool with Pydantic Schema:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Tool Name: {submit_leave_request.name}\")\n",
        "print(f\"Args Schema: {submit_leave_request.args}\")\n",
        "print(\"\\nâœ… Pydantic provides rich validation and documentation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_pydantic"
      },
      "source": [
        "## Test the Complex Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "test_pydantic_code",
        "outputId": "1f6aa279-fad0-47f7-dead-52210c010808",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leave Request Result:\n",
            "==================================================\n",
            "Leave request LR-5913 submitted successfully for employee 101 from 2025-11-01 to 2025-11-05. Reason: Vacation\n",
            "\n",
            "âœ… Complex inputs handled with ease!\n"
          ]
        }
      ],
      "source": [
        "# Test the tool\n",
        "result = submit_leave_request.invoke({\n",
        "    \"employee_id\": \"101\",\n",
        "    \"start_date\": \"2025-11-01\",\n",
        "    \"end_date\": \"2025-11-05\",\n",
        "    \"reason\": \"Vacation\"\n",
        "})\n",
        "\n",
        "print(\"Leave Request Result:\")\n",
        "print(\"=\" * 50)\n",
        "print(result)\n",
        "print(\"\\nâœ… Complex inputs handled with ease!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "error_handling"
      },
      "source": [
        "## Part 3: Error Handling in Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "error_handling_code",
        "outputId": "3b11e39c-a9ed-4fcd-c002-a180dc3de8b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test with valid employee ID:\n",
            "âœ… Monthly Salary: â‚¹1,00,000\n",
            "\n",
            "Test with invalid employee ID:\n",
            "âŒ Tool Exception: Salary information not available for employee 999\n",
            "\n",
            "âœ… Proper error handling makes tools more robust!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool, ToolException\n",
        "\n",
        "@tool\n",
        "def calculate_salary(employee_id: Annotated[str, \"Employee ID to calculate salary for\"]) -> str:\n",
        "    \"\"\"Calculate monthly salary for an employee. Returns salary details.\"\"\"\n",
        "    salaries = {\n",
        "        \"101\": \"Monthly Salary: â‚¹1,00,000\",\n",
        "        \"102\": \"Monthly Salary: â‚¹1,50,000\",\n",
        "        \"103\": \"Monthly Salary: â‚¹2,00,000\"\n",
        "    }\n",
        "\n",
        "    if employee_id not in salaries:\n",
        "        raise ToolException(f\"Salary information not available for employee {employee_id}\")\n",
        "\n",
        "    return salaries[employee_id]\n",
        "\n",
        "# Test with valid ID\n",
        "print(\"Test with valid employee ID:\")\n",
        "try:\n",
        "    result = calculate_salary.invoke({\"employee_id\": \"101\"})\n",
        "    print(f\"âœ… {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")\n",
        "\n",
        "# Test with invalid ID\n",
        "print(\"\\nTest with invalid employee ID:\")\n",
        "try:\n",
        "    result = calculate_salary.invoke({\"employee_id\": \"999\"})\n",
        "    print(f\"âœ… {result}\")\n",
        "except ToolException as e:\n",
        "    print(f\"âŒ Tool Exception: {e}\")\n",
        "\n",
        "print(\"\\nâœ… Proper error handling makes tools more robust!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "langgraph_integration_title"
      },
      "source": [
        "---\n",
        "# Lab 4: Integrating @tool with LangGraph Workflows\n",
        "\n",
        "**Objective:** Combine LangGraph workflows with @tool decorated functions.\n",
        "\n",
        "**This is the BEST of both worlds:**\n",
        "- LangGraph for workflow control\n",
        "- @tool for LLM-ready functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "langgraph_imports"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow_tools"
      },
      "source": [
        "## Step 1: Define Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "workflow_tools_code",
        "outputId": "101c2f40-f1ae-42c0-855f-1eec88d1ee1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All tools defined with @tool decorator!\n",
            "Tools: validate_employee_id, get_employee_details, calculate_benefits\n"
          ]
        }
      ],
      "source": [
        "# Define HR tools with @tool decorator\n",
        "@tool\n",
        "def validate_employee_id(employee_id: Annotated[str, \"Employee ID to validate\"]) -> str:\n",
        "    \"\"\"Validate if an employee ID exists in the system.\"\"\"\n",
        "    valid_ids = [\"101\", \"102\", \"103\", \"104\", \"105\"]\n",
        "    if employee_id in valid_ids:\n",
        "        return f\"âœ… Employee ID {employee_id} is valid\"\n",
        "    return f\"âŒ Employee ID {employee_id} is invalid\"\n",
        "\n",
        "@tool\n",
        "def get_employee_details(employee_id: Annotated[str, \"Employee ID to get details for\"]) -> str:\n",
        "    \"\"\"Get detailed information about an employee.\"\"\"\n",
        "    details = {\n",
        "        \"101\": \"Priya Sharma | Engineering | Senior Developer | Joined: 2020\",\n",
        "        \"102\": \"Rahul Verma | Engineering | Manager | Joined: 2018\",\n",
        "        \"103\": \"Anjali Patel | HR | Director | Joined: 2015\"\n",
        "    }\n",
        "    return details.get(employee_id, \"Employee not found\")\n",
        "\n",
        "@tool\n",
        "def calculate_benefits(employee_id: Annotated[str, \"Employee ID to calculate benefits for\"]) -> str:\n",
        "    \"\"\"Calculate employee benefits based on tenure and position.\"\"\"\n",
        "    return f\"Benefits for {employee_id}: Health Insurance, PF, Bonus, Leave Encashment\"\n",
        "\n",
        "print(\"âœ… All tools defined with @tool decorator!\")\n",
        "print(f\"Tools: {validate_employee_id.name}, {get_employee_details.name}, {calculate_benefits.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow_state"
      },
      "source": [
        "## Step 2: Define Workflow State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "workflow_state_code",
        "outputId": "915946f7-ffc7-46b3-ba41-ea0447db12bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Workflow state defined!\n"
          ]
        }
      ],
      "source": [
        "class EmployeeQueryState(TypedDict):\n",
        "    \"\"\"State for employee query workflow.\"\"\"\n",
        "    employee_id: str\n",
        "    validation_result: str\n",
        "    employee_details: str\n",
        "    benefits: str\n",
        "    messages: Annotated[list, add_messages]\n",
        "    final_report: str\n",
        "\n",
        "print(\"âœ… Workflow state defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow_nodes"
      },
      "source": [
        "## Step 3: Create Workflow Nodes Using Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "workflow_nodes_code",
        "outputId": "64512e05-2402-420c-d57d-78fe9ce69487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All workflow nodes created using @tool functions!\n"
          ]
        }
      ],
      "source": [
        "def validate_node(state: EmployeeQueryState):\n",
        "    \"\"\"Node 1: Validate employee using @tool.\"\"\"\n",
        "    print(f\"ðŸ“‹ Validating employee {state['employee_id']}...\")\n",
        "    result = validate_employee_id.invoke({\"employee_id\": state['employee_id']})\n",
        "    return {\n",
        "        \"validation_result\": result,\n",
        "        \"messages\": [(\"assistant\", result)]\n",
        "    }\n",
        "\n",
        "def fetch_details_node(state: EmployeeQueryState):\n",
        "    \"\"\"Node 2: Fetch employee details using @tool.\"\"\"\n",
        "    print(f\"ðŸ“„ Fetching details for employee {state['employee_id']}...\")\n",
        "    if \"invalid\" in state['validation_result'].lower():\n",
        "        return {\"employee_details\": \"Skipped - Invalid ID\"}\n",
        "\n",
        "    result = get_employee_details.invoke({\"employee_id\": state['employee_id']})\n",
        "    return {\n",
        "        \"employee_details\": result,\n",
        "        \"messages\": [(\"assistant\", result)]\n",
        "    }\n",
        "\n",
        "def calculate_benefits_node(state: EmployeeQueryState):\n",
        "    \"\"\"Node 3: Calculate benefits using @tool.\"\"\"\n",
        "    print(f\"ðŸ’° Calculating benefits for employee {state['employee_id']}...\")\n",
        "    if \"invalid\" in state['validation_result'].lower():\n",
        "        return {\"benefits\": \"Skipped - Invalid ID\"}\n",
        "\n",
        "    result = calculate_benefits.invoke({\"employee_id\": state['employee_id']})\n",
        "    return {\n",
        "        \"benefits\": result,\n",
        "        \"messages\": [(\"assistant\", result)]\n",
        "    }\n",
        "\n",
        "def generate_report_node(state: EmployeeQueryState):\n",
        "    \"\"\"Node 4: Generate final report.\"\"\"\n",
        "    print(f\"ðŸ“Š Generating final report...\")\n",
        "    report = f\"\"\"\n",
        "Employee Query Report\n",
        "{'=' * 50}\n",
        "Employee ID: {state['employee_id']}\n",
        "Validation: {state['validation_result']}\n",
        "Details: {state['employee_details']}\n",
        "Benefits: {state['benefits']}\n",
        "{'=' * 50}\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"final_report\": report,\n",
        "        \"messages\": [(\"assistant\", \"Report generated successfully\")]\n",
        "    }\n",
        "\n",
        "print(\"âœ… All workflow nodes created using @tool functions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow_build"
      },
      "source": [
        "## Step 4: Build the Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "workflow_build_code",
        "outputId": "db1949ab-5272-412e-b319-7aa7a3e282aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Workflow compiled!\n",
            "Flow: START â†’ validate â†’ fetch_details â†’ calculate_benefits â†’ generate_report â†’ END\n"
          ]
        }
      ],
      "source": [
        "# Create workflow\n",
        "workflow = StateGraph(EmployeeQueryState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"validate\", validate_node)\n",
        "workflow.add_node(\"fetch_details\", fetch_details_node)\n",
        "workflow.add_node(\"calculate_benefits\", calculate_benefits_node)\n",
        "workflow.add_node(\"generate_report\", generate_report_node)\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(START, \"validate\")\n",
        "workflow.add_edge(\"validate\", \"fetch_details\")\n",
        "workflow.add_edge(\"fetch_details\", \"calculate_benefits\")\n",
        "workflow.add_edge(\"calculate_benefits\", \"generate_report\")\n",
        "workflow.add_edge(\"generate_report\", END)\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"âœ… Workflow compiled!\")\n",
        "print(\"Flow: START â†’ validate â†’ fetch_details â†’ calculate_benefits â†’ generate_report â†’ END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow_test"
      },
      "source": [
        "## Step 5: Test the Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "workflow_test_code",
        "outputId": "ab074739-6071-456f-d383-7c6cca9680bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running workflow for employee 101...\n",
            "======================================================================\n",
            "ðŸ“‹ Validating employee 101...\n",
            "ðŸ“„ Fetching details for employee 101...\n",
            "ðŸ’° Calculating benefits for employee 101...\n",
            "ðŸ“Š Generating final report...\n",
            "\n",
            "Final Report:\n",
            "\n",
            "Employee Query Report\n",
            "==================================================\n",
            "Employee ID: 101\n",
            "Validation: âœ… Employee ID 101 is valid\n",
            "Details: Priya Sharma | Engineering | Senior Developer | Joined: 2020\n",
            "Benefits: Benefits for 101: Health Insurance, PF, Bonus, Leave Encashment\n",
            "==================================================\n",
            "    \n",
            "\n",
            "âœ… Workflow completed using @tool decorated functions!\n"
          ]
        }
      ],
      "source": [
        "# Test with valid employee\n",
        "initial_state = {\n",
        "    \"employee_id\": \"101\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"employee_details\": \"\",\n",
        "    \"benefits\": \"\",\n",
        "    \"messages\": [],\n",
        "    \"final_report\": \"\"\n",
        "}\n",
        "\n",
        "print(\"Running workflow for employee 101...\")\n",
        "print(\"=\" * 70)\n",
        "result = app.invoke(initial_state)\n",
        "print(\"\\nFinal Report:\")\n",
        "print(result['final_report'])\n",
        "\n",
        "print(\"\\nâœ… Workflow completed using @tool decorated functions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_summary"
      },
      "source": [
        "---\n",
        "# Summary: Plain Functions vs @tool Decorator\n",
        "\n",
        "## Comparison Table\n",
        "\n",
        "| Feature | Plain Functions | @tool Decorator |\n",
        "|---------|----------------|------------------|\n",
        "| **Schema Generation** | âŒ Manual | âœ… Automatic |\n",
        "| **LLM Integration** | âŒ Limited | âœ… Native |\n",
        "| **Type Validation** | âŒ Optional | âœ… Built-in |\n",
        "| **Documentation** | âŒ Separate | âœ… Integrated |\n",
        "| **Error Handling** | âŒ Manual | âœ… Enhanced |\n",
        "| **Agent Compatibility** | âš ï¸  Requires wrapper | âœ… Direct |\n",
        "| **Best For** | Simple nodes | LLM-ready tools |\n",
        "\n",
        "## When to Use @tool?\n",
        "\n",
        "âœ… **Use @tool when:**\n",
        "- Building agents that need LLM tool calling\n",
        "- Want automatic schema generation\n",
        "- Need robust type validation\n",
        "- Creating reusable tools\n",
        "- Working with LangChain ecosystem\n",
        "\n",
        "âš ï¸ **Use plain functions when:**\n",
        "- Building simple workflow nodes\n",
        "- Don't need LLM integration\n",
        "- Internal processing only\n",
        "- Maximum flexibility needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercises_title"
      },
      "source": [
        "---\n",
        "# ðŸŽ¯ Exercises\n",
        "\n",
        "## Exercise 1: Create Custom Tools\n",
        "\n",
        "Create three new @tool decorated functions:\n",
        "1. `update_employee_info` - Update employee details\n",
        "2. `approve_leave_request` - Approve/reject leave requests\n",
        "3. `generate_payslip` - Generate monthly payslip\n",
        "\n",
        "**Requirements:**\n",
        "- Use Pydantic models for complex inputs\n",
        "- Add proper docstrings\n",
        "- Include error handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise1_code"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "# Hint: Use @tool decorator and Pydantic BaseModel\n",
        "\n",
        "@tool\n",
        "def update_employee_info(employee_id: str, field: str, value: str) -> str:\n",
        "    \"\"\"TODO: Implement this tool.\"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Implement approve_leave_request and generate_payslip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise2"
      },
      "source": [
        "## Exercise 2: Build a Tool-Powered Workflow\n",
        "\n",
        "Create a LangGraph workflow that:\n",
        "1. Takes an employee ID\n",
        "2. Validates the employee\n",
        "3. Checks their leave balance\n",
        "4. Processes a leave request if balance is sufficient\n",
        "5. Generates a confirmation report\n",
        "\n",
        "**Use only @tool decorated functions!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise2_code"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "# Hint: Define tools first, then create workflow nodes\n",
        "\n",
        "# TODO: Define tools\n",
        "# TODO: Create State\n",
        "# TODO: Create nodes\n",
        "# TODO: Build workflow\n",
        "# TODO: Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exercise3"
      },
      "source": [
        "## Exercise 3: Error Handling Challenge\n",
        "\n",
        "Enhance the `calculate_salary` tool to:\n",
        "1. Validate employee ID format (must be 3 digits)\n",
        "2. Check if employee exists\n",
        "3. Handle division errors when calculating bonuses\n",
        "4. Return meaningful error messages\n",
        "\n",
        "Test with: valid ID, invalid format, non-existent ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise3_code"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from langchain.tools.base import ToolException\n",
        "\n",
        "@tool\n",
        "def enhanced_calculate_salary(employee_id: str) -> str:\n",
        "    \"\"\"TODO: Add robust error handling.\"\"\"\n",
        "    # TODO: Validate ID format\n",
        "    # TODO: Check if employee exists\n",
        "    # TODO: Calculate salary with error handling\n",
        "    pass\n",
        "\n",
        "# TODO: Test cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bonus_exercise"
      },
      "source": [
        "## ðŸŒŸ Bonus Challenge: Advanced Tool Integration\n",
        "\n",
        "Create an agent that can:\n",
        "1. Handle conversational queries about employees\n",
        "2. Use multiple tools in sequence\n",
        "3. Maintain context across queries\n",
        "4. Generate comprehensive reports\n",
        "\n",
        "Example queries to support:\n",
        "- \"Who is employee 101 and how many leave days do they have?\"\n",
        "- \"Compare the leave balances of employees in Engineering\"\n",
        "- \"Generate a benefits report for all managers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bonus_code"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "# This is open-ended - be creative!\n",
        "# Hint: Combine create_agent, @tool, and LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "# Conclusion\n",
        "\n",
        "**What you learned:**\n",
        "1. âœ… The difference between plain functions and @tool decorator\n",
        "2. âœ… How to create tools with automatic schema generation\n",
        "3. âœ… Using Pydantic models for complex inputs\n",
        "4. âœ… Error handling in tools\n",
        "5. âœ… Integrating @tool with LangGraph workflows\n",
        "6. âœ… Building production-ready agents with tools\n",
        "\n",
        "**Key Takeaways:**\n",
        "- **@tool decorator** is the standard way to create LLM-ready tools\n",
        "- **Automatic schema generation** saves time and reduces errors\n",
        "- **Type hints and docstrings** are critical for tool quality\n",
        "- **Tools work seamlessly** with both agents and workflows\n",
        "\n",
        "**Next Steps:**\n",
        "- Explore tool artifacts (Module 4)\n",
        "- Learn about tool streaming (Module 5)\n",
        "- Build multi-agent systems (Module 6)\n",
        "- Deploy production agents (Module 7)\n",
        "\n",
        "---\n",
        "**Created with:** LangChain 1.0 + OpenAI + LangGraph\n",
        "\n",
        "**References:**\n",
        "- [LangChain Tools Documentation](https://python.langchain.com/docs/concepts/tools/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}