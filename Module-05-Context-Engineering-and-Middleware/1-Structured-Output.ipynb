{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqs86oZVCDfM"
      },
      "source": [
        "# HR Structured Outputs with LangChain 1.0\n",
        "\n",
        "**Module:** Working with Structured Response Formats\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Understand 4 different ways to define structured outputs\n",
        "- Compare Pydantic, Dataclass, TypedDict, and JSON Schema\n",
        "- Build production-ready HR agents with structured responses\n",
        "- Apply best practices for data extraction\n",
        "\n",
        "**Use Case:** Extract structured employee information from unstructured text\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCnQ9ycbCDfQ"
      },
      "source": [
        "---\n",
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ECfJ8AemCDfQ",
        "outputId": "80bf6ccf-5ddd-4e19-f021-af0099ab6a9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
            "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
            "  Downloading langgraph-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Collecting pydantic-core==2.41.4 (from pydantic)\n",
            "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.35)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (8.5.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain-1.0.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.0.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic-core, ormsgpack, pydantic, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.10\n",
            "    Uninstalling pydantic-2.11.10:\n",
            "      Successfully uninstalled pydantic-2.11.10\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-1.0.0 langchain-core-1.0.0 langchain-openai-1.0.0 langgraph-1.0.0 langgraph-checkpoint-2.1.2 langgraph-prebuilt-1.0.0 langgraph-sdk-0.2.9 ormsgpack-1.11.0 pydantic-2.12.3 pydantic-core-2.41.4\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain 1.0 alpha packages\n",
        "!pip install --pre -U langchain langchain-openai pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LPwWzv3CDfR"
      },
      "source": [
        "## Setup: Configure OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P-pGuc_8CDfR",
        "outputId": "971c2ec6-134b-45b3-f160-a761f0b0ece1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API Key configured!\n"
          ]
        }
      ],
      "source": [
        "# For Google Colab\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "print(\"✅ API Key configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WotLgR17CDfS"
      },
      "outputs": [],
      "source": [
        "# Alternative: For local Jupyter or other environments\n",
        "# import os\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
        "# print(\"✅ API Key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDcv9U2sCDfS"
      },
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2MsnzjXICDfS",
        "outputId": "47a9c515-472b-4c92-e23c-22d68286125d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "from typing import Optional, List\n",
        "from dataclasses import dataclass\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.agents import create_agent\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "print(\"✅ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EslEm8DTCDfS"
      },
      "source": [
        "---\n",
        "# Lab 1: Pydantic BaseModel (⭐ Recommended)\n",
        "\n",
        "**Objective:** Use Pydantic BaseModel for structured output\n",
        "\n",
        "**Benefits:**\n",
        "- Automatic validation\n",
        "- Rich field descriptions\n",
        "- IDE autocomplete support\n",
        "- Easy serialization\n",
        "- Best integration with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jZa7UpSCDfT"
      },
      "source": [
        "## Step 1: Define Pydantic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rNqkg4XXCDfT",
        "outputId": "b1156943-62ba-4917-eb97-3c0f8810fc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ EmployeeInfo Pydantic model defined!\n",
            "\n",
            "Model fields: ['employee_id', 'full_name', 'email', 'phone', 'department', 'position', 'salary', 'joining_date', 'skills']\n"
          ]
        }
      ],
      "source": [
        "class EmployeeInfo(BaseModel):\n",
        "    \"\"\"Structured employee information using Pydantic.\"\"\"\n",
        "\n",
        "    employee_id: str = Field(\n",
        "        description=\"Unique employee identifier (e.g., EMP001)\"\n",
        "    )\n",
        "    full_name: str = Field(\n",
        "        description=\"Full name of the employee\"\n",
        "    )\n",
        "    email: str = Field(\n",
        "        description=\"Work email address\"\n",
        "    )\n",
        "    phone: str = Field(\n",
        "        description=\"Contact phone number\"\n",
        "    )\n",
        "    department: str = Field(\n",
        "        description=\"Department name (e.g., Engineering, HR, Sales)\"\n",
        "    )\n",
        "    position: str = Field(\n",
        "        description=\"Job title/position\"\n",
        "    )\n",
        "    salary: Optional[float] = Field(\n",
        "        default=None,\n",
        "        description=\"Annual salary in INR (optional)\"\n",
        "    )\n",
        "    joining_date: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date of joining in YYYY-MM-DD format\"\n",
        "    )\n",
        "    skills: Optional[List[str]] = Field(\n",
        "        default=None,\n",
        "        description=\"List of key skills\"\n",
        "    )\n",
        "\n",
        "print(\"✅ EmployeeInfo Pydantic model defined!\")\n",
        "print(f\"\\nModel fields: {list(EmployeeInfo.model_fields.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiA56SFuCDfT"
      },
      "source": [
        "## Step 2: Create Agent with Pydantic Response Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qrzTpzWmCDfT",
        "outputId": "105dc96b-40d2-44b0-d94c-c822ac15ad4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent created with Pydantic response format!\n"
          ]
        }
      ],
      "source": [
        "# Define a simple tool (optional - for demonstration)\n",
        "@tool\n",
        "def get_employee_database(query: str) -> str:\n",
        "    \"\"\"Search employee database for information.\"\"\"\n",
        "    return \"Database contains employee records...\"\n",
        "\n",
        "# Create agent with Pydantic response format\n",
        "tools = [get_employee_database]\n",
        "\n",
        "agent_pydantic = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    response_format=EmployeeInfo  # Auto-selects ProviderStrategy\n",
        ")\n",
        "\n",
        "print(\"✅ Agent created with Pydantic response format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piOU-0WiCDfT"
      },
      "source": [
        "## Step 3: Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "smcr4i1hCDfU",
        "outputId": "9800d440-0171-4019-f800-03b44dc7e309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PYDANTIC BASEMODEL RESULT\n",
            "======================================================================\n",
            "Type: <class '__main__.EmployeeInfo'>\n",
            "\n",
            "Employee ID: EMP101\n",
            "Name: Priya Sharma\n",
            "Email: priya.sharma@company.com\n",
            "Phone: +91-9876543210\n",
            "Department: Engineering\n",
            "Position: Senior Developer\n",
            "Salary: ₹1,200,000.00\n",
            "Joining Date: 2020-05-15\n",
            "Skills: Python, Django, AWS, Docker\n",
            "\n",
            "✅ Pydantic provides validation, serialization, and IDE support!\n"
          ]
        }
      ],
      "source": [
        "# Sample unstructured employee data\n",
        "input_text = \"\"\"\n",
        "Extract employee info: Priya Sharma, EMP101, works in Engineering\n",
        "department as Senior Developer. Email: priya.sharma@company.com,\n",
        "Phone: +91-9876543210. Joined on 2020-05-15. Salary: 1200000 INR.\n",
        "Skills: Python, Django, AWS, Docker.\n",
        "\"\"\"\n",
        "\n",
        "result = agent_pydantic.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": input_text}]\n",
        "})\n",
        "\n",
        "employee = result[\"structured_response\"]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PYDANTIC BASEMODEL RESULT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Type: {type(employee)}\")\n",
        "print(f\"\\nEmployee ID: {employee.employee_id}\")\n",
        "print(f\"Name: {employee.full_name}\")\n",
        "print(f\"Email: {employee.email}\")\n",
        "print(f\"Phone: {employee.phone}\")\n",
        "print(f\"Department: {employee.department}\")\n",
        "print(f\"Position: {employee.position}\")\n",
        "if employee.salary:\n",
        "    print(f\"Salary: ₹{employee.salary:,.2f}\")\n",
        "if employee.joining_date:\n",
        "    print(f\"Joining Date: {employee.joining_date}\")\n",
        "if employee.skills:\n",
        "    print(f\"Skills: {', '.join(employee.skills)}\")\n",
        "\n",
        "print(\"\\n✅ Pydantic provides validation, serialization, and IDE support!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPlRJWS4CDfU"
      },
      "source": [
        "## Bonus: Serialize to Dictionary/JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9cYRKu5jCDfU",
        "outputId": "6672bc8b-17c2-4277-bcac-f0e495831649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As Dictionary:\n",
            "{'employee_id': 'EMP101', 'full_name': 'Priya Sharma', 'email': 'priya.sharma@company.com', 'phone': '+91-9876543210', 'department': 'Engineering', 'position': 'Senior Developer', 'salary': 1200000.0, 'joining_date': '2020-05-15', 'skills': ['Python', 'Django', 'AWS', 'Docker']}\n",
            "\n",
            "As JSON:\n",
            "{\n",
            "  \"employee_id\": \"EMP101\",\n",
            "  \"full_name\": \"Priya Sharma\",\n",
            "  \"email\": \"priya.sharma@company.com\",\n",
            "  \"phone\": \"+91-9876543210\",\n",
            "  \"department\": \"Engineering\",\n",
            "  \"position\": \"Senior Developer\",\n",
            "  \"salary\": 1200000.0,\n",
            "  \"joining_date\": \"2020-05-15\",\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"Django\",\n",
            "    \"AWS\",\n",
            "    \"Docker\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Convert to dictionary\n",
        "employee_dict = employee.model_dump()\n",
        "print(\"As Dictionary:\")\n",
        "print(employee_dict)\n",
        "\n",
        "# Convert to JSON\n",
        "employee_json = employee.model_dump_json(indent=2)\n",
        "print(\"\\nAs JSON:\")\n",
        "print(employee_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ7E_Y8yCDfU"
      },
      "source": [
        "---\n",
        "# Lab 2: Python Dataclass\n",
        "\n",
        "**Objective:** Use Python's built-in dataclass for structured output\n",
        "\n",
        "**Benefits:**\n",
        "- Built into Python 3.7+\n",
        "- No external dependencies\n",
        "- Simple and lightweight\n",
        "- Good for prototypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiml4M2eCDfU"
      },
      "source": [
        "## Step 1: Define Dataclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MhCH76CMCDfU",
        "outputId": "5b0ee60a-5619-4f2f-bb72-547d83f28feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ EmployeeInfoDataclass defined!\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class EmployeeInfoDataclass:\n",
        "    \"\"\"Structured employee information using dataclass.\"\"\"\n",
        "\n",
        "    employee_id: str\n",
        "    full_name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    department: str\n",
        "    position: str\n",
        "    salary: Optional[float] = None\n",
        "    joining_date: Optional[str] = None\n",
        "    skills: Optional[List[str]] = None\n",
        "\n",
        "print(\"✅ EmployeeInfoDataclass defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNhD5YVHCDfV"
      },
      "source": [
        "## Step 2: Create Agent with Dataclass Response Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YvVw4becCDfV",
        "outputId": "a7817714-1b87-40f7-9799-df41a47aa232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent created with Dataclass response format!\n"
          ]
        }
      ],
      "source": [
        "agent_dataclass = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    response_format=EmployeeInfoDataclass\n",
        ")\n",
        "\n",
        "print(\"✅ Agent created with Dataclass response format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pww05r1GCDfV"
      },
      "source": [
        "## Step 3: Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EQ3QztKTCDfV",
        "outputId": "daa5170f-14d2-4f0f-d55e-127e51e50b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PYTHON DATACLASS RESULT\n",
            "======================================================================\n",
            "Type: <class '__main__.EmployeeInfoDataclass'>\n",
            "\n",
            "Employee ID: EMP102\n",
            "Name: Rahul Verma\n",
            "Email: rahul.verma@company.com\n",
            "Phone: +91-9876543211\n",
            "Department: Engineering\n",
            "Position: Manager\n",
            "Salary: ₹1,800,000.00\n",
            "Skills: Team Management, System Design, Kubernetes\n",
            "\n",
            "✅ Dataclass is simple and built into Python!\n"
          ]
        }
      ],
      "source": [
        "input_text = \"\"\"\n",
        "Extract info: Rahul Verma (EMP102) - Engineering Manager\n",
        "Contact: rahul.verma@company.com, +91-9876543211\n",
        "Joined: 2018-03-20, Salary: 1800000 INR\n",
        "Skills: Team Management, System Design, Kubernetes\n",
        "\"\"\"\n",
        "\n",
        "result = agent_dataclass.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": input_text}]\n",
        "})\n",
        "\n",
        "employee = result[\"structured_response\"]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PYTHON DATACLASS RESULT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Type: {type(employee)}\")\n",
        "print(f\"\\nEmployee ID: {employee.employee_id}\")\n",
        "print(f\"Name: {employee.full_name}\")\n",
        "print(f\"Email: {employee.email}\")\n",
        "print(f\"Phone: {employee.phone}\")\n",
        "print(f\"Department: {employee.department}\")\n",
        "print(f\"Position: {employee.position}\")\n",
        "if employee.salary:\n",
        "    print(f\"Salary: ₹{employee.salary:,.2f}\")\n",
        "if employee.skills:\n",
        "    print(f\"Skills: {', '.join(employee.skills)}\")\n",
        "\n",
        "print(\"\\n✅ Dataclass is simple and built into Python!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHJlTpkCDfV"
      },
      "source": [
        "---\n",
        "# Lab 3: TypedDict\n",
        "\n",
        "**Objective:** Use TypedDict for dictionary-based structured output\n",
        "\n",
        "**Benefits:**\n",
        "- Dictionary-based access\n",
        "- Type hints for IDEs\n",
        "- Flexible structure\n",
        "- Works well with dict workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wziHa9dYCDfV"
      },
      "source": [
        "## Step 1: Define TypedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5ayhnQ5FCDfV",
        "outputId": "33d2118f-4561-4cd7-89d5-3f28badef124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ EmployeeInfoTypedDict defined!\n"
          ]
        }
      ],
      "source": [
        "class EmployeeInfoTypedDict(TypedDict):\n",
        "    \"\"\"Structured employee information using TypedDict.\"\"\"\n",
        "\n",
        "    employee_id: str\n",
        "    full_name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    department: str\n",
        "    position: str\n",
        "    salary: Optional[float]\n",
        "    joining_date: Optional[str]\n",
        "    skills: Optional[List[str]]\n",
        "\n",
        "print(\"✅ EmployeeInfoTypedDict defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HxikZ1iCDfW"
      },
      "source": [
        "## Step 2: Create Agent with TypedDict Response Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S87mwD9ZCDfW",
        "outputId": "8bfc52b7-70cf-4651-d75a-009bca806d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent created with TypedDict response format!\n"
          ]
        }
      ],
      "source": [
        "agent_typeddict = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    response_format=EmployeeInfoTypedDict\n",
        ")\n",
        "\n",
        "print(\"✅ Agent created with TypedDict response format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enpl9KctCDfW"
      },
      "source": [
        "## Step 3: Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5OGHYxd6CDfW",
        "outputId": "abfd4929-728e-40bc-d335-c8bb45059c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TYPEDDICT RESULT\n",
            "======================================================================\n",
            "Type: <class 'dict'>\n",
            "\n",
            "Employee ID: EMP103\n",
            "Name: Anjali Patel\n",
            "Email: anjali.patel@company.com\n",
            "Phone: +91-9876543212\n",
            "Department: Human Resources\n",
            "Position: HR Director\n",
            "Salary: ₹2,500,000.00\n",
            "Skills: Recruitment, Policy Development, Employee Relations\n",
            "\n",
            "✅ TypedDict returns a dictionary with type hints!\n"
          ]
        }
      ],
      "source": [
        "input_text = \"\"\"\n",
        "Employee details: Anjali Patel, ID: EMP103\n",
        "HR Director, anjali.patel@company.com\n",
        "Phone: +91-9876543212, Joined: 2015-01-10\n",
        "Annual compensation: 2500000 INR\n",
        "Key skills: Recruitment, Policy Development, Employee Relations\n",
        "\"\"\"\n",
        "\n",
        "result = agent_typeddict.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": input_text}]\n",
        "})\n",
        "\n",
        "employee = result[\"structured_response\"]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TYPEDDICT RESULT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Type: {type(employee)}\")\n",
        "print(f\"\\nEmployee ID: {employee['employee_id']}\")\n",
        "print(f\"Name: {employee['full_name']}\")\n",
        "print(f\"Email: {employee['email']}\")\n",
        "print(f\"Phone: {employee['phone']}\")\n",
        "print(f\"Department: {employee['department']}\")\n",
        "print(f\"Position: {employee['position']}\")\n",
        "if employee.get('salary'):\n",
        "    print(f\"Salary: ₹{employee['salary']:,.2f}\")\n",
        "if employee.get('skills'):\n",
        "    print(f\"Skills: {', '.join(employee['skills'])}\")\n",
        "\n",
        "print(\"\\n✅ TypedDict returns a dictionary with type hints!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIxqWHzhCDfW"
      },
      "source": [
        "---\n",
        "# Lab 4: JSON Schema\n",
        "\n",
        "**Objective:** Use JSON Schema for structured output\n",
        "\n",
        "**Benefits:**\n",
        "- Language-agnostic\n",
        "- Fine-grained validation\n",
        "- Enum constraints\n",
        "- Cross-platform compatibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD3LrIUMCDfW"
      },
      "source": [
        "## Step 1: Define JSON Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1oGv1TN5CDfX",
        "outputId": "8e2b43df-3148-4958-ac90-e88a184905b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON Schema defined!\n",
            "\n",
            "Schema preview:\n",
            "{\n",
            "  \"type\": \"object\",\n",
            "  \"title\": \"EmployeeInfo\",\n",
            "  \"description\": \"Structured employee information using JSON Schema\",\n",
            "  \"properties\": {\n",
            "    \"employee_id\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Unique employee identifier (e.g., EMP001)\"\n",
            "    },\n",
            "    \"full_name\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Full name of the employee\"\n",
            "    },\n",
            "    \"email\": {\n",
            "      \"type\": \"string\",\n",
            "      \"description\": \"Work email address\",\n",
            "      \"format\": \"email\"\n",
            "    },\n",
            "    \"phone\": {\n",
            "      \"type\": \"stri...\n"
          ]
        }
      ],
      "source": [
        "EMPLOYEE_INFO_JSON_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"title\": \"EmployeeInfo\",\n",
        "    \"description\": \"Structured employee information using JSON Schema\",\n",
        "    \"properties\": {\n",
        "        \"employee_id\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Unique employee identifier (e.g., EMP001)\"\n",
        "        },\n",
        "        \"full_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Full name of the employee\"\n",
        "        },\n",
        "        \"email\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Work email address\",\n",
        "            \"format\": \"email\"\n",
        "        },\n",
        "        \"phone\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Contact phone number\"\n",
        "        },\n",
        "        \"department\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Department name\",\n",
        "            \"enum\": [\"Engineering\", \"HR\", \"Sales\", \"Marketing\", \"Finance\", \"Operations\"]\n",
        "        },\n",
        "        \"position\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Job title/position\"\n",
        "        },\n",
        "        \"salary\": {\n",
        "            \"type\": [\"number\", \"null\"],\n",
        "            \"description\": \"Annual salary in INR\"\n",
        "        },\n",
        "        \"joining_date\": {\n",
        "            \"type\": [\"string\", \"null\"],\n",
        "            \"description\": \"Date of joining in YYYY-MM-DD format\",\n",
        "            \"format\": \"date\"\n",
        "        },\n",
        "        \"skills\": {\n",
        "            \"type\": [\"array\", \"null\"],\n",
        "            \"description\": \"List of key skills\",\n",
        "            \"items\": {\n",
        "                \"type\": \"string\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"employee_id\", \"full_name\", \"email\", \"phone\", \"department\", \"position\"],\n",
        "    \"additionalProperties\": False\n",
        "}\n",
        "\n",
        "print(\"✅ JSON Schema defined!\")\n",
        "import json\n",
        "print(\"\\nSchema preview:\")\n",
        "print(json.dumps(EMPLOYEE_INFO_JSON_SCHEMA, indent=2)[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PJ6vV8GCDfX"
      },
      "source": [
        "## Step 2: Create Agent with JSON Schema Response Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F_VpsGIGCDfX",
        "outputId": "91c41de6-1837-46fd-dd9a-8775edbf3458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent created with JSON Schema response format!\n"
          ]
        }
      ],
      "source": [
        "agent_json_schema = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    response_format=EMPLOYEE_INFO_JSON_SCHEMA\n",
        ")\n",
        "\n",
        "print(\"✅ Agent created with JSON Schema response format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJGu-w7zCDfX"
      },
      "source": [
        "## Step 3: Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y3IhTJ_UCDfY",
        "outputId": "ea558177-085b-477f-a7f7-a1baf1de8608",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "JSON SCHEMA RESULT\n",
            "======================================================================\n",
            "Type: <class 'dict'>\n",
            "\n",
            "Employee ID: EMP104\n",
            "Name: Arjun Reddy\n",
            "Email: arjun.reddy@company.com\n",
            "Phone: +91-9876543213\n",
            "Department: Sales\n",
            "Position: Sales Team Lead\n",
            "Salary: ₹1,500,000.00\n",
            "Skills: B2B Sales, CRM Management, Negotiation\n",
            "\n",
            "✅ JSON Schema provides fine-grained validation and is language-agnostic!\n"
          ]
        }
      ],
      "source": [
        "input_text = \"\"\"\n",
        "Parse employee info: Arjun Reddy (EMP104), Sales Team Lead\n",
        "Email: arjun.reddy@company.com, Mobile: +91-9876543213\n",
        "Department: Sales, Joining: 2019-07-01\n",
        "CTC: 1500000 per annum\n",
        "Expertise: B2B Sales, CRM Management, Negotiation\n",
        "\"\"\"\n",
        "\n",
        "result = agent_json_schema.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": input_text}]\n",
        "})\n",
        "\n",
        "employee = result[\"structured_response\"]\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"JSON SCHEMA RESULT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Type: {type(employee)}\")\n",
        "print(f\"\\nEmployee ID: {employee['employee_id']}\")\n",
        "print(f\"Name: {employee['full_name']}\")\n",
        "print(f\"Email: {employee['email']}\")\n",
        "print(f\"Phone: {employee['phone']}\")\n",
        "print(f\"Department: {employee['department']}\")\n",
        "print(f\"Position: {employee['position']}\")\n",
        "if employee.get('salary'):\n",
        "    print(f\"Salary: ₹{employee['salary']:,.2f}\")\n",
        "if employee.get('skills'):\n",
        "    print(f\"Skills: {', '.join(employee['skills'])}\")\n",
        "\n",
        "print(\"\\n✅ JSON Schema provides fine-grained validation and is language-agnostic!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ46iCJgCDfZ"
      },
      "source": [
        "---\n",
        "# Comparison Summary\n",
        "\n",
        "Let's compare all four approaches side by side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NofsQO0NCDfZ",
        "outputId": "9402fcab-8017-455b-8afa-a519b65ed8a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPARISON: STRUCTURED OUTPUT FORMATS\n",
            "================================================================================\n",
            "            Format Validation Complexity Dependencies IDE Support    Documentation       Best For\n",
            "Pydantic BaseModel     ✅ Rich     Medium     External ✅ Excellent    ✅ Field-level     Production\n",
            "  Python Dataclass   ⚠️ Basic        Low     Built-in      ✅ Good     ❌ Class-only   Simple cases\n",
            "         TypedDict     ❌ None        Low     Built-in      ✅ Good     ❌ Class-only Dict workflows\n",
            "       JSON Schema     ✅ Rich       High         None   ❌ Limited ✅ Property-level Cross-platform\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION: Use Pydantic BaseModel for most HR use cases!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "comparison_data = {\n",
        "    \"Format\": [\"Pydantic BaseModel\", \"Python Dataclass\", \"TypedDict\", \"JSON Schema\"],\n",
        "    \"Validation\": [\"✅ Rich\", \"⚠️ Basic\", \"❌ None\", \"✅ Rich\"],\n",
        "    \"Complexity\": [\"Medium\", \"Low\", \"Low\", \"High\"],\n",
        "    \"Dependencies\": [\"External\", \"Built-in\", \"Built-in\", \"None\"],\n",
        "    \"IDE Support\": [\"✅ Excellent\", \"✅ Good\", \"✅ Good\", \"❌ Limited\"],\n",
        "    \"Documentation\": [\"✅ Field-level\", \"❌ Class-only\", \"❌ Class-only\", \"✅ Property-level\"],\n",
        "    \"Best For\": [\"Production\", \"Simple cases\", \"Dict workflows\", \"Cross-platform\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPARISON: STRUCTURED OUTPUT FORMATS\")\n",
        "print(\"=\" * 80)\n",
        "print(df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"RECOMMENDATION: Use Pydantic BaseModel for most HR use cases!\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqTO6kCRCDfZ"
      },
      "source": [
        "---\n",
        "# Exercises\n",
        "\n",
        "## Exercise 1: Create a Leave Request Model\n",
        "\n",
        "Create a Pydantic model for leave requests that includes:\n",
        "- employee_id\n",
        "- leave_type (Casual/Sick/Earned)\n",
        "- start_date\n",
        "- end_date\n",
        "- reason\n",
        "- days_requested\n",
        "\n",
        "Then create an agent that extracts this information from text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ1QvfqzCDfZ"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class LeaveRequest(BaseModel):\n",
        "    \"\"\"TODO: Define the leave request model.\"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Create agent and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJNtwgaVCDfZ"
      },
      "source": [
        "## Exercise 2: Performance Review Model\n",
        "\n",
        "Create a model for performance reviews with:\n",
        "- employee_id\n",
        "- reviewer_id\n",
        "- review_period\n",
        "- technical_rating (1-5)\n",
        "- communication_rating (1-5)\n",
        "- achievements (list)\n",
        "- areas_of_improvement (list)\n",
        "- promotion_recommended (boolean)\n",
        "\n",
        "Add validation to ensure ratings are between 1-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlns7d6yCDfZ"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class PerformanceReview(BaseModel):\n",
        "    \"\"\"TODO: Define the performance review model.\"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Add validation constraints\n",
        "# Hint: Use Field(ge=1, le=5) for ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM_BU9t1CDfZ"
      },
      "source": [
        "## Exercise 3: Compare All Four Formats\n",
        "\n",
        "For the same input text, extract employee information using all four formats and compare:\n",
        "1. Execution time\n",
        "2. Response structure\n",
        "3. Ease of access to fields\n",
        "\n",
        "Which format would you choose for a production HR system?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg7jX0NBCDfa"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import time\n",
        "\n",
        "test_input = \"Your test employee data here\"\n",
        "\n",
        "# TODO: Test all four formats and measure time\n",
        "# TODO: Compare results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xomMFzE5CDfa"
      },
      "source": [
        "## 🌟 Bonus Challenge: Multi-Department Report\n",
        "\n",
        "Create a complex nested model that can:\n",
        "1. Process employees from multiple departments\n",
        "2. Calculate average salary per department\n",
        "3. List top skills across all employees\n",
        "4. Identify departments that are understaffed (< 3 employees)\n",
        "5. Generate an executive summary\n",
        "\n",
        "Test with at least 10 employees across 4 departments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtCkUWcuCDfa"
      },
      "outputs": [],
      "source": [
        "# Your code here - Be creative!\n",
        "class DepartmentReport(BaseModel):\n",
        "    \"\"\"TODO: Design your comprehensive report model.\"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFcvqtWeCDfa"
      },
      "source": [
        "---\n",
        "# Conclusion\n",
        "\n",
        "**What you learned:**\n",
        "1. ✅ Four different ways to define structured outputs in LangChain 1.0\n",
        "2. ✅ Using Pydantic BaseModel for production-ready extraction\n",
        "3. ✅ Python Dataclass for simple, lightweight schemas\n",
        "4. ✅ TypedDict for dictionary-based workflows\n",
        "5. ✅ JSON Schema for language-agnostic specifications\n",
        "6. ✅ Nested models for complex data structures\n",
        "7. ✅ Best practices for HR data extraction\n",
        "\n",
        "**Key Takeaways:**\n",
        "- **Pydantic** is the recommended choice for most production use cases\n",
        "- **Field descriptions** are critical for LLM understanding\n",
        "- **Validation** catches errors early and ensures data quality\n",
        "- **Nested models** enable complex hierarchical data structures\n",
        "\n",
        "**Next Steps:**\n",
        "- Integrate with actual HR databases\n",
        "- Add more complex validation rules\n",
        "- Build end-to-end HR automation workflows\n",
        "- Deploy as production API services\n",
        "\n",
        "---\n",
        "**Created with:** LangChain 1.0 + OpenAI + Pydantic\n",
        "\n",
        "**References:**\n",
        "- [LangChain Documentation](https://python.langchain.com/)\n",
        "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
        "- [JSON Schema](https://json-schema.org/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
