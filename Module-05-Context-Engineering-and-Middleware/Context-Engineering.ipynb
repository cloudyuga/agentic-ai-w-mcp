{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Context Engineering for HR Agents - LangChain 1.0\n",
        "\n",
        "**Module:** Context Engineering with Proper Middleware Patterns\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Master dynamic system prompts with runtime configuration\n",
        "- Implement built-in middleware (Summarization, Human-in-the-Loop)\n",
        "- Use decorator-based middleware patterns\n",
        "- Build session context and long-term memory\n",
        "- Create context-aware tools\n",
        "- Implement dynamic model and tool selection\n",
        "\n",
        "**HR Use Cases:**\n",
        "- Personalized employee assistance\n",
        "- Context-aware leave management\n",
        "- Approval workflows\n",
        "- Long consultation sessions\n",
        "\n",
        "**Time:** 3-4 hours\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --pre -U langchain langchain-openai langgraph\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Configure OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "print(\"✅ API Key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Dict, Any\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain_core.tools import tool, InjectedState\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.prebuilt import InjectedStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.types import Command\n",
        "from datetime import datetime\n",
        "from functools import wraps\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"✅ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 1: Dynamic System Prompts with Runtime Configuration\n",
        "\n",
        "**Objective:** Create personalized system prompts based on employee context\n",
        "\n",
        "**Context Engineering Concept:** Access runtime configuration to customize prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Define Employee Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMPLOYEE_DB = {\n",
        "    \"EMP101\": {\n",
        "        \"name\": \"Priya Sharma\",\n",
        "        \"department\": \"Engineering\",\n",
        "        \"role\": \"Senior Developer\",\n",
        "        \"manager\": \"Rahul Verma\",\n",
        "        \"leave_balance\": 12,\n",
        "        \"salary\": 120000,\n",
        "        \"preferences\": {\n",
        "            \"communication_style\": \"detailed\",\n",
        "            \"language\": \"English\"\n",
        "        }\n",
        "    },\n",
        "    \"EMP102\": {\n",
        "        \"name\": \"Rahul Verma\",\n",
        "        \"department\": \"Engineering\",\n",
        "        \"role\": \"Engineering Manager\",\n",
        "        \"manager\": \"Anjali Patel\",\n",
        "        \"leave_balance\": 8,\n",
        "        \"salary\": 180000,\n",
        "        \"preferences\": {\n",
        "            \"communication_style\": \"concise\",\n",
        "            \"language\": \"English\"\n",
        "        }\n",
        "    },\n",
        "    \"EMP103\": {\n",
        "        \"name\": \"Anjali Patel\",\n",
        "        \"department\": \"HR\",\n",
        "        \"role\": \"HR Director\",\n",
        "        \"manager\": None,\n",
        "        \"leave_balance\": 15,\n",
        "        \"salary\": 200000,\n",
        "        \"preferences\": {\n",
        "            \"communication_style\": \"formal\",\n",
        "            \"language\": \"English\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✅ Employee database initialized\")\n",
        "print(f\"Total employees: {len(EMPLOYEE_DB)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Dynamic System Prompt Function\n",
        "\n",
        "This function will be passed to the `prompt` parameter of `create_agent`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_personalized_prompt(state: dict) -> str:\n",
        "    \"\"\"\n",
        "    Create a personalized system prompt based on employee context.\n",
        "    Accesses runtime configuration via state[\"configurable\"].\n",
        "    \"\"\"\n",
        "    # Access runtime configuration\n",
        "    runtime_config = state.get(\"configurable\", {})\n",
        "    employee_id = runtime_config.get(\"employee_id\", \"UNKNOWN\")\n",
        "    \n",
        "    # Lookup employee info\n",
        "    employee = EMPLOYEE_DB.get(employee_id, {})\n",
        "    \n",
        "    if not employee:\n",
        "        return \"You are a helpful HR assistant.\"\n",
        "    \n",
        "    name = employee.get(\"name\", \"Employee\")\n",
        "    department = employee.get(\"department\", \"Unknown\")\n",
        "    role = employee.get(\"role\", \"Unknown\")\n",
        "    leave_balance = employee.get(\"leave_balance\", 0)\n",
        "    comm_style = employee.get(\"preferences\", {}).get(\"communication_style\", \"detailed\")\n",
        "    \n",
        "    # Time-based greeting\n",
        "    hour = datetime.now().hour\n",
        "    if hour < 12:\n",
        "        greeting = \"Good morning\"\n",
        "    elif hour < 17:\n",
        "        greeting = \"Good afternoon\"\n",
        "    else:\n",
        "        greeting = \"Good evening\"\n",
        "    \n",
        "    # Build personalized prompt\n",
        "    base_prompt = f\"\"\"{greeting}! You are an AI HR assistant helping {name} ({employee_id}).\n",
        "\n",
        "Employee Context:\n",
        "- Department: {department}\n",
        "- Role: {role}\n",
        "- Current Leave Balance: {leave_balance} days\n",
        "- Communication Style: {comm_style}\n",
        "\n",
        "Instructions:\n",
        "\"\"\"\n",
        "    \n",
        "    # Customize based on communication style\n",
        "    if comm_style == \"concise\":\n",
        "        base_prompt += \"\"\"- Provide brief, to-the-point responses\n",
        "- Use bullet points when listing information\n",
        "- Avoid lengthy explanations\"\"\"\n",
        "    elif comm_style == \"detailed\":\n",
        "        base_prompt += \"\"\"- Provide comprehensive explanations\n",
        "- Include relevant context and examples\n",
        "- Be thorough in your responses\"\"\"\n",
        "    elif comm_style == \"formal\":\n",
        "        base_prompt += \"\"\"- Maintain professional and formal tone\n",
        "- Use proper business language\n",
        "- Be respectful and courteous\"\"\"\n",
        "    \n",
        "    # Add role-specific instructions\n",
        "    if \"Manager\" in role or \"Director\" in role:\n",
        "        base_prompt += \"\\n- You can access team-level information and reports\"\n",
        "    \n",
        "    base_prompt += \"\\n\\nBe helpful, accurate, and professional in all interactions.\"\n",
        "    \n",
        "    return base_prompt\n",
        "\n",
        "print(\"✅ Dynamic prompt function created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Tools that Access Runtime Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def check_leave_balance(employee_id: Annotated[str, \"Employee ID to check\"]) -> str:\n",
        "    \"\"\"Check the remaining leave balance for an employee.\"\"\"\n",
        "    employee = EMPLOYEE_DB.get(employee_id)\n",
        "    if not employee:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    return f\"{employee['name']} has {employee['leave_balance']} days of leave remaining.\"\n",
        "\n",
        "@tool\n",
        "def get_manager_info(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Get manager information for an employee.\"\"\"\n",
        "    employee = EMPLOYEE_DB.get(employee_id)\n",
        "    if not employee:\n",
        "        return f\"Employee {employee_id} not found\"\n",
        "    \n",
        "    manager_name = employee.get(\"manager\")\n",
        "    if not manager_name:\n",
        "        return f\"{employee['name']} does not have a manager (likely a senior executive).\"\n",
        "    \n",
        "    return f\"{employee['name']}'s manager is {manager_name}.\"\n",
        "\n",
        "@tool\n",
        "def request_leave(\n",
        "    days: Annotated[int, \"Number of days to request\"],\n",
        "    reason: Annotated[str, \"Reason for leave\"],\n",
        "    config: RunnableConfig\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Request leave for the current employee.\n",
        "    This tool automatically knows who is making the request via config.\n",
        "    \"\"\"\n",
        "    # Access runtime configuration to get employee_id\n",
        "    employee_id = config.get(\"configurable\", {}).get(\"employee_id\", \"UNKNOWN\")\n",
        "    \n",
        "    employee = EMPLOYEE_DB.get(employee_id)\n",
        "    if not employee:\n",
        "        return \"Error: Employee not found\"\n",
        "    \n",
        "    name = employee[\"name\"]\n",
        "    current_balance = employee[\"leave_balance\"]\n",
        "    \n",
        "    if days > current_balance:\n",
        "        return f\"❌ Leave request denied. You requested {days} days but only have {current_balance} days available.\"\n",
        "    \n",
        "    new_balance = current_balance - days\n",
        "    request_id = f\"LR-{employee_id}-001\"\n",
        "    \n",
        "    return f\"\"\"✅ Leave request submitted successfully!\n",
        "\n",
        "Request ID: {request_id}\n",
        "Employee: {name} ({employee_id})\n",
        "Days Requested: {days}\n",
        "Reason: {reason}\n",
        "Previous Balance: {current_balance} days\n",
        "New Balance (if approved): {new_balance} days\n",
        "\n",
        "Status: Pending Manager Approval\"\"\"\n",
        "\n",
        "tools = [check_leave_balance, get_manager_info, request_leave]\n",
        "print(\"✅ Context-aware tools defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Agent with Dynamic Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=tools,\n",
        "    prompt=create_personalized_prompt  # Function that generates dynamic prompt\n",
        ")\n",
        "\n",
        "print(\"✅ Agent with dynamic prompt created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Test with Different Employees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Engineer with detailed communication style\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST 1: Priya (Engineer - Detailed Style)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have?\"}]},\n",
        "    config={\"configurable\": {\"employee_id\": \"EMP101\"}}\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n",
        "print()\n",
        "\n",
        "# Test 2: Manager with concise communication style\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST 2: Rahul (Manager - Concise Style)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have?\"}]},\n",
        "    config={\"configurable\": {\"employee_id\": \"EMP102\"}}\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n",
        "print()\n",
        "\n",
        "# Test 3: Context-aware leave request\n",
        "print(\"=\" * 70)\n",
        "print(\"TEST 3: Leave Request (Auto-detects who is requesting)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"I want to request 5 days of leave for vacation\"}]},\n",
        "    config={\"configurable\": {\"employee_id\": \"EMP101\"}}\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\n✅ Notice how responses adapt to each employee!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 2: Built-in Middleware - Summarization\n",
        "\n",
        "**Objective:** Use middleware to manage long conversations\n",
        "\n",
        "**Why?** Long HR consultations can exceed context windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summarization Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleSummarizationMiddleware:\n",
        "    \"\"\"Simplified summarization middleware.\"\"\"\n",
        "    \n",
        "    def __init__(self, model: ChatOpenAI, max_tokens: int = 2000, messages_to_keep: int = 5):\n",
        "        self.model = model\n",
        "        self.max_tokens = max_tokens\n",
        "        self.messages_to_keep = messages_to_keep\n",
        "        self.summary = None\n",
        "    \n",
        "    def estimate_tokens(self, messages) -> int:\n",
        "        \"\"\"Rough token estimation.\"\"\"\n",
        "        total = 0\n",
        "        for msg in messages:\n",
        "            if hasattr(msg, 'content'):\n",
        "                total += len(msg.content.split()) * 1.3\n",
        "        return int(total)\n",
        "    \n",
        "    def summarize_messages(self, messages) -> str:\n",
        "        \"\"\"Create summary of old messages.\"\"\"\n",
        "        conversation = \"\\n\".join([\n",
        "            f\"{msg.type}: {msg.content}\" \n",
        "            for msg in messages \n",
        "            if hasattr(msg, 'content')\n",
        "        ])\n",
        "        \n",
        "        summary_prompt = f\"\"\"Summarize this HR conversation concisely:\n",
        "\n",
        "{conversation}\n",
        "\n",
        "Summary (2-3 sentences):\"\"\"\n",
        "        \n",
        "        response = self.model.invoke([HumanMessage(content=summary_prompt)])\n",
        "        return response.content\n",
        "    \n",
        "    def create_hook(self):\n",
        "        \"\"\"Create a hook function for the agent.\"\"\"\n",
        "        def summarization_hook(state: AgentState) -> dict:\n",
        "            messages = state.get(\"messages\", [])\n",
        "            \n",
        "            if len(messages) < self.messages_to_keep:\n",
        "                return {}\n",
        "            \n",
        "            token_count = self.estimate_tokens(messages)\n",
        "            print(f\"\\n📊 Token count: ~{token_count} (threshold: {self.max_tokens})\")\n",
        "            \n",
        "            if token_count > self.max_tokens:\n",
        "                print(f\"🔄 Summarizing old messages...\")\n",
        "                \n",
        "                to_summarize = messages[:-self.messages_to_keep]\n",
        "                recent_messages = messages[-self.messages_to_keep:]\n",
        "                \n",
        "                summary = self.summarize_messages(to_summarize)\n",
        "                self.summary = summary\n",
        "                \n",
        "                print(f\"✅ Summary created: {len(to_summarize)} messages → {len(summary.split())} words\")\n",
        "                \n",
        "                summary_message = SystemMessage(content=f\"**Previous conversation summary:**\\n{summary}\")\n",
        "                new_messages = [summary_message] + recent_messages\n",
        "                \n",
        "                return {\"messages\": new_messages}\n",
        "            \n",
        "            return {}\n",
        "        \n",
        "        return summarization_hook\n",
        "\n",
        "print(\"✅ Summarization middleware created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Summarization Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create middleware\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "summarization_mw = SimpleSummarizationMiddleware(\n",
        "    model=llm,\n",
        "    max_tokens=500,  # Low threshold for demo\n",
        "    messages_to_keep=3\n",
        ")\n",
        "\n",
        "# Create agent with summarization\n",
        "agent_with_summarization = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[check_leave_balance, get_manager_info],\n",
        "    prompt=create_personalized_prompt,\n",
        "    checkpointer=InMemorySaver()\n",
        ")\n",
        "\n",
        "# Note: In practice, you'd integrate the hook with the agent's execution loop\n",
        "# For this demo, we'll manually call it\n",
        "\n",
        "print(\"✅ Agent with summarization middleware ready!\")\n",
        "print(\"\\nIn production, the summarization hook would be called:\")\n",
        "print(\"  - Before each model invocation\")\n",
        "print(\"  - Automatically condenses long conversations\")\n",
        "print(\"  - Preserves recent context\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 3: Built-in Middleware - Human-in-the-Loop\n",
        "\n",
        "**Objective:** Require human approval for sensitive operations\n",
        "\n",
        "**Use Cases:** Salary updates, terminations, promotions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Human-in-the-Loop Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def update_salary(\n",
        "    employee_id: Annotated[str, \"Employee ID\"],\n",
        "    new_salary: Annotated[int, \"New salary amount\"]\n",
        ") -> str:\n",
        "    \"\"\"Update employee salary. CRITICAL operation requiring approval.\"\"\"\n",
        "    if employee_id in EMPLOYEE_DB:\n",
        "        old_salary = EMPLOYEE_DB[employee_id]['salary']\n",
        "        EMPLOYEE_DB[employee_id]['salary'] = new_salary\n",
        "        return f\"✅ Salary updated for {EMPLOYEE_DB[employee_id]['name']}: ₹{old_salary:,} → ₹{new_salary:,}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def approve_leave(\n",
        "    employee_id: Annotated[str, \"Employee ID\"],\n",
        "    days: Annotated[int, \"Number of leave days\"]\n",
        ") -> str:\n",
        "    \"\"\"Approve leave request. Requires manager approval.\"\"\"\n",
        "    if employee_id in EMPLOYEE_DB:\n",
        "        emp = EMPLOYEE_DB[employee_id]\n",
        "        if emp['leave_balance'] >= days:\n",
        "            EMPLOYEE_DB[employee_id]['leave_balance'] -= days\n",
        "            return f\"✅ Approved {days} days leave for {emp['name']}. Remaining: {EMPLOYEE_DB[employee_id]['leave_balance']} days\"\n",
        "        return f\"❌ Insufficient leave balance. {emp['name']} has only {emp['leave_balance']} days\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "class SimpleHumanInTheLoopMiddleware:\n",
        "    \"\"\"Human approval for sensitive operations.\"\"\"\n",
        "    \n",
        "    def __init__(self, tools_requiring_approval: list[str]):\n",
        "        self.approval_required = tools_requiring_approval\n",
        "        self.pending_approvals = {}\n",
        "        self.approval_history = []\n",
        "    \n",
        "    def create_hook(self):\n",
        "        \"\"\"Create a hook function for the agent.\"\"\"\n",
        "        def approval_hook(state: AgentState) -> dict:\n",
        "            messages = state.get(\"messages\", [])\n",
        "            \n",
        "            for msg in messages:\n",
        "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
        "                    for tool_call in msg.tool_calls:\n",
        "                        tool_name = tool_call.get('name', '')\n",
        "                        \n",
        "                        if tool_name in self.approval_required:\n",
        "                            approval_id = f\"approval_{len(self.pending_approvals) + 1}\"\n",
        "                            \n",
        "                            approval_request = {\n",
        "                                \"id\": approval_id,\n",
        "                                \"tool\": tool_name,\n",
        "                                \"args\": tool_call.get('args', {}),\n",
        "                                \"status\": \"pending\",\n",
        "                                \"timestamp\": datetime.now().isoformat()\n",
        "                            }\n",
        "                            \n",
        "                            self.pending_approvals[approval_id] = approval_request\n",
        "                            \n",
        "                            print(f\"\\n✋ [APPROVAL REQUIRED]\")\n",
        "                            print(f\"   ID: {approval_id}\")\n",
        "                            print(f\"   Tool: {tool_name}\")\n",
        "                            print(f\"   Arguments: {tool_call.get('args', {})}\")\n",
        "                            \n",
        "                            return {\n",
        "                                \"messages\": [(\n",
        "                                    \"assistant\",\n",
        "                                    f\"⏸️  **Approval Required**\\n\\n\"\n",
        "                                    f\"Operation: `{tool_name}`\\n\"\n",
        "                                    f\"Details: {json.dumps(tool_call.get('args', {}), indent=2)}\\n\\n\"\n",
        "                                    f\"Approval ID: `{approval_id}`\\n\\n\"\n",
        "                                    f\"This operation requires manager approval.\"\n",
        "                                )]\n",
        "                            }\n",
        "            \n",
        "            return {}\n",
        "        \n",
        "        return approval_hook\n",
        "    \n",
        "    def approve(self, approval_id: str, approved: bool, approver_id: str = \"unknown\", notes: str = \"\"):\n",
        "        \"\"\"Approve or reject an operation.\"\"\"\n",
        "        if approval_id in self.pending_approvals:\n",
        "            approval = self.pending_approvals[approval_id]\n",
        "            approval[\"status\"] = \"approved\" if approved else \"rejected\"\n",
        "            approval[\"approver_id\"] = approver_id\n",
        "            approval[\"approval_timestamp\"] = datetime.now().isoformat()\n",
        "            approval[\"notes\"] = notes\n",
        "            \n",
        "            self.approval_history.append(approval)\n",
        "            del self.pending_approvals[approval_id]\n",
        "            \n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def get_pending_approvals(self):\n",
        "        return self.pending_approvals\n",
        "    \n",
        "    def get_approval_history(self):\n",
        "        return self.approval_history\n",
        "\n",
        "print(\"✅ Human-in-the-Loop middleware created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Approval Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create middleware\n",
        "hitl_mw = SimpleHumanInTheLoopMiddleware(\n",
        "    tools_requiring_approval=[\"update_salary\", \"approve_leave\"]\n",
        ")\n",
        "\n",
        "# Create agent\n",
        "agent_with_approval = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[check_leave_balance, update_salary, approve_leave],\n",
        "    prompt=create_personalized_prompt\n",
        ")\n",
        "\n",
        "print(\"✅ Agent with approval workflow ready!\")\n",
        "print(\"\\nApproval required for:\")\n",
        "print(\"  - update_salary\")\n",
        "print(\"  - approve_leave\")\n",
        "print(\"\\nWorkflow:\")\n",
        "print(\"  1. Agent requests sensitive operation\")\n",
        "print(\"  2. Middleware intercepts and pauses\")\n",
        "print(\"  3. Manager reviews and approves/rejects\")\n",
        "print(\"  4. Operation completes or is cancelled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 4: Decorator-Based Middleware\n",
        "\n",
        "**Objective:** Use decorators for lifecycle hooks\n",
        "\n",
        "**Decorator Types:**\n",
        "- `@before_agent` - Session initialization\n",
        "- `@before_model` - Per-call logging\n",
        "- `@after_model` - Response tracking\n",
        "- `@after_agent` - Session cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Session-Level Decorators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decorator implementations\n",
        "class before_agent:\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "        wraps(func)(self)\n",
        "    \n",
        "    def __call__(self, state: AgentState) -> dict:\n",
        "        print(f\"\\n🚀 [@before_agent] {self.func.__name__}\")\n",
        "        return self.func(state)\n",
        "\n",
        "class after_agent:\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "        wraps(func)(self)\n",
        "    \n",
        "    def __call__(self, state: AgentState) -> dict:\n",
        "        print(f\"\\n🏁 [@after_agent] {self.func.__name__}\")\n",
        "        return self.func(state)\n",
        "\n",
        "@before_agent\n",
        "def initialize_hr_session(state: AgentState) -> dict:\n",
        "    \"\"\"Initialize HR consultation session.\"\"\"\n",
        "    session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    user_id = state.get(\"configurable\", {}).get(\"employee_id\", \"unknown\")\n",
        "    \n",
        "    print(f\"   📋 Session ID: {session_id}\")\n",
        "    print(f\"   👤 User: {user_id}\")\n",
        "    print(f\"   🕐 Started: {datetime.now().isoformat()}\")\n",
        "    \n",
        "    return {\n",
        "        \"session_id\": session_id,\n",
        "        \"session_start\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "@after_agent\n",
        "def log_session_summary(state: AgentState) -> dict:\n",
        "    \"\"\"Log session summary.\"\"\"\n",
        "    session_id = state.get(\"session_id\", \"unknown\")\n",
        "    start_time = state.get(\"session_start\")\n",
        "    \n",
        "    if start_time:\n",
        "        duration = (datetime.now() - datetime.fromisoformat(start_time)).total_seconds()\n",
        "        print(f\"   ⏱️  Duration: {duration:.2f}s\")\n",
        "    \n",
        "    print(f\"   📋 Session: {session_id}\")\n",
        "    print(f\"   💬 Messages: {len(state.get('messages', []))}\")\n",
        "    print(f\"   🕐 Ended: {datetime.now().isoformat()}\")\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"✅ Session-level decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Call-Level Decorators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_call_stats = {\"total_calls\": 0, \"call_history\": []}\n",
        "\n",
        "class before_model:\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "        wraps(func)(self)\n",
        "    \n",
        "    def __call__(self, state: AgentState) -> dict:\n",
        "        print(f\"\\n🤖 [@before_model] {self.func.__name__}\")\n",
        "        return self.func(state)\n",
        "\n",
        "class after_model:\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "        wraps(func)(self)\n",
        "    \n",
        "    def __call__(self, state: AgentState) -> dict:\n",
        "        print(f\"\\n✅ [@after_model] {self.func.__name__}\")\n",
        "        return self.func(state)\n",
        "\n",
        "@before_model\n",
        "def log_model_call(state: AgentState) -> dict:\n",
        "    \"\"\"Log each model call.\"\"\"\n",
        "    model_call_stats[\"total_calls\"] += 1\n",
        "    call_num = model_call_stats[\"total_calls\"]\n",
        "    \n",
        "    messages = state.get(\"messages\", [])\n",
        "    last_msg = messages[-1].content if messages else \"No message\"\n",
        "    \n",
        "    print(f\"   📞 Model Call #{call_num}\")\n",
        "    print(f\"   💬 Query: {last_msg[:50]}...\")\n",
        "    \n",
        "    return {\"current_model_call\": call_num}\n",
        "\n",
        "@after_model\n",
        "def track_token_usage(state: AgentState) -> dict:\n",
        "    \"\"\"Track token usage.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    tokens = sum(len(m.content.split()) * 1.3 for m in messages if hasattr(m, 'content'))\n",
        "    tokens = int(tokens)\n",
        "    \n",
        "    call_num = state.get(\"current_model_call\", \"?\")\n",
        "    print(f\"   💰 Call #{call_num}: ~{tokens} tokens\")\n",
        "    \n",
        "    return {}\n",
        "\n",
        "print(\"✅ Call-level decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 5: Long-Term Memory\n",
        "\n",
        "**Objective:** Store user preferences across sessions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize memory store\n",
        "memory_store = InMemoryStore()\n",
        "\n",
        "# Pre-populate with preferences\n",
        "memory_store.put(\n",
        "    namespace=(\"employee_preferences\", \"EMP101\"),\n",
        "    key=\"notification_settings\",\n",
        "    value={\n",
        "        \"email_notifications\": True,\n",
        "        \"slack_notifications\": True,\n",
        "        \"frequency\": \"daily\"\n",
        "    }\n",
        ")\n",
        "\n",
        "@tool\n",
        "def get_my_preferences(\n",
        "    preference_type: Annotated[str, \"Type: notification_settings, work_schedule, etc.\"],\n",
        "    store: Annotated[InMemoryStore, InjectedStore],\n",
        "    config: RunnableConfig\n",
        ") -> str:\n",
        "    \"\"\"Retrieve employee preferences from long-term memory.\"\"\"\n",
        "    employee_id = config.get(\"configurable\", {}).get(\"employee_id\", \"UNKNOWN\")\n",
        "    namespace = (\"employee_preferences\", employee_id)\n",
        "    \n",
        "    try:\n",
        "        item = store.get(namespace, preference_type)\n",
        "        if item:\n",
        "            return f\"Your {preference_type}:\\n{json.dumps(item.value, indent=2)}\"\n",
        "        return f\"No {preference_type} found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create agent with memory\n",
        "agent_with_memory = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_my_preferences, check_leave_balance],\n",
        "    prompt=create_personalized_prompt,\n",
        "    store=memory_store\n",
        ")\n",
        "\n",
        "print(\"✅ Agent with long-term memory created!\")\n",
        "\n",
        "# Test\n",
        "result = agent_with_memory.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are my notification settings?\"}]},\n",
        "    config={\"configurable\": {\"employee_id\": \"EMP101\"}}\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST: Retrieve Preferences from Long-Term Memory\")\n",
        "print(\"=\"*70)\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "## Context Engineering Techniques\n",
        "\n",
        "| Technique | Implementation | Use Case |\n",
        "|-----------|----------------|----------|\n",
        "| **Dynamic Prompts** | `prompt=function` | User-specific instructions |\n",
        "| **Runtime Config** | `config={\"configurable\": {...}}` | Access user context in tools |\n",
        "| **Summarization** | Middleware hook | Long conversations |\n",
        "| **Human-in-Loop** | Middleware hook | Sensitive operations |\n",
        "| **Decorators** | `@before_agent`, etc. | Lifecycle hooks |\n",
        "| **Long-term Memory** | `store=InMemoryStore()` | Persistent preferences |\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "✅ **Dynamic Prompts:**\n",
        "- Access runtime config via `state[\"configurable\"]`\n",
        "- Personalize based on user role/preferences\n",
        "- Include time-based context\n",
        "\n",
        "✅ **Middleware:**\n",
        "- Use built-in middleware for common patterns\n",
        "- Create custom hooks for specific needs\n",
        "- Keep lightweight (runs frequently)\n",
        "\n",
        "✅ **Memory:**\n",
        "- Session context for conversations\n",
        "- Long-term memory for preferences\n",
        "- Use InjectedStore in tools\n",
        "\n",
        "## Production Checklist\n",
        "\n",
        "- [ ] Dynamic prompts with user context\n",
        "- [ ] Runtime configuration in tools\n",
        "- [ ] Summarization for long sessions\n",
        "- [ ] Approval workflows for sensitive ops\n",
        "- [ ] Decorator-based monitoring\n",
        "- [ ] Long-term memory persistence\n",
        "- [ ] Error handling in middleware\n",
        "- [ ] Performance monitoring\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've mastered context engineering for HR agents! 🎉"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
