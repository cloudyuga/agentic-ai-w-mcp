{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decorator-based Middlewares for HR Agents - LangChain 1.0 \n",
        "\n",
        "**Module:** Decorator-based Middleware Patterns\n",
        "\n",
        "**What you'll learn:**\n",
        "- 🎯 `@before_agent` - Before agent starts (once per invocation)\n",
        "- 🎯 `@before_model` - Before each model call  \n",
        "- 🎯 `@after_model` - After each model response\n",
        "- 🎯 `@after_agent` - After agent completes (once per invocation)\n",
        "\n",
        "**Key Fix:**\n",
        "- ✅ Uses `middleware` parameter instead of `pre_model_hook`/`post_model_hook`\n",
        "- ✅ Proper decorator imports from `langchain.agents.middleware`\n",
        "- ✅ Correct function signatures with `Runtime` parameter\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --pre -U langchain langchain-openai langgraph\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# CORRECTED IMPORTS\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain.agents.middleware import before_model, after_model, before_agent, after_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.runtime import Runtime\n",
        "from typing import Annotated, Any\n",
        "from datetime import datetime\n",
        "from functools import wraps\n",
        "import time\n",
        "import json\n",
        "\n",
        "print(\"✅ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: HR Data and Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Employee database\n",
        "EMPLOYEES = {\n",
        "    \"101\": {\"name\": \"Priya Sharma\", \"department\": \"Engineering\", \"role\": \"Senior Developer\", \"salary\": 120000},\n",
        "    \"102\": {\"name\": \"Rahul Verma\", \"department\": \"Engineering\", \"role\": \"Manager\", \"salary\": 180000},\n",
        "    \"103\": {\"name\": \"Anjali Patel\", \"department\": \"HR\", \"role\": \"HR Director\", \"salary\": 200000},\n",
        "    \"104\": {\"name\": \"Arjun Reddy\", \"department\": \"Sales\", \"role\": \"Team Lead\", \"salary\": 150000},\n",
        "    \"105\": {\"name\": \"Sneha Gupta\", \"department\": \"Marketing\", \"role\": \"Specialist\", \"salary\": 110000}\n",
        "}\n",
        "\n",
        "@tool\n",
        "def get_employee_info(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Get employee information.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} - {emp['department']} - {emp['role']}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def check_salary(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Check employee salary. SENSITIVE.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        return f\"Salary: ₹{EMPLOYEES[employee_id]['salary']:,}\"\n",
        "    return \"Not found\"\n",
        "\n",
        "@tool\n",
        "def update_employee_record(employee_id: Annotated[str, \"Employee ID\"], field: Annotated[str, \"Field\"], value: Annotated[str, \"Value\"]) -> str:\n",
        "    \"\"\"Update employee record.\"\"\"\n",
        "    if employee_id in EMPLOYEES and field in EMPLOYEES[employee_id]:\n",
        "        old_value = EMPLOYEES[employee_id][field]\n",
        "        EMPLOYEES[employee_id][field] = value\n",
        "        return f\"Updated {field}: {old_value} → {value}\"\n",
        "    return \"Update failed\"\n",
        "\n",
        "print(f\"✅ Loaded {len(EMPLOYEES)} employees\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Session-Level Decorators (CORRECTED)\n",
        "\n",
        "## @before_agent and @after_agent\n",
        "\n",
        "**Key Changes:**\n",
        "- ✅ Import from `langchain.agents.middleware`\n",
        "- ✅ Add `runtime: Runtime` parameter\n",
        "- ✅ Return `dict[str, Any] | None` instead of just `dict`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1.1: @before_agent - Session Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORRECTED: Use official decorator from langchain\n",
        "@before_agent\n",
        "def initialize_hr_session(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Initialize HR consultation session.\"\"\"\n",
        "    if not state.get(\"session_id\"):\n",
        "        session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        \n",
        "        print(f\"\\n🚀 [@before_agent] initialize_hr_session\")\n",
        "        print(f\"   📋 Session ID: {session_id}\")\n",
        "        print(f\"   👤 User: {user_id}\")\n",
        "        print(f\"   🕐 Started: {datetime.now().isoformat()}\")\n",
        "        \n",
        "        return {\n",
        "            \"session_id\": session_id,\n",
        "            \"session_start\": datetime.now().isoformat(),\n",
        "            \"interaction_count\": 0\n",
        "        }\n",
        "    return None\n",
        "\n",
        "@before_agent\n",
        "def verify_user_authentication(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Verify user is authenticated.\"\"\"\n",
        "    user_id = state.get(\"current_user_id\")\n",
        "    \n",
        "    print(f\"\\n🚀 [@before_agent] verify_user_authentication\")\n",
        "    \n",
        "    if not user_id or user_id not in EMPLOYEES:\n",
        "        print(f\"   ❌ Authentication failed for: {user_id}\")\n",
        "        return {\n",
        "            \"authenticated\": False,\n",
        "            \"messages\": [{\"role\": \"assistant\", \"content\": \"❌ Authentication required. Please log in.\"}],\n",
        "            \"jump_to\": \"__end__\"\n",
        "        }\n",
        "    \n",
        "    print(f\"   ✅ Authenticated: {EMPLOYEES[user_id]['name']}\")\n",
        "    return {\"authenticated\": True}\n",
        "\n",
        "print(\"✅ @before_agent decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1.2: @after_agent - Session Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@after_agent\n",
        "def log_session_summary(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Log session summary after completion.\"\"\"\n",
        "    print(f\"\\n🏁 [@after_agent] log_session_summary\")\n",
        "    \n",
        "    session_id = state.get(\"session_id\", \"unknown\")\n",
        "    start_time = state.get(\"session_start\", \"unknown\")\n",
        "    \n",
        "    if start_time != \"unknown\":\n",
        "        duration = (datetime.now() - datetime.fromisoformat(start_time)).total_seconds()\n",
        "        print(f\"   ⏱️  Duration: {duration:.2f}s\")\n",
        "    \n",
        "    print(f\"   📋 Session: {session_id}\")\n",
        "    print(f\"   💬 Messages: {len(state.get('messages', []))}\")\n",
        "    print(f\"   🕐 Ended: {datetime.now().isoformat()}\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_agent\n",
        "def cleanup_resources(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Release resources after session.\"\"\"\n",
        "    print(f\"\\n🏁 [@after_agent] cleanup_resources\")\n",
        "    print(f\"   🧹 Cleaning up session resources...\")\n",
        "    print(f\"   💾 Saving session data...\")\n",
        "    print(f\"   ✅ Cleanup complete\")\n",
        "    return None\n",
        "\n",
        "print(\"✅ @after_agent decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Call-Level Decorators (CORRECTED)\n",
        "\n",
        "## @before_model and @after_model\n",
        "\n",
        "**Runs:** Before/After EACH model call\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.1: @before_model - Per-Call Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global stats\n",
        "model_call_stats = {\n",
        "    \"total_calls\": 0,\n",
        "    \"call_history\": []\n",
        "}\n",
        "\n",
        "@before_model\n",
        "def log_model_call(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Log each model call.\"\"\"\n",
        "    model_call_stats[\"total_calls\"] += 1\n",
        "    call_num = model_call_stats[\"total_calls\"]\n",
        "    \n",
        "    print(f\"\\n🤖 [@before_model] log_model_call\")\n",
        "    print(f\"   📞 Model Call #{call_num}\")\n",
        "    \n",
        "    messages = state.get(\"messages\", [])\n",
        "    if messages:\n",
        "        last_msg = str(messages[-1].content) if hasattr(messages[-1], 'content') else \"No message\"\n",
        "        print(f\"   💬 Query: {last_msg[:50]}...\")\n",
        "    \n",
        "    call_info = {\n",
        "        \"call_number\": call_num,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    model_call_stats[\"call_history\"].append(call_info)\n",
        "    \n",
        "    return {\"current_model_call\": call_num}\n",
        "\n",
        "@before_model\n",
        "def check_rate_limit_per_call(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Check if rate limit exceeded.\"\"\"\n",
        "    if model_call_stats[\"total_calls\"] > 5:\n",
        "        print(f\"\\n🤖 [@before_model] check_rate_limit_per_call\")\n",
        "        print(f\"   ⚠️  Rate limit warning: {model_call_stats['total_calls']} calls\")\n",
        "    return None\n",
        "\n",
        "print(\"✅ @before_model decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.2: @after_model - Response Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response_stats = {\n",
        "    \"total_tokens\": 0,\n",
        "    \"total_cost\": 0.0\n",
        "}\n",
        "\n",
        "@after_model\n",
        "def track_token_usage(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Track token usage per model call.\"\"\"\n",
        "    print(f\"\\n✅ [@after_model] track_token_usage\")\n",
        "    \n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    # Rough estimate\n",
        "    tokens = sum(len(str(m.content).split()) * 1.3 for m in messages if hasattr(m, 'content'))\n",
        "    tokens = int(tokens)\n",
        "    \n",
        "    cost = (tokens / 1000) * 0.002\n",
        "    \n",
        "    response_stats[\"total_tokens\"] += tokens\n",
        "    response_stats[\"total_cost\"] += cost\n",
        "    \n",
        "    call_num = state.get(\"current_model_call\", \"?\")\n",
        "    print(f\"   💰 Call #{call_num}: ~{tokens} tokens (${cost:.4f})\")\n",
        "    print(f\"   📊 Session total: ~{response_stats['total_tokens']} tokens (${response_stats['total_cost']:.4f})\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_model\n",
        "def validate_response_quality(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Validate model response.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if messages:\n",
        "        response = str(messages[-1].content) if hasattr(messages[-1], 'content') else \"\"\n",
        "        \n",
        "        if len(response) < 10:\n",
        "            print(f\"\\n✅ [@after_model] validate_response_quality\")\n",
        "            print(f\"   ⚠️  Warning: Short response ({len(response)} chars)\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "print(\"✅ @after_model decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Performance Tracking\n",
        "\n",
        "Track model call performance and tool execution.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "performance_stats = {\n",
        "    \"calls\": [],\n",
        "    \"total_time\": 0.0\n",
        "}\n",
        "\n",
        "tool_execution_stats = {\n",
        "    \"total_calls\": 0,\n",
        "    \"by_tool\": {},\n",
        "    \"failures\": []\n",
        "}\n",
        "\n",
        "@before_model\n",
        "def measure_performance_pre(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Start performance timer.\"\"\"\n",
        "    print(f\"\\n🤖 [@before_model] measure_performance_pre\")\n",
        "    print(f\"   ⏱️  Starting timer...\")\n",
        "    return {\"model_call_start\": time.time()}\n",
        "\n",
        "@after_model\n",
        "def measure_performance_post(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"End performance timer.\"\"\"\n",
        "    start_time = state.get(\"model_call_start\")\n",
        "    if start_time:\n",
        "        duration = time.time() - start_time\n",
        "        performance_stats[\"calls\"].append(duration)\n",
        "        performance_stats[\"total_time\"] += duration\n",
        "        \n",
        "        avg_time = performance_stats[\"total_time\"] / len(performance_stats[\"calls\"])\n",
        "        \n",
        "        print(f\"\\n✅ [@after_model] measure_performance_post\")\n",
        "        print(f\"   ⚡ This call: {duration:.3f}s\")\n",
        "        print(f\"   📊 Average: {avg_time:.3f}s\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_model\n",
        "def monitor_tool_execution(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Monitor tool calls.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    if messages:\n",
        "        last_msg = messages[-1]\n",
        "        if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
        "            print(f\"\\n✅ [@after_model] monitor_tool_execution\")\n",
        "            for tool_call in last_msg.tool_calls:\n",
        "                tool_name = tool_call.get('name', 'unknown')\n",
        "                \n",
        "                tool_execution_stats[\"total_calls\"] += 1\n",
        "                tool_execution_stats[\"by_tool\"][tool_name] = tool_execution_stats[\"by_tool\"].get(tool_name, 0) + 1\n",
        "                \n",
        "                print(f\"   🔧 Tool: {tool_name}\")\n",
        "                print(f\"   📞 Total tool calls: {tool_execution_stats['total_calls']}\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "print(\"✅ Performance tracking defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: Dynamic Prompt Generation\n",
        "\n",
        "Generate context-aware prompts based on current state.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@before_model\n",
        "def generate_dynamic_context(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Generate context-aware system prompt.\"\"\"\n",
        "    user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "    session_time = datetime.now().strftime(\"%A, %I:%M %p\")\n",
        "    \n",
        "    print(f\"\\n🤖 [@before_model] generate_dynamic_context\")\n",
        "    \n",
        "    # Get user info\n",
        "    user_context = \"\"\n",
        "    if user_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[user_id]\n",
        "        user_context = f\"User: {emp['name']} ({emp['role']}, {emp['department']})\"\n",
        "        print(f\"   👤 {user_context}\")\n",
        "    \n",
        "    # Time-based greeting\n",
        "    hour = datetime.now().hour\n",
        "    greeting = \"Good morning\" if hour < 12 else \"Good afternoon\" if hour < 17 else \"Good evening\"\n",
        "    \n",
        "    print(f\"   ⏰ {greeting}, {session_time}\")\n",
        "    \n",
        "    dynamic_instructions = f\"{greeting}! Current user: {user_context if user_id in EMPLOYEES else 'Unknown'}\"\n",
        "    \n",
        "    return {\"dynamic_context\": dynamic_instructions}\n",
        "\n",
        "print(\"✅ Dynamic context generator defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Complete Demo - All Decorators Together (FIXED)\n",
        "\n",
        "**KEY FIX:** Use `middleware` parameter instead of `pre_model_hook`/`post_model_hook`\n",
        "\n",
        "Let's create an HR agent that uses ALL decorator patterns!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset all stats\n",
        "model_call_stats = {\"total_calls\": 0, \"call_history\": []}\n",
        "response_stats = {\"total_tokens\": 0, \"total_cost\": 0.0}\n",
        "performance_stats = {\"calls\": [], \"total_time\": 0.0}\n",
        "tool_execution_stats = {\"total_calls\": 0, \"by_tool\": {}, \"failures\": []}\n",
        "\n",
        "# Custom state schema\n",
        "class SessionAgentState(AgentState):\n",
        "    current_user_id: str = \"\"\n",
        "    session_id: str = \"\"\n",
        "    session_start: str = \"\"\n",
        "    authenticated: bool = False\n",
        "    current_model_call: int = 0\n",
        "    model_call_start: float = 0.0\n",
        "    dynamic_context: str = \"\"\n",
        "\n",
        "# CORRECTED: Create comprehensive HR agent with middleware\n",
        "comprehensive_hr_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_salary, update_employee_record],\n",
        "    middleware=[  # ✅ USE MIDDLEWARE, NOT pre_model_hook/post_model_hook\n",
        "        # Session-level\n",
        "        verify_user_authentication,\n",
        "        initialize_hr_session,\n",
        "        # Call-level (before)\n",
        "        log_model_call,\n",
        "        check_rate_limit_per_call,\n",
        "        measure_performance_pre,\n",
        "        generate_dynamic_context,\n",
        "        # Call-level (after)\n",
        "        track_token_usage,\n",
        "        validate_response_quality,\n",
        "        measure_performance_post,\n",
        "        monitor_tool_execution,\n",
        "        # Session cleanup\n",
        "        log_session_summary,\n",
        "        cleanup_resources\n",
        "    ],\n",
        "    state_schema=SessionAgentState,\n",
        "    checkpointer=InMemorySaver(),\n",
        "    prompt=\"\"\"You are a comprehensive HR assistant with full middleware monitoring.\n",
        "    \n",
        "    Help employees with their HR needs while maintaining:\n",
        "    - Session tracking\n",
        "    - Performance monitoring  \n",
        "    - Cost tracking\n",
        "    - Tool execution logging\n",
        "    \n",
        "    Be professional and use the dynamic context provided.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"✅ Comprehensive HR Agent created!\")\n",
        "print(\"\\nActive middleware:\")\n",
        "print(\"  🚀 @before_agent: Session init, Authentication\")\n",
        "print(\"  🤖 @before_model: Logging, Rate limit, Performance, Dynamic context\")\n",
        "print(\"  ✅ @after_model: Token tracking, Validation, Performance, Tool monitoring\")\n",
        "print(\"  🏁 @after_agent: Session summary, Cleanup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Complete System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"decorator_demo_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COMPREHENSIVE DECORATOR DEMO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Basic query\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Test 1: Employee Info Query\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = comprehensive_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me about my role and department\"}],\n",
        "    \"current_user_id\": \"101\"\n",
        "}, config)\n",
        "\n",
        "print(f\"\\n🤖 Response: {result['messages'][-1].content[:150]}...\")\n",
        "\n",
        "# Test 2: Salary check\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Test 2: Salary Check\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = comprehensive_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my current salary?\"}],\n",
        "    \"current_user_id\": \"101\"\n",
        "}, config)\n",
        "\n",
        "print(f\"\\n🤖 Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Final stats\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SESSION END - FINAL STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 Model Call Statistics:\")\n",
        "print(f\"   Total calls: {model_call_stats['total_calls']}\")\n",
        "\n",
        "print(f\"\\n💰 Token & Cost Statistics:\")\n",
        "print(f\"   Total tokens: ~{response_stats['total_tokens']}\")\n",
        "print(f\"   Total cost: ${response_stats['total_cost']:.4f}\")\n",
        "\n",
        "print(f\"\\n⏱️  Performance Statistics:\")\n",
        "if performance_stats['calls']:\n",
        "    print(f\"   Total time: {performance_stats['total_time']:.3f}s\")\n",
        "    print(f\"   Average: {performance_stats['total_time']/len(performance_stats['calls']):.3f}s per call\")\n",
        "    print(f\"   Min: {min(performance_stats['calls']):.3f}s\")\n",
        "    print(f\"   Max: {max(performance_stats['calls']):.3f}s\")\n",
        "\n",
        "print(f\"\\n🔧 Tool Execution Statistics:\")\n",
        "print(f\"   Total tool calls: {tool_execution_stats['total_calls']}\")\n",
        "if tool_execution_stats['by_tool']:\n",
        "    print(f\"   Breakdown:\")\n",
        "    for tool, count in tool_execution_stats['by_tool'].items():\n",
        "        print(f\"      • {tool}: {count} times\")\n",
        "\n",
        "print(\"\\n✅ All middleware executed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "## Key Fixes Applied\n",
        "\n",
        "✅ **Correct Imports:**\n",
        "```python\n",
        "from langchain.agents.middleware import before_model, after_model, before_agent, after_agent\n",
        "from langgraph.runtime import Runtime\n",
        "```\n",
        "\n",
        "✅ **Correct Function Signatures:**\n",
        "```python\n",
        "@before_model\n",
        "def my_middleware(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    return None  # or return a dict with state updates\n",
        "```\n",
        "\n",
        "✅ **Correct Agent Creation:**\n",
        "```python\n",
        "agent = create_agent(\n",
        "    model=\"...\",\n",
        "    tools=[...],\n",
        "    middleware=[...],  # NOT pre_model_hook or post_model_hook\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "## Decorator Types\n",
        "\n",
        "| Decorator | Runs | Frequency |\n",
        "|-----------|------|----------|\n",
        "| `@before_agent` | Start of invocation | Once |\n",
        "| `@before_model` | Before each LLM call | Multiple |\n",
        "| `@after_model` | After each response | Multiple |\n",
        "| `@after_agent` | End of invocation | Once |\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:** Explore class-based middleware for more complex scenarios!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
