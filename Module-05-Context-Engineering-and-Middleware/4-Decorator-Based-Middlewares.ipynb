{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decorator-based Middlewares for HR Agents - LangChain 1.0 \n",
        "\n",
        "**Module:** Decorator-based Middleware Patterns\n",
        "\n",
        "**What you'll learn:**\n",
        "- ðŸŽ¯ `@before_agent` - Before agent starts (once per invocation)\n",
        "- ðŸŽ¯ `@before_model` - Before each model call  \n",
        "- ðŸŽ¯ `@after_model` - After each model response\n",
        "- ðŸŽ¯ `@after_agent` - After agent completes (once per invocation)\n",
        "\n",
        "**Key Fix:**\n",
        "- âœ… Uses `middleware` parameter instead of `pre_model_hook`/`post_model_hook`\n",
        "- âœ… Proper decorator imports from `langchain.agents.middleware`\n",
        "- âœ… Correct function signatures with `Runtime` parameter\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --pre -U langchain langchain-openai langgraph\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# CORRECTED IMPORTS\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain.agents.middleware import before_model, after_model, before_agent, after_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.runtime import Runtime\n",
        "from typing import Annotated, Any\n",
        "from datetime import datetime\n",
        "from functools import wraps\n",
        "import time\n",
        "import json\n",
        "\n",
        "print(\"âœ… Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: HR Data and Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Employee database\n",
        "EMPLOYEES = {\n",
        "    \"101\": {\"name\": \"Priya Sharma\", \"department\": \"Engineering\", \"role\": \"Senior Developer\", \"salary\": 120000},\n",
        "    \"102\": {\"name\": \"Rahul Verma\", \"department\": \"Engineering\", \"role\": \"Manager\", \"salary\": 180000},\n",
        "    \"103\": {\"name\": \"Anjali Patel\", \"department\": \"HR\", \"role\": \"HR Director\", \"salary\": 200000},\n",
        "    \"104\": {\"name\": \"Arjun Reddy\", \"department\": \"Sales\", \"role\": \"Team Lead\", \"salary\": 150000},\n",
        "    \"105\": {\"name\": \"Sneha Gupta\", \"department\": \"Marketing\", \"role\": \"Specialist\", \"salary\": 110000}\n",
        "}\n",
        "\n",
        "@tool\n",
        "def get_employee_info(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Get employee information.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} - {emp['department']} - {emp['role']}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def check_salary(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Check employee salary. SENSITIVE.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        return f\"Salary: â‚¹{EMPLOYEES[employee_id]['salary']:,}\"\n",
        "    return \"Not found\"\n",
        "\n",
        "@tool\n",
        "def update_employee_record(employee_id: Annotated[str, \"Employee ID\"], field: Annotated[str, \"Field\"], value: Annotated[str, \"Value\"]) -> str:\n",
        "    \"\"\"Update employee record.\"\"\"\n",
        "    if employee_id in EMPLOYEES and field in EMPLOYEES[employee_id]:\n",
        "        old_value = EMPLOYEES[employee_id][field]\n",
        "        EMPLOYEES[employee_id][field] = value\n",
        "        return f\"Updated {field}: {old_value} â†’ {value}\"\n",
        "    return \"Update failed\"\n",
        "\n",
        "print(f\"âœ… Loaded {len(EMPLOYEES)} employees\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Session-Level Decorators (CORRECTED)\n",
        "\n",
        "## @before_agent and @after_agent\n",
        "\n",
        "**Key Changes:**\n",
        "- âœ… Import from `langchain.agents.middleware`\n",
        "- âœ… Add `runtime: Runtime` parameter\n",
        "- âœ… Return `dict[str, Any] | None` instead of just `dict`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1.1: @before_agent - Session Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CORRECTED: Use official decorator from langchain\n",
        "@before_agent\n",
        "def initialize_hr_session(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Initialize HR consultation session.\"\"\"\n",
        "    if not state.get(\"session_id\"):\n",
        "        session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        \n",
        "        print(f\"\\nðŸš€ [@before_agent] initialize_hr_session\")\n",
        "        print(f\"   ðŸ“‹ Session ID: {session_id}\")\n",
        "        print(f\"   ðŸ‘¤ User: {user_id}\")\n",
        "        print(f\"   ðŸ• Started: {datetime.now().isoformat()}\")\n",
        "        \n",
        "        return {\n",
        "            \"session_id\": session_id,\n",
        "            \"session_start\": datetime.now().isoformat(),\n",
        "            \"interaction_count\": 0\n",
        "        }\n",
        "    return None\n",
        "\n",
        "@before_agent\n",
        "def verify_user_authentication(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Verify user is authenticated.\"\"\"\n",
        "    user_id = state.get(\"current_user_id\")\n",
        "    \n",
        "    print(f\"\\nðŸš€ [@before_agent] verify_user_authentication\")\n",
        "    \n",
        "    if not user_id or user_id not in EMPLOYEES:\n",
        "        print(f\"   âŒ Authentication failed for: {user_id}\")\n",
        "        return {\n",
        "            \"authenticated\": False,\n",
        "            \"messages\": [{\"role\": \"assistant\", \"content\": \"âŒ Authentication required. Please log in.\"}],\n",
        "            \"jump_to\": \"__end__\"\n",
        "        }\n",
        "    \n",
        "    print(f\"   âœ… Authenticated: {EMPLOYEES[user_id]['name']}\")\n",
        "    return {\"authenticated\": True}\n",
        "\n",
        "print(\"âœ… @before_agent decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1.2: @after_agent - Session Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@after_agent\n",
        "def log_session_summary(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Log session summary after completion.\"\"\"\n",
        "    print(f\"\\nðŸ [@after_agent] log_session_summary\")\n",
        "    \n",
        "    session_id = state.get(\"session_id\", \"unknown\")\n",
        "    start_time = state.get(\"session_start\", \"unknown\")\n",
        "    \n",
        "    if start_time != \"unknown\":\n",
        "        duration = (datetime.now() - datetime.fromisoformat(start_time)).total_seconds()\n",
        "        print(f\"   â±ï¸  Duration: {duration:.2f}s\")\n",
        "    \n",
        "    print(f\"   ðŸ“‹ Session: {session_id}\")\n",
        "    print(f\"   ðŸ’¬ Messages: {len(state.get('messages', []))}\")\n",
        "    print(f\"   ðŸ• Ended: {datetime.now().isoformat()}\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_agent\n",
        "def cleanup_resources(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Release resources after session.\"\"\"\n",
        "    print(f\"\\nðŸ [@after_agent] cleanup_resources\")\n",
        "    print(f\"   ðŸ§¹ Cleaning up session resources...\")\n",
        "    print(f\"   ðŸ’¾ Saving session data...\")\n",
        "    print(f\"   âœ… Cleanup complete\")\n",
        "    return None\n",
        "\n",
        "print(\"âœ… @after_agent decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Call-Level Decorators (CORRECTED)\n",
        "\n",
        "## @before_model and @after_model\n",
        "\n",
        "**Runs:** Before/After EACH model call\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.1: @before_model - Per-Call Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global stats\n",
        "model_call_stats = {\n",
        "    \"total_calls\": 0,\n",
        "    \"call_history\": []\n",
        "}\n",
        "\n",
        "@before_model\n",
        "def log_model_call(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Log each model call.\"\"\"\n",
        "    model_call_stats[\"total_calls\"] += 1\n",
        "    call_num = model_call_stats[\"total_calls\"]\n",
        "    \n",
        "    print(f\"\\nðŸ¤– [@before_model] log_model_call\")\n",
        "    print(f\"   ðŸ“ž Model Call #{call_num}\")\n",
        "    \n",
        "    messages = state.get(\"messages\", [])\n",
        "    if messages:\n",
        "        last_msg = str(messages[-1].content) if hasattr(messages[-1], 'content') else \"No message\"\n",
        "        print(f\"   ðŸ’¬ Query: {last_msg[:50]}...\")\n",
        "    \n",
        "    call_info = {\n",
        "        \"call_number\": call_num,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    model_call_stats[\"call_history\"].append(call_info)\n",
        "    \n",
        "    return {\"current_model_call\": call_num}\n",
        "\n",
        "@before_model\n",
        "def check_rate_limit_per_call(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Check if rate limit exceeded.\"\"\"\n",
        "    if model_call_stats[\"total_calls\"] > 5:\n",
        "        print(f\"\\nðŸ¤– [@before_model] check_rate_limit_per_call\")\n",
        "        print(f\"   âš ï¸  Rate limit warning: {model_call_stats['total_calls']} calls\")\n",
        "    return None\n",
        "\n",
        "print(\"âœ… @before_model decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.2: @after_model - Response Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response_stats = {\n",
        "    \"total_tokens\": 0,\n",
        "    \"total_cost\": 0.0\n",
        "}\n",
        "\n",
        "@after_model\n",
        "def track_token_usage(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Track token usage per model call.\"\"\"\n",
        "    print(f\"\\nâœ… [@after_model] track_token_usage\")\n",
        "    \n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    # Rough estimate\n",
        "    tokens = sum(len(str(m.content).split()) * 1.3 for m in messages if hasattr(m, 'content'))\n",
        "    tokens = int(tokens)\n",
        "    \n",
        "    cost = (tokens / 1000) * 0.002\n",
        "    \n",
        "    response_stats[\"total_tokens\"] += tokens\n",
        "    response_stats[\"total_cost\"] += cost\n",
        "    \n",
        "    call_num = state.get(\"current_model_call\", \"?\")\n",
        "    print(f\"   ðŸ’° Call #{call_num}: ~{tokens} tokens (${cost:.4f})\")\n",
        "    print(f\"   ðŸ“Š Session total: ~{response_stats['total_tokens']} tokens (${response_stats['total_cost']:.4f})\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_model\n",
        "def validate_response_quality(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Validate model response.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if messages:\n",
        "        response = str(messages[-1].content) if hasattr(messages[-1], 'content') else \"\"\n",
        "        \n",
        "        if len(response) < 10:\n",
        "            print(f\"\\nâœ… [@after_model] validate_response_quality\")\n",
        "            print(f\"   âš ï¸  Warning: Short response ({len(response)} chars)\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "print(\"âœ… @after_model decorators defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Performance Tracking\n",
        "\n",
        "Track model call performance and tool execution.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "performance_stats = {\n",
        "    \"calls\": [],\n",
        "    \"total_time\": 0.0\n",
        "}\n",
        "\n",
        "tool_execution_stats = {\n",
        "    \"total_calls\": 0,\n",
        "    \"by_tool\": {},\n",
        "    \"failures\": []\n",
        "}\n",
        "\n",
        "@before_model\n",
        "def measure_performance_pre(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Start performance timer.\"\"\"\n",
        "    print(f\"\\nðŸ¤– [@before_model] measure_performance_pre\")\n",
        "    print(f\"   â±ï¸  Starting timer...\")\n",
        "    return {\"model_call_start\": time.time()}\n",
        "\n",
        "@after_model\n",
        "def measure_performance_post(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"End performance timer.\"\"\"\n",
        "    start_time = state.get(\"model_call_start\")\n",
        "    if start_time:\n",
        "        duration = time.time() - start_time\n",
        "        performance_stats[\"calls\"].append(duration)\n",
        "        performance_stats[\"total_time\"] += duration\n",
        "        \n",
        "        avg_time = performance_stats[\"total_time\"] / len(performance_stats[\"calls\"])\n",
        "        \n",
        "        print(f\"\\nâœ… [@after_model] measure_performance_post\")\n",
        "        print(f\"   âš¡ This call: {duration:.3f}s\")\n",
        "        print(f\"   ðŸ“Š Average: {avg_time:.3f}s\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "@after_model\n",
        "def monitor_tool_execution(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Monitor tool calls.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    if messages:\n",
        "        last_msg = messages[-1]\n",
        "        if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
        "            print(f\"\\nâœ… [@after_model] monitor_tool_execution\")\n",
        "            for tool_call in last_msg.tool_calls:\n",
        "                tool_name = tool_call.get('name', 'unknown')\n",
        "                \n",
        "                tool_execution_stats[\"total_calls\"] += 1\n",
        "                tool_execution_stats[\"by_tool\"][tool_name] = tool_execution_stats[\"by_tool\"].get(tool_name, 0) + 1\n",
        "                \n",
        "                print(f\"   ðŸ”§ Tool: {tool_name}\")\n",
        "                print(f\"   ðŸ“ž Total tool calls: {tool_execution_stats['total_calls']}\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "print(\"âœ… Performance tracking defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: Dynamic Prompt Generation\n",
        "\n",
        "Generate context-aware prompts based on current state.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@before_model\n",
        "def generate_dynamic_context(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    \"\"\"Generate context-aware system prompt.\"\"\"\n",
        "    user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "    session_time = datetime.now().strftime(\"%A, %I:%M %p\")\n",
        "    \n",
        "    print(f\"\\nðŸ¤– [@before_model] generate_dynamic_context\")\n",
        "    \n",
        "    # Get user info\n",
        "    user_context = \"\"\n",
        "    if user_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[user_id]\n",
        "        user_context = f\"User: {emp['name']} ({emp['role']}, {emp['department']})\"\n",
        "        print(f\"   ðŸ‘¤ {user_context}\")\n",
        "    \n",
        "    # Time-based greeting\n",
        "    hour = datetime.now().hour\n",
        "    greeting = \"Good morning\" if hour < 12 else \"Good afternoon\" if hour < 17 else \"Good evening\"\n",
        "    \n",
        "    print(f\"   â° {greeting}, {session_time}\")\n",
        "    \n",
        "    dynamic_instructions = f\"{greeting}! Current user: {user_context if user_id in EMPLOYEES else 'Unknown'}\"\n",
        "    \n",
        "    return {\"dynamic_context\": dynamic_instructions}\n",
        "\n",
        "print(\"âœ… Dynamic context generator defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Complete Demo - All Decorators Together (FIXED)\n",
        "\n",
        "**KEY FIX:** Use `middleware` parameter instead of `pre_model_hook`/`post_model_hook`\n",
        "\n",
        "Let's create an HR agent that uses ALL decorator patterns!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset all stats\n",
        "model_call_stats = {\"total_calls\": 0, \"call_history\": []}\n",
        "response_stats = {\"total_tokens\": 0, \"total_cost\": 0.0}\n",
        "performance_stats = {\"calls\": [], \"total_time\": 0.0}\n",
        "tool_execution_stats = {\"total_calls\": 0, \"by_tool\": {}, \"failures\": []}\n",
        "\n",
        "# Custom state schema\n",
        "class SessionAgentState(AgentState):\n",
        "    current_user_id: str = \"\"\n",
        "    session_id: str = \"\"\n",
        "    session_start: str = \"\"\n",
        "    authenticated: bool = False\n",
        "    current_model_call: int = 0\n",
        "    model_call_start: float = 0.0\n",
        "    dynamic_context: str = \"\"\n",
        "\n",
        "# CORRECTED: Create comprehensive HR agent with middleware\n",
        "comprehensive_hr_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_salary, update_employee_record],\n",
        "    middleware=[  # âœ… USE MIDDLEWARE, NOT pre_model_hook/post_model_hook\n",
        "        # Session-level\n",
        "        verify_user_authentication,\n",
        "        initialize_hr_session,\n",
        "        # Call-level (before)\n",
        "        log_model_call,\n",
        "        check_rate_limit_per_call,\n",
        "        measure_performance_pre,\n",
        "        generate_dynamic_context,\n",
        "        # Call-level (after)\n",
        "        track_token_usage,\n",
        "        validate_response_quality,\n",
        "        measure_performance_post,\n",
        "        monitor_tool_execution,\n",
        "        # Session cleanup\n",
        "        log_session_summary,\n",
        "        cleanup_resources\n",
        "    ],\n",
        "    state_schema=SessionAgentState,\n",
        "    checkpointer=InMemorySaver(),\n",
        "    prompt=\"\"\"You are a comprehensive HR assistant with full middleware monitoring.\n",
        "    \n",
        "    Help employees with their HR needs while maintaining:\n",
        "    - Session tracking\n",
        "    - Performance monitoring  \n",
        "    - Cost tracking\n",
        "    - Tool execution logging\n",
        "    \n",
        "    Be professional and use the dynamic context provided.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Comprehensive HR Agent created!\")\n",
        "print(\"\\nActive middleware:\")\n",
        "print(\"  ðŸš€ @before_agent: Session init, Authentication\")\n",
        "print(\"  ðŸ¤– @before_model: Logging, Rate limit, Performance, Dynamic context\")\n",
        "print(\"  âœ… @after_model: Token tracking, Validation, Performance, Tool monitoring\")\n",
        "print(\"  ðŸ @after_agent: Session summary, Cleanup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Complete System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"decorator_demo_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COMPREHENSIVE DECORATOR DEMO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Basic query\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Test 1: Employee Info Query\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = comprehensive_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me about my role and department\"}],\n",
        "    \"current_user_id\": \"101\"\n",
        "}, config)\n",
        "\n",
        "print(f\"\\nðŸ¤– Response: {result['messages'][-1].content[:150]}...\")\n",
        "\n",
        "# Test 2: Salary check\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Test 2: Salary Check\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "result = comprehensive_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is my current salary?\"}],\n",
        "    \"current_user_id\": \"101\"\n",
        "}, config)\n",
        "\n",
        "print(f\"\\nðŸ¤– Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Final stats\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SESSION END - FINAL STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nðŸ“Š Model Call Statistics:\")\n",
        "print(f\"   Total calls: {model_call_stats['total_calls']}\")\n",
        "\n",
        "print(f\"\\nðŸ’° Token & Cost Statistics:\")\n",
        "print(f\"   Total tokens: ~{response_stats['total_tokens']}\")\n",
        "print(f\"   Total cost: ${response_stats['total_cost']:.4f}\")\n",
        "\n",
        "print(f\"\\nâ±ï¸  Performance Statistics:\")\n",
        "if performance_stats['calls']:\n",
        "    print(f\"   Total time: {performance_stats['total_time']:.3f}s\")\n",
        "    print(f\"   Average: {performance_stats['total_time']/len(performance_stats['calls']):.3f}s per call\")\n",
        "    print(f\"   Min: {min(performance_stats['calls']):.3f}s\")\n",
        "    print(f\"   Max: {max(performance_stats['calls']):.3f}s\")\n",
        "\n",
        "print(f\"\\nðŸ”§ Tool Execution Statistics:\")\n",
        "print(f\"   Total tool calls: {tool_execution_stats['total_calls']}\")\n",
        "if tool_execution_stats['by_tool']:\n",
        "    print(f\"   Breakdown:\")\n",
        "    for tool, count in tool_execution_stats['by_tool'].items():\n",
        "        print(f\"      â€¢ {tool}: {count} times\")\n",
        "\n",
        "print(\"\\nâœ… All middleware executed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "## Key Fixes Applied\n",
        "\n",
        "âœ… **Correct Imports:**\n",
        "```python\n",
        "from langchain.agents.middleware import before_model, after_model, before_agent, after_agent\n",
        "from langgraph.runtime import Runtime\n",
        "```\n",
        "\n",
        "âœ… **Correct Function Signatures:**\n",
        "```python\n",
        "@before_model\n",
        "def my_middleware(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    return None  # or return a dict with state updates\n",
        "```\n",
        "\n",
        "âœ… **Correct Agent Creation:**\n",
        "```python\n",
        "agent = create_agent(\n",
        "    model=\"...\",\n",
        "    tools=[...],\n",
        "    middleware=[...],  # NOT pre_model_hook or post_model_hook\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "## Decorator Types\n",
        "\n",
        "| Decorator | Runs | Frequency |\n",
        "|-----------|------|----------|\n",
        "| `@before_agent` | Start of invocation | Once |\n",
        "| `@before_model` | Before each LLM call | Multiple |\n",
        "| `@after_model` | After each response | Multiple |\n",
        "| `@after_agent` | End of invocation | Once |\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:** Explore class-based middleware for more complex scenarios!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
