{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module: Agent Middleware for Execution Control in LangChain 1.0\n",
        "\n",
        "**Building on Previous HR Modules:**\n",
        "- Module 3: Created HR tools with @tool decorator\n",
        "- Module 4: Added short-term memory and persistence\n",
        "- **This Module: Control agent execution with middleware hooks**\n",
        "\n",
        "**What you'll learn:**\n",
        "- üéØ AgentMiddleware hooks (before_model, after_model, modify_model_request)\n",
        "- üîí Access control and authorization\n",
        "- ‚è±Ô∏è Rate limiting and throttling\n",
        "- üìä Logging and monitoring\n",
        "- üõ°Ô∏è Input validation and sanitization\n",
        "- üí∞ Token usage tracking and cost management\n",
        "- üö® Error handling and recovery\n",
        "- ‚úÖ Approval workflows (human-in-the-loop)\n",
        "\n",
        "**Real HR Use Cases:**\n",
        "- Verify employee authorization before sensitive operations\n",
        "- Log all HR queries for compliance\n",
        "- Rate limit requests to prevent abuse\n",
        "- Validate and sanitize employee inputs\n",
        "- Monitor token usage and costs\n",
        "- Implement approval workflows for critical actions\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install LangChain 1.0 alpha packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Configure API Keys & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure API key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Common imports\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import Annotated, TypedDict, Literal\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Understanding Middleware üéØ\n",
        "\n",
        "## What is Middleware?\n",
        "\n",
        "Middleware are functions that intercept the agent execution flow:\n",
        "\n",
        "```\n",
        "User Input ‚Üí [before_model] ‚Üí [modify_model_request] ‚Üí LLM ‚Üí [after_model] ‚Üí Tools ‚Üí Response\n",
        "              ‚Üë                ‚Üë                              ‚Üë\n",
        "              Pre-processing   Request modification           Post-processing\n",
        "```\n",
        "\n",
        "## Three Types of Middleware Hooks\n",
        "\n",
        "### 1. **before_model** \n",
        "- Runs BEFORE the LLM is called\n",
        "- Can update state permanently\n",
        "- Can jump to different nodes (model, tools, __end__)\n",
        "- Use for: authorization, logging, validation\n",
        "\n",
        "### 2. **modify_model_request**\n",
        "- Runs BEFORE the LLM is called (after before_model)\n",
        "- CANNOT update state permanently (stateless)\n",
        "- Can only modify the model request object\n",
        "- Use for: dynamic prompt injection, model switching\n",
        "\n",
        "### 3. **after_model**\n",
        "- Runs AFTER the LLM responds\n",
        "- Can update state permanently\n",
        "- Can jump to different nodes\n",
        "- Use for: response validation, logging, error handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: HR Tools for Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HR Employee Database (mock)\n",
        "EMPLOYEES = {\n",
        "    \"101\": {\"name\": \"Priya Sharma\", \"department\": \"Engineering\", \"role\": \"Senior Developer\", \"leave_balance\": 12},\n",
        "    \"102\": {\"name\": \"Rahul Verma\", \"department\": \"Engineering\", \"role\": \"Manager\", \"leave_balance\": 8},\n",
        "    \"103\": {\"name\": \"Anjali Patel\", \"department\": \"HR\", \"role\": \"Director\", \"leave_balance\": 15},\n",
        "    \"104\": {\"name\": \"Arjun Reddy\", \"department\": \"Sales\", \"role\": \"Team Lead\", \"leave_balance\": 10},\n",
        "    \"105\": {\"name\": \"Sneha Gupta\", \"department\": \"Marketing\", \"role\": \"Specialist\", \"leave_balance\": 5}\n",
        "}\n",
        "\n",
        "# Define HR tools\n",
        "@tool\n",
        "def get_employee_info(employee_id: Annotated[str, \"Employee ID to look up\"]) -> str:\n",
        "    \"\"\"Get employee information by ID.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} - {emp['department']} - {emp['role']}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def check_leave_balance(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Check leave balance for an employee.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} has {emp['leave_balance']} days of leave remaining\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def update_salary(employee_id: Annotated[str, \"Employee ID\"], \n",
        "                  new_salary: Annotated[float, \"New salary amount\"]) -> str:\n",
        "    \"\"\"Update employee salary. SENSITIVE OPERATION - requires authorization.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        return f\"Salary updated for {EMPLOYEES[employee_id]['name']} to ‚Çπ{new_salary:,.2f}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "print(\"‚úÖ HR tools defined!\")\n",
        "print(f\"Available tools: {get_employee_info.name}, {check_leave_balance.name}, {update_salary.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: before_model Hook - Pre-processing\n",
        "\n",
        "**Use before_model for:**\n",
        "- Authorization checks\n",
        "- Input validation\n",
        "- Logging requests\n",
        "- Rate limiting\n",
        "- Early exit conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.1: Basic Logging Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentMiddleware\n",
        "\n",
        "class LoggingMiddleware(AgentMiddleware):\n",
        "    \"\"\"Log all requests before they reach the LLM.\"\"\"\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log the incoming message before LLM processing.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            last_message = messages[-1]\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            print(f\"\\nüìù [LOGGING MIDDLEWARE - {timestamp}]\")\n",
        "            print(f\"   User: {last_message.content}\")\n",
        "        \n",
        "        # Return empty dict - no state modification\n",
        "        return {}\n",
        "\n",
        "# Create agent with logging middleware\n",
        "logging_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[LoggingMiddleware()],\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Logging Middleware\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = logging_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "})\n",
        "\n",
        "print(f\"\\nAgent Response: {result['messages'][-1].content}\")\n",
        "print(\"\\n‚úÖ All requests are now logged!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.2: Authorization Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom state with user context\n",
        "class AuthorizedAgentState(AgentState):\n",
        "    current_user_id: str = \"\"\n",
        "    current_user_role: str = \"\"\n",
        "    authorized: bool = False\n",
        "\n",
        "class AuthorizationMiddleware(AgentMiddleware):\n",
        "    \"\"\"Check if user is authorized for sensitive operations.\"\"\"\n",
        "    \n",
        "    def __init__(self, sensitive_tools: list[str]):\n",
        "        self.sensitive_tools = sensitive_tools\n",
        "    \n",
        "    def before_model(self, state: AuthorizedAgentState) -> dict:\n",
        "        \"\"\"Verify authorization before processing.\"\"\"\n",
        "        user_role = state.get(\"current_user_role\", \"\")\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        \n",
        "        print(f\"\\nüîê [AUTHORIZATION CHECK]\")\n",
        "        print(f\"   User ID: {user_id}\")\n",
        "        print(f\"   Role: {user_role}\")\n",
        "        \n",
        "        # Check if message mentions sensitive operations\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            content = messages[-1].content.lower()\n",
        "            needs_auth = any(tool in content for tool in [\"salary\", \"update\", \"change\"])\n",
        "            \n",
        "            if needs_auth:\n",
        "                # Only HR Directors can update salaries\n",
        "                if user_role == \"HR Director\":\n",
        "                    print(f\"   ‚úÖ Authorized - {user_role} can perform sensitive operations\")\n",
        "                    return {\"authorized\": True}\n",
        "                else:\n",
        "                    print(f\"   ‚ùå UNAUTHORIZED - {user_role} cannot perform this operation\")\n",
        "                    # Jump directly to end, skip LLM\n",
        "                    return {\n",
        "                        \"authorized\": False,\n",
        "                        \"messages\": [(\"assistant\", f\"‚ùå Access Denied: Only HR Directors can perform salary updates. Your role: {user_role}\")],\n",
        "                        \"jump_to\": \"__end__\"  # Skip LLM and tools!\n",
        "                    }\n",
        "        \n",
        "        return {\"authorized\": True}\n",
        "\n",
        "# Create agent with authorization\n",
        "auth_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, update_salary],\n",
        "    middleware=[AuthorizationMiddleware(sensitive_tools=[\"update_salary\"])],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant. Help with employee queries.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Test 1: Unauthorized User (Regular Employee)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = auth_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 150000\"}],\n",
        "    \"current_user_id\": \"104\",\n",
        "    \"current_user_role\": \"Team Lead\"\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 2: Authorized User (HR Director)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = auth_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 150000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Authorization middleware protects sensitive operations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.3: Rate Limiting Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class RateLimitMiddleware(AgentMiddleware):\n",
        "    \"\"\"Limit number of requests per user per time window.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_requests: int = 5, window_seconds: int = 60):\n",
        "        self.max_requests = max_requests\n",
        "        self.window_seconds = window_seconds\n",
        "        self.request_history = defaultdict(list)  # user_id -> [timestamps]\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Check rate limit before processing.\"\"\"\n",
        "        user_id = state.get(\"current_user_id\", \"anonymous\")\n",
        "        now = datetime.now()\n",
        "        \n",
        "        # Clean old requests outside the time window\n",
        "        cutoff = now - timedelta(seconds=self.window_seconds)\n",
        "        self.request_history[user_id] = [\n",
        "            ts for ts in self.request_history[user_id] if ts > cutoff\n",
        "        ]\n",
        "        \n",
        "        # Check if limit exceeded\n",
        "        current_count = len(self.request_history[user_id])\n",
        "        \n",
        "        print(f\"\\n‚è±Ô∏è  [RATE LIMIT CHECK]\")\n",
        "        print(f\"   User: {user_id}\")\n",
        "        print(f\"   Requests in last {self.window_seconds}s: {current_count}/{self.max_requests}\")\n",
        "        \n",
        "        if current_count >= self.max_requests:\n",
        "            print(f\"   ‚ùå RATE LIMIT EXCEEDED\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", f\"‚è±Ô∏è Rate limit exceeded. You have made {current_count} requests in the last {self.window_seconds} seconds. Maximum allowed: {self.max_requests}. Please try again later.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Add current request\n",
        "        self.request_history[user_id].append(now)\n",
        "        print(f\"   ‚úÖ Request allowed ({current_count + 1}/{self.max_requests})\")\n",
        "        return {}\n",
        "\n",
        "# Create agent with rate limiting\n",
        "rate_limited_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[RateLimitMiddleware(max_requests=3, window_seconds=60)],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Rate Limiting (3 requests per 60 seconds)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make 4 requests quickly\n",
        "for i in range(4):\n",
        "    print(f\"\\n--- Request {i+1} ---\")\n",
        "    result = rate_limited_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Who is employee 10{i+1}?\"}],\n",
        "        \"current_user_id\": \"104\"\n",
        "    })\n",
        "    print(f\"Response: {result['messages'][-1].content[:100]}...\")\n",
        "\n",
        "print(\"\\n‚úÖ Rate limiting prevents abuse!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.4: Input Validation Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class InputValidationMiddleware(AgentMiddleware):\n",
        "    \"\"\"Validate and sanitize user inputs.\"\"\"\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Validate input before processing.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            return {}\n",
        "        \n",
        "        last_message = messages[-1]\n",
        "        content = last_message.content\n",
        "        \n",
        "        print(f\"\\nüõ°Ô∏è  [INPUT VALIDATION]\")\n",
        "        \n",
        "        # Check for empty input\n",
        "        if not content or not content.strip():\n",
        "            print(\"   ‚ùå Empty input detected\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", \"Please provide a valid question or request.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Check for SQL injection attempts (basic)\n",
        "        sql_patterns = [r\"DROP\\s+TABLE\", r\"DELETE\\s+FROM\", r\"INSERT\\s+INTO\", r\"--\", r\";\"]\n",
        "        for pattern in sql_patterns:\n",
        "            if re.search(pattern, content, re.IGNORECASE):\n",
        "                print(f\"   ‚ùå Potential SQL injection detected: {pattern}\")\n",
        "                return {\n",
        "                    \"messages\": [(\"assistant\", \"‚ö†Ô∏è Invalid input detected. Please rephrase your request.\")],\n",
        "                    \"jump_to\": \"__end__\"\n",
        "                }\n",
        "        \n",
        "        # Check for excessive length\n",
        "        if len(content) > 1000:\n",
        "            print(f\"   ‚ùå Input too long: {len(content)} characters\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", \"Your message is too long. Please keep it under 1000 characters.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Sanitize: remove special characters (keep basic punctuation)\n",
        "        sanitized = re.sub(r'[^a-zA-Z0-9\\s.,?!-]', '', content)\n",
        "        if sanitized != content:\n",
        "            print(f\"   üßπ Input sanitized (removed special characters)\")\n",
        "            # Update the message with sanitized content\n",
        "            messages[-1].content = sanitized\n",
        "            return {\"messages\": messages}\n",
        "        \n",
        "        print(\"   ‚úÖ Input valid\")\n",
        "        return {}\n",
        "\n",
        "# Create agent with input validation\n",
        "validated_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[InputValidationMiddleware()],\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Input Validation\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Valid input\n",
        "print(\"\\nTest 1: Valid input\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content[:100]}\")\n",
        "\n",
        "# Test 2: SQL injection attempt\n",
        "print(\"\\nTest 2: SQL injection attempt\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"SELECT * FROM employees; DROP TABLE users;\"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 3: Empty input\n",
        "print(\"\\nTest 3: Empty input\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"   \"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Input validation protects against malicious inputs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: modify_model_request Hook - Request Modification\n",
        "\n",
        "**Use modify_model_request for:**\n",
        "- Dynamic prompt injection\n",
        "- Model switching based on context\n",
        "- Adjusting temperature/parameters\n",
        "- Adding system instructions\n",
        "\n",
        "**Important:** This hook is STATELESS - cannot modify permanent state!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 3.1: Dynamic Context Injection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentMiddleware, ModelRequest\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "class ContextInjectionMiddleware(AgentMiddleware):\n",
        "    \"\"\"Inject user context into the system prompt dynamically.\"\"\"\n",
        "    \n",
        "    def modify_model_request(self, state: AgentState, request: ModelRequest) -> ModelRequest:\n",
        "        \"\"\"Add employee context to system prompt.\"\"\"\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        user_role = state.get(\"current_user_role\", \"unknown\")\n",
        "        \n",
        "        # Get employee details\n",
        "        emp_info = \"\"\n",
        "        if user_id in EMPLOYEES:\n",
        "            emp = EMPLOYEES[user_id]\n",
        "            emp_info = f\"Current User: {emp['name']} (ID: {user_id})\\nRole: {emp['role']}\\nDepartment: {emp['department']}\"\n",
        "        \n",
        "        # Inject context into system prompt\n",
        "        original_prompt = request.system_prompt or \"\"\n",
        "        enhanced_prompt = f\"\"\"{original_prompt}\n",
        "\n",
        "CURRENT USER CONTEXT:\n",
        "{emp_info}\n",
        "\n",
        "Always be aware of who you're talking to and personalize responses accordingly.\n",
        "\"\"\"\n",
        "        \n",
        "        print(f\"\\nüíâ [CONTEXT INJECTION]\")\n",
        "        print(f\"   Injected context for: {user_id} ({user_role})\")\n",
        "        \n",
        "        request.system_prompt = enhanced_prompt\n",
        "        return request\n",
        "\n",
        "# Create agent with context injection\n",
        "context_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[check_leave_balance],\n",
        "    middleware=[ContextInjectionMiddleware()],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are a helpful HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Context Injection\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = context_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have?\"}],\n",
        "    \"current_user_id\": \"101\",\n",
        "    \"current_user_role\": \"Senior Developer\"\n",
        "})\n",
        "\n",
        "print(f\"\\nResponse: {result['messages'][-1].content}\")\n",
        "print(\"\\n‚úÖ Agent knows who it's talking to without explicit mention!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 3.2: Dynamic Model Switching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelSwitchingMiddleware(AgentMiddleware):\n",
        "    \"\"\"Switch between models based on query complexity.\"\"\"\n",
        "    \n",
        "    def modify_model_request(self, state: AgentState, request: ModelRequest) -> ModelRequest:\n",
        "        \"\"\"Use GPT-4 for complex queries, GPT-3.5 for simple ones.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            return request\n",
        "        \n",
        "        content = messages[-1].content.lower()\n",
        "        \n",
        "        # Keywords that indicate complex queries\n",
        "        complex_keywords = [\"analyze\", \"compare\", \"evaluate\", \"recommend\", \"strategy\", \"plan\"]\n",
        "        is_complex = any(keyword in content for keyword in complex_keywords)\n",
        "        \n",
        "        if is_complex:\n",
        "            print(f\"\\nüîÑ [MODEL SWITCHING] Complex query detected ‚Üí Using GPT-4\")\n",
        "            request.model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "        else:\n",
        "            print(f\"\\nüîÑ [MODEL SWITCHING] Simple query ‚Üí Using GPT-3.5\")\n",
        "            request.model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "        \n",
        "        return request\n",
        "\n",
        "# Note: This is a demonstration - in practice you'd configure this differently\n",
        "print(\"‚úÖ Model switching middleware defined!\")\n",
        "print(\"üí° In production, this optimizes costs by using cheaper models for simple queries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: after_model Hook - Post-processing\n",
        "\n",
        "**Use after_model for:**\n",
        "- Response validation\n",
        "- Content filtering\n",
        "- Logging responses\n",
        "- Token usage tracking\n",
        "- Error recovery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.1: Response Logging and Audit Trail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AuditTrailMiddleware(AgentMiddleware):\n",
        "    \"\"\"Log all interactions for compliance and auditing.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.audit_log = []\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log request.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            self.request_timestamp = datetime.now()\n",
        "            self.request_content = messages[-1].content\n",
        "        return {}\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log response and save audit entry.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if len(messages) >= 2:\n",
        "            response_content = messages[-1].content\n",
        "            \n",
        "            audit_entry = {\n",
        "                \"timestamp\": self.request_timestamp.isoformat(),\n",
        "                \"user_id\": state.get(\"current_user_id\", \"unknown\"),\n",
        "                \"request\": self.request_content,\n",
        "                \"response\": response_content[:100],  # Truncate for readability\n",
        "                \"tools_used\": [msg.name for msg in messages if hasattr(msg, 'name')]\n",
        "            }\n",
        "            \n",
        "            self.audit_log.append(audit_entry)\n",
        "            \n",
        "            print(f\"\\nüìã [AUDIT LOG ENTRY CREATED]\")\n",
        "            print(f\"   Timestamp: {audit_entry['timestamp']}\")\n",
        "            print(f\"   User: {audit_entry['user_id']}\")\n",
        "            print(f\"   Request: {audit_entry['request'][:50]}...\")\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def get_audit_log(self):\n",
        "        \"\"\"Retrieve audit log.\"\"\"\n",
        "        return self.audit_log\n",
        "\n",
        "# Create agent with audit trail\n",
        "audit_middleware = AuditTrailMiddleware()\n",
        "audit_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance],\n",
        "    middleware=[audit_middleware],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Audit Trail\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make several requests\n",
        "requests = [\n",
        "    (\"Who is employee 101?\", \"101\"),\n",
        "    (\"Check leave balance for employee 102\", \"102\"),\n",
        "    (\"Tell me about employee 103\", \"103\")\n",
        "]\n",
        "\n",
        "for query, user_id in requests:\n",
        "    result = audit_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": query}],\n",
        "        \"current_user_id\": user_id\n",
        "    })\n",
        "\n",
        "# Display audit log\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPLETE AUDIT LOG\")\n",
        "print(\"=\" * 70)\n",
        "for i, entry in enumerate(audit_middleware.get_audit_log(), 1):\n",
        "    print(f\"\\nEntry {i}:\")\n",
        "    print(json.dumps(entry, indent=2))\n",
        "\n",
        "print(\"\\n‚úÖ All interactions logged for compliance!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.2: Token Usage Tracking and Cost Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenTrackingMiddleware(AgentMiddleware):\n",
        "    \"\"\"Track token usage and estimated costs.\"\"\"\n",
        "    \n",
        "    def __init__(self, cost_per_1k_tokens: float = 0.002):\n",
        "        self.total_tokens = 0\n",
        "        self.total_cost = 0.0\n",
        "        self.cost_per_1k = cost_per_1k_tokens\n",
        "        self.usage_history = []\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Estimate token usage after LLM call.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        \n",
        "        # Rough estimation (in production, use actual token counts from API)\n",
        "        estimated_tokens = sum(len(msg.content.split()) * 1.3 for msg in messages)\n",
        "        estimated_tokens = int(estimated_tokens)\n",
        "        \n",
        "        cost = (estimated_tokens / 1000) * self.cost_per_1k\n",
        "        \n",
        "        self.total_tokens += estimated_tokens\n",
        "        self.total_cost += cost\n",
        "        \n",
        "        usage_entry = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"user_id\": state.get(\"current_user_id\", \"unknown\"),\n",
        "            \"tokens\": estimated_tokens,\n",
        "            \"cost\": f\"${cost:.4f}\"\n",
        "        }\n",
        "        self.usage_history.append(usage_entry)\n",
        "        \n",
        "        print(f\"\\nüí∞ [TOKEN USAGE]\")\n",
        "        print(f\"   This call: ~{estimated_tokens} tokens (${cost:.4f})\")\n",
        "        print(f\"   Total: ~{self.total_tokens} tokens (${self.total_cost:.4f})\")\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def get_usage_report(self):\n",
        "        \"\"\"Generate usage report.\"\"\"\n",
        "        return {\n",
        "            \"total_tokens\": self.total_tokens,\n",
        "            \"total_cost\": f\"${self.total_cost:.4f}\",\n",
        "            \"history\": self.usage_history\n",
        "        }\n",
        "\n",
        "# Create agent with token tracking\n",
        "token_middleware = TokenTrackingMiddleware()\n",
        "cost_tracking_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[token_middleware],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Token Usage Tracking\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make several requests\n",
        "for i in range(3):\n",
        "    result = cost_tracking_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Tell me about employee 10{i+1}\"}],\n",
        "        \"current_user_id\": f\"10{i+1}\"\n",
        "    })\n",
        "\n",
        "# Display usage report\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"USAGE REPORT\")\n",
        "print(\"=\" * 70)\n",
        "report = token_middleware.get_usage_report()\n",
        "print(json.dumps(report, indent=2))\n",
        "\n",
        "print(\"\\n‚úÖ Token usage and costs tracked!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.3: Content Filtering and Safety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ContentFilterMiddleware(AgentMiddleware):\n",
        "    \"\"\"Filter responses for sensitive information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Patterns to redact (for demo purposes)\n",
        "        self.sensitive_patterns = {\n",
        "            r'\\b\\d{10}\\b': '[PHONE_REDACTED]',  # Phone numbers\n",
        "            r'\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b': '[EMAIL_REDACTED]',  # Emails\n",
        "            r'\\b\\d{3}-\\d{2}-\\d{4}\\b': '[SSN_REDACTED]',  # SSN format\n",
        "        }\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Filter response for sensitive data.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            return {}\n",
        "        \n",
        "        last_message = messages[-1]\n",
        "        original_content = last_message.content\n",
        "        filtered_content = original_content\n",
        "        \n",
        "        # Apply filters\n",
        "        redacted = False\n",
        "        for pattern, replacement in self.sensitive_patterns.items():\n",
        "            matches = re.findall(pattern, filtered_content, re.IGNORECASE)\n",
        "            if matches:\n",
        "                filtered_content = re.sub(pattern, replacement, filtered_content, flags=re.IGNORECASE)\n",
        "                redacted = True\n",
        "        \n",
        "        if redacted:\n",
        "            print(f\"\\nüõ°Ô∏è  [CONTENT FILTER]\")\n",
        "            print(f\"   ‚ö†Ô∏è  Sensitive information detected and redacted\")\n",
        "            last_message.content = filtered_content\n",
        "            return {\"messages\": messages}\n",
        "        \n",
        "        return {}\n",
        "\n",
        "# Create agent with content filtering\n",
        "filtered_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    middleware=[ContentFilterMiddleware()],\n",
        "    prompt=\"You are an HR assistant. When providing examples, use realistic sample data.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Content Filtering\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = filtered_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Can you give me an example employee contact? Use format: Name, email, phone\"}]\n",
        "})\n",
        "\n",
        "print(f\"\\nResponse: {result['messages'][-1].content}\")\n",
        "print(\"\\n‚úÖ Sensitive information automatically redacted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Combining Multiple Middleware\n",
        "\n",
        "**Production Pattern:** Chain multiple middleware for comprehensive control."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 5.1: Production HR Agent with All Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create production agent with all middleware\n",
        "audit_mw = AuditTrailMiddleware()\n",
        "token_mw = TokenTrackingMiddleware()\n",
        "\n",
        "production_hr_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance, update_salary],\n",
        "    middleware=[\n",
        "        LoggingMiddleware(),              # 1. Log all requests\n",
        "        InputValidationMiddleware(),      # 2. Validate inputs\n",
        "        AuthorizationMiddleware([\"update_salary\"]),  # 3. Check authorization\n",
        "        RateLimitMiddleware(max_requests=10, window_seconds=60),  # 4. Rate limiting\n",
        "        ContextInjectionMiddleware(),     # 5. Inject context\n",
        "        audit_mw,                         # 6. Audit trail\n",
        "        token_mw,                         # 7. Token tracking\n",
        "        ContentFilterMiddleware()         # 8. Filter sensitive data\n",
        "    ],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    checkpointer=InMemorySaver(),\n",
        "    prompt=\"\"\"You are a professional HR assistant for a large organization.\n",
        "    \n",
        "    Your responsibilities:\n",
        "    - Help employees with HR queries\n",
        "    - Check leave balances\n",
        "    - Provide employee information\n",
        "    - Handle sensitive operations with care\n",
        "    \n",
        "    Always be professional, helpful, and security-conscious.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Production HR agent created with 8-layer middleware stack!\")\n",
        "print(\"\\nMiddleware layers:\")\n",
        "print(\"  1. üìù Logging\")\n",
        "print(\"  2. üõ°Ô∏è  Input Validation\")\n",
        "print(\"  3. üîê Authorization\")\n",
        "print(\"  4. ‚è±Ô∏è  Rate Limiting\")\n",
        "print(\"  5. üíâ Context Injection\")\n",
        "print(\"  6. üìã Audit Trail\")\n",
        "print(\"  7. üí∞ Token Tracking\")\n",
        "print(\"  8. üõ°Ô∏è  Content Filtering\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 5.2: Test Production Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"production_test_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PRODUCTION HR AGENT TEST\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Normal query (authorized user)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 1: Employee checking own leave balance\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have remaining?\"}],\n",
        "    \"current_user_id\": \"101\",\n",
        "    \"current_user_role\": \"Senior Developer\"\n",
        "}, config)\n",
        "print(f\"\\nüë§ User: Priya Sharma (101)\")\n",
        "print(f\"ü§ñ Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 2: Unauthorized operation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 2: Unauthorized salary update attempt\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update my salary to 200000\"}],\n",
        "    \"current_user_id\": \"104\",\n",
        "    \"current_user_role\": \"Team Lead\"\n",
        "}, config)\n",
        "print(f\"\\nüë§ User: Arjun Reddy (104)\")\n",
        "print(f\"ü§ñ Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 3: Authorized operation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 3: Authorized salary update (HR Director)\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 180000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "}, config)\n",
        "print(f\"\\nüë§ User: Anjali Patel (103)\")\n",
        "print(f\"ü§ñ Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Display final reports\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"AUDIT & USAGE REPORTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nüìã Audit Log:\")\n",
        "for i, entry in enumerate(audit_mw.get_audit_log(), 1):\n",
        "    print(f\"\\n  Entry {i}:\")\n",
        "    print(f\"    User: {entry['user_id']}\")\n",
        "    print(f\"    Request: {entry['request'][:60]}...\")\n",
        "    print(f\"    Time: {entry['timestamp']}\")\n",
        "\n",
        "print(\"\\nüí∞ Token Usage:\")\n",
        "usage = token_mw.get_usage_report()\n",
        "print(f\"  Total Tokens: {usage['total_tokens']}\")\n",
        "print(f\"  Total Cost: {usage['total_cost']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Production agent with complete middleware protection!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 6: Human-in-the-Loop Middleware\n",
        "\n",
        "**Use Case:** Require human approval for critical operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 6.1: Approval Workflow Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ApprovalWorkflowMiddleware(AgentMiddleware):\n",
        "    \"\"\"Require approval for sensitive operations.\"\"\"\n",
        "    \n",
        "    def __init__(self, approval_required_tools: list[str]):\n",
        "        self.approval_required = approval_required_tools\n",
        "        self.pending_approvals = {}\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Check if tools require approval.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        \n",
        "        # Check if any tool calls are pending\n",
        "        for msg in messages:\n",
        "            if hasattr(msg, 'tool_calls'):\n",
        "                for tool_call in msg.tool_calls:\n",
        "                    tool_name = tool_call.get('name', '')\n",
        "                    \n",
        "                    if tool_name in self.approval_required:\n",
        "                        approval_id = f\"approval_{len(self.pending_approvals)}\"\n",
        "                        \n",
        "                        self.pending_approvals[approval_id] = {\n",
        "                            \"tool\": tool_name,\n",
        "                            \"args\": tool_call.get('args', {}),\n",
        "                            \"status\": \"pending\",\n",
        "                            \"timestamp\": datetime.now().isoformat()\n",
        "                        }\n",
        "                        \n",
        "                        print(f\"\\n‚úã [APPROVAL REQUIRED]\")\n",
        "                        print(f\"   Tool: {tool_name}\")\n",
        "                        print(f\"   Args: {tool_call.get('args', {})}\")\n",
        "                        print(f\"   Approval ID: {approval_id}\")\n",
        "                        \n",
        "                        # In production, this would pause execution\n",
        "                        # and wait for human approval\n",
        "                        return {\n",
        "                            \"messages\": [(\"assistant\", f\"‚è∏Ô∏è  Operation requires approval. Approval ID: {approval_id}. Please have a manager review and approve this action.\")],\n",
        "                            \"jump_to\": \"__end__\"\n",
        "                        }\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def approve(self, approval_id: str, approved: bool):\n",
        "        \"\"\"Approve or reject a pending operation.\"\"\"\n",
        "        if approval_id in self.pending_approvals:\n",
        "            self.pending_approvals[approval_id][\"status\"] = \"approved\" if approved else \"rejected\"\n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def get_pending_approvals(self):\n",
        "        return {k: v for k, v in self.pending_approvals.items() if v[\"status\"] == \"pending\"}\n",
        "\n",
        "# Create agent with approval workflow\n",
        "approval_mw = ApprovalWorkflowMiddleware(approval_required_tools=[\"update_salary\"])\n",
        "approval_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, update_salary],\n",
        "    middleware=[approval_mw],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Approval Workflow\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = approval_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 200000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "})\n",
        "\n",
        "print(f\"\\nAgent Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\nüìã Pending Approvals:\")\n",
        "for approval_id, details in approval_mw.get_pending_approvals().items():\n",
        "    print(f\"\\n  {approval_id}:\")\n",
        "    print(f\"    Tool: {details['tool']}\")\n",
        "    print(f\"    Args: {details['args']}\")\n",
        "    print(f\"    Status: {details['status']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Sensitive operations require human approval!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary & Best Practices\n",
        "\n",
        "## Middleware Execution Order\n",
        "\n",
        "```\n",
        "before_model hooks:    Run in order (1 ‚Üí 2 ‚Üí 3)\n",
        "modify_model_request:  Run in order (1 ‚Üí 2 ‚Üí 3)\n",
        "after_model hooks:     Run in REVERSE order (3 ‚Üí 2 ‚Üí 1)\n",
        "```\n",
        "\n",
        "## When to Use Each Hook\n",
        "\n",
        "| Hook | Use For | Can Modify State | Can Jump |\n",
        "|------|---------|-----------------|----------|\n",
        "| **before_model** | Authorization, validation, logging | ‚úÖ Yes | ‚úÖ Yes |\n",
        "| **modify_model_request** | Dynamic prompts, model switching | ‚ùå No | ‚ùå No |\n",
        "| **after_model** | Response filtering, audit, metrics | ‚úÖ Yes | ‚úÖ Yes |\n",
        "\n",
        "## Production Middleware Stack (Recommended Order)\n",
        "\n",
        "1. **Logging** - Log all incoming requests\n",
        "2. **Input Validation** - Sanitize and validate inputs\n",
        "3. **Rate Limiting** - Prevent abuse\n",
        "4. **Authorization** - Check permissions\n",
        "5. **Context Injection** - Add user context to prompts\n",
        "6. **Audit Trail** - Record all interactions\n",
        "7. **Token Tracking** - Monitor usage and costs\n",
        "8. **Content Filtering** - Redact sensitive data\n",
        "9. **Approval Workflow** - Human-in-the-loop for critical ops\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "‚úÖ **Middleware provides powerful execution control**  \n",
        "‚úÖ **Chain multiple middleware for comprehensive protection**  \n",
        "‚úÖ **Use before_model for pre-processing and authorization**  \n",
        "‚úÖ **Use modify_model_request for dynamic request modification**  \n",
        "‚úÖ **Use after_model for post-processing and auditing**  \n",
        "‚úÖ **Always log and audit in production**  \n",
        "‚úÖ **Implement rate limiting to prevent abuse**  \n",
        "‚úÖ **Track token usage for cost management**  \n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Implement custom middleware for your use case\n",
        "- Add persistent storage for audit logs\n",
        "- Integrate with external authentication systems\n",
        "- Build approval workflows with notification systems\n",
        "- Deploy with production monitoring and alerting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Exercises\n",
        "\n",
        "## Exercise 1: Department-Based Authorization\n",
        "\n",
        "Create middleware that:\n",
        "- Only allows HR department to view salary information\n",
        "- Only allows managers to approve leave requests\n",
        "- Logs unauthorized access attempts\n",
        "\n",
        "**Hint:** Use `before_model` hook with user role checking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class DepartmentAuthMiddleware(AgentMiddleware):\n",
        "    \"\"\"TODO: Implement department-based authorization.\"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Create tools for salary info and leave approval\n",
        "# TODO: Test with different user roles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Smart Caching Middleware\n",
        "\n",
        "Create middleware that:\n",
        "- Caches responses for identical queries\n",
        "- Invalidates cache after 5 minutes\n",
        "- Logs cache hits/misses\n",
        "- Calculates cache hit rate\n",
        "\n",
        "**Hint:** Use `before_model` to check cache, `after_model` to store responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class CachingMiddleware(AgentMiddleware):\n",
        "    \"\"\"TODO: Implement response caching.\"\"\"\n",
        "    def __init__(self, ttl_seconds: int = 300):\n",
        "        self.cache = {}  # query -> (response, timestamp)\n",
        "        self.ttl = ttl_seconds\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "    \n",
        "    # TODO: Implement before_model and after_model\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Multi-Language Support\n",
        "\n",
        "Create middleware that:\n",
        "- Detects user's preferred language from state\n",
        "- Modifies system prompt to include language instruction\n",
        "- Translates common HR terms\n",
        "\n",
        "**Hint:** Use `modify_model_request` hook.\n",
        "\n",
        "**Languages to support:** English, Hindi, Tamil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class MultiLanguageMiddleware(AgentMiddleware):\n",
        "    \"\"\"TODO: Add multi-language support.\"\"\"\n",
        "    \n",
        "    def modify_model_request(self, state: AgentState, request: ModelRequest) -> ModelRequest:\n",
        "        # TODO: Get user's preferred language\n",
        "        # TODO: Modify system prompt with language instruction\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Compliance Reporting\n",
        "\n",
        "Create middleware that generates compliance reports:\n",
        "- Track all data access by employee\n",
        "- Log sensitive operations (salary updates, leave approvals)\n",
        "- Generate daily summary reports\n",
        "- Alert on suspicious patterns (e.g., excessive queries)\n",
        "\n",
        "**Hint:** Combine `before_model` and `after_model` hooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class ComplianceReportingMiddleware(AgentMiddleware):\n",
        "    \"\"\"TODO: Implement compliance reporting.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.access_log = []\n",
        "        self.sensitive_ops = []\n",
        "    \n",
        "    # TODO: Implement tracking and reporting\n",
        "    \n",
        "    def generate_daily_report(self):\n",
        "        \"\"\"TODO: Generate compliance report.\"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåü Bonus Challenge: Advanced Approval System\n",
        "\n",
        "Create a complete approval workflow:\n",
        "- Different approval levels (Manager ‚Üí Director ‚Üí C-Level)\n",
        "- Email notifications for pending approvals\n",
        "- Time-based auto-rejection (if not approved in 24hrs)\n",
        "- Approval history and audit trail\n",
        "- Web dashboard to view and approve requests\n",
        "\n",
        "**This is open-ended - be creative!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here - this is a complex, production-ready system!\n",
        "# Consider using:\n",
        "# - Database for persistent storage\n",
        "# - Message queue for notifications\n",
        "# - Scheduled jobs for auto-rejection\n",
        "# - REST API for approval interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Conclusion\n",
        "\n",
        "**Congratulations! You've mastered Agent Middleware in LangChain 1.0!**\n",
        "\n",
        "You now know how to:\n",
        "- ‚úÖ Control agent execution with middleware hooks\n",
        "- ‚úÖ Implement authorization and access control\n",
        "- ‚úÖ Add rate limiting and abuse prevention\n",
        "- ‚úÖ Track usage and manage costs\n",
        "- ‚úÖ Create audit trails for compliance\n",
        "- ‚úÖ Build human-in-the-loop workflows\n",
        "- ‚úÖ Combine multiple middleware for production systems\n",
        "\n",
        "**Remember:** Middleware is essential for production agents. Always implement proper:\n",
        "- üîê Authorization\n",
        "- üìã Audit logging\n",
        "- ‚è±Ô∏è  Rate limiting\n",
        "- üí∞ Cost tracking\n",
        "- üõ°Ô∏è  Security controls\n",
        "\n",
        "---\n",
        "**Next Module:** Advanced Agent Patterns and Multi-Agent Systems\n",
        "\n",
        "**References:**\n",
        "- [LangChain Middleware Documentation](https://docs.langchain.com/oss/python/langchain/middleware)\n",
        "- [LangChain Agents Guide](https://python.langchain.com/docs/concepts/agents/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
