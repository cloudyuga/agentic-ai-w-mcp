{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module: Agent Hooks for Execution Control in LangChain 1.0\n",
        "\n",
        "**Building on Previous HR Modules:**\n",
        "- Module 3: Created HR tools with @tool decorator\n",
        "- Module 4: Added short-term memory and persistence\n",
        "- **This Module: Control agent execution with hook functions**\n",
        "\n",
        "**What you'll learn:**\n",
        "- ðŸŽ¯ pre_model_hook and post_model_hook patterns\n",
        "- ðŸ”’ Access control and authorization\n",
        "- â±ï¸ Rate limiting and throttling\n",
        "- ðŸ“Š Logging and monitoring\n",
        "- ðŸ›¡ï¸ Input validation and sanitization\n",
        "- ðŸ’° Token usage tracking and cost management\n",
        "- ðŸš¨ Error handling and recovery\n",
        "- âœ… Approval workflows (human-in-the-loop)\n",
        "- ðŸ”— Chaining multiple hooks for production systems\n",
        "\n",
        "**Real HR Use Cases:**\n",
        "- Verify employee authorization before sensitive operations\n",
        "- Log all HR queries for compliance\n",
        "- Rate limit requests to prevent abuse\n",
        "- Validate and sanitize employee inputs\n",
        "- Monitor token usage and costs\n",
        "- Implement approval workflows for critical actions\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install LangChain 1.0 alpha packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph\n",
        "!pip install langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Configure API Keys & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure API key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Common imports\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import Annotated, TypedDict, Literal\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"âœ… Setup complete!\")\n",
        "print(\"\\nðŸ“Œ IMPORTANT NOTE:\")\n",
        "print(\"The LangChain documentation shows AgentMiddleware classes, but in LangChain 1.0,\")\n",
        "print(\"we use simple hook FUNCTIONS instead:\")\n",
        "print(\"  â€¢ pre_model_hook: runs before LLM\")\n",
        "print(\"  â€¢ post_model_hook: runs after LLM\")\n",
        "print(\"\\nThis notebook uses the correct LangChain 1.0 patterns!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Understanding Hooks ðŸŽ¯\n",
        "\n",
        "## What are Hooks?\n",
        "\n",
        "Hooks are functions that intercept the agent execution flow:\n",
        "\n",
        "```\n",
        "User Input â†’ [pre_model_hook] â†’ LLM â†’ [post_model_hook] â†’ Tools â†’ Response\n",
        "              â†‘                         â†‘\n",
        "              Pre-processing            Post-processing\n",
        "```\n",
        "\n",
        "## Two Types of Hooks in LangChain 1.0\n",
        "\n",
        "### 1. **pre_model_hook** \n",
        "- Runs BEFORE the LLM is called\n",
        "- Can update state permanently\n",
        "- Can jump to different nodes (using `jump_to: \"__end__\"`)\n",
        "- Use for: authorization, logging, validation, rate limiting\n",
        "- Signature: `def hook(state: AgentState) -> dict`\n",
        "\n",
        "### 2. **post_model_hook**\n",
        "- Runs AFTER the LLM responds\n",
        "- Can update state permanently\n",
        "- Can jump to different nodes\n",
        "- Use for: response validation, logging, metrics, content filtering\n",
        "- Signature: `def hook(state: AgentState) -> dict`\n",
        "\n",
        "## Hook Return Values\n",
        "\n",
        "Hooks return a dictionary with state updates:\n",
        "\n",
        "```python\n",
        "# Normal flow - return empty dict or state updates\n",
        "return {\"key\": \"value\"}\n",
        "\n",
        "# Early exit - jump to end\n",
        "return {\n",
        "    \"messages\": [(\"assistant\", \"Access denied\")],\n",
        "    \"jump_to\": \"__end__\"  # Skip LLM/tools and end immediately\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: HR Tools for Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HR Employee Database (mock)\n",
        "EMPLOYEES = {\n",
        "    \"101\": {\"name\": \"Priya Sharma\", \"department\": \"Engineering\", \"role\": \"Senior Developer\", \"leave_balance\": 12},\n",
        "    \"102\": {\"name\": \"Rahul Verma\", \"department\": \"Engineering\", \"role\": \"Manager\", \"leave_balance\": 8},\n",
        "    \"103\": {\"name\": \"Anjali Patel\", \"department\": \"HR\", \"role\": \"Director\", \"leave_balance\": 15},\n",
        "    \"104\": {\"name\": \"Arjun Reddy\", \"department\": \"Sales\", \"role\": \"Team Lead\", \"leave_balance\": 10},\n",
        "    \"105\": {\"name\": \"Sneha Gupta\", \"department\": \"Marketing\", \"role\": \"Specialist\", \"leave_balance\": 5}\n",
        "}\n",
        "\n",
        "# Define HR tools\n",
        "@tool\n",
        "def get_employee_info(employee_id: Annotated[str, \"Employee ID to look up\"]) -> str:\n",
        "    \"\"\"Get employee information by ID.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} - {emp['department']} - {emp['role']}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def check_leave_balance(employee_id: Annotated[str, \"Employee ID\"]) -> str:\n",
        "    \"\"\"Check leave balance for an employee.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        emp = EMPLOYEES[employee_id]\n",
        "        return f\"{emp['name']} has {emp['leave_balance']} days of leave remaining\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "@tool\n",
        "def update_salary(employee_id: Annotated[str, \"Employee ID\"], \n",
        "                  new_salary: Annotated[float, \"New salary amount\"]) -> str:\n",
        "    \"\"\"Update employee salary. SENSITIVE OPERATION - requires authorization.\"\"\"\n",
        "    if employee_id in EMPLOYEES:\n",
        "        return f\"Salary updated for {EMPLOYEES[employee_id]['name']} to â‚¹{new_salary:,.2f}\"\n",
        "    return f\"Employee {employee_id} not found\"\n",
        "\n",
        "print(\"âœ… HR tools defined!\")\n",
        "print(f\"Available tools: {get_employee_info.name}, {check_leave_balance.name}, {update_salary.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: pre_model_hook - Pre-processing\n",
        "\n",
        "**Use pre_model_hook for:**\n",
        "- Authorization checks\n",
        "- Input validation\n",
        "- Logging requests\n",
        "- Rate limiting\n",
        "- Early exit conditions\n",
        "\n",
        "**Key Pattern:**\n",
        "```python\n",
        "def my_pre_hook(state: AgentState) -> dict:\n",
        "    # Do validation/checks\n",
        "    if should_block:\n",
        "        return {\n",
        "            \"messages\": [(\"assistant\", \"Error message\")],\n",
        "            \"jump_to\": \"__end__\"  # Skip LLM\n",
        "        }\n",
        "    return {}  # Continue normally\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.1: Basic Logging Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentMiddleware\n",
        "\n",
        "class LoggingMiddleware(AgentMiddleware):\n",
        "    \"\"\"Log all requests before they reach the LLM.\"\"\"\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log the incoming message before LLM processing.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            last_message = messages[-1]\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            print(f\"\\nðŸ“ [LOGGING MIDDLEWARE - {timestamp}]\")\n",
        "            print(f\"   User: {last_message.content}\")\n",
        "        \n",
        "        # Return empty dict - no state modification\n",
        "        return {}\n",
        "\n",
        "# Create agent with logging middleware\n",
        "logging_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[LoggingMiddleware()],\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Logging Middleware\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = logging_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "})\n",
        "\n",
        "print(f\"\\nAgent Response: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ… All requests are now logged!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.2: Authorization Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom state with user context\n",
        "class AuthorizedAgentState(AgentState):\n",
        "    current_user_id: str = \"\"\n",
        "    current_user_role: str = \"\"\n",
        "    authorized: bool = False\n",
        "\n",
        "class AuthorizationMiddleware(AgentMiddleware):\n",
        "    \"\"\"Check if user is authorized for sensitive operations.\"\"\"\n",
        "    \n",
        "    def __init__(self, sensitive_tools: list[str]):\n",
        "        self.sensitive_tools = sensitive_tools\n",
        "    \n",
        "    def before_model(self, state: AuthorizedAgentState) -> dict:\n",
        "        \"\"\"Verify authorization before processing.\"\"\"\n",
        "        user_role = state.get(\"current_user_role\", \"\")\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        \n",
        "        print(f\"\\nðŸ” [AUTHORIZATION CHECK]\")\n",
        "        print(f\"   User ID: {user_id}\")\n",
        "        print(f\"   Role: {user_role}\")\n",
        "        \n",
        "        # Check if message mentions sensitive operations\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            content = messages[-1].content.lower()\n",
        "            needs_auth = any(tool in content for tool in [\"salary\", \"update\", \"change\"])\n",
        "            \n",
        "            if needs_auth:\n",
        "                # Only HR Directors can update salaries\n",
        "                if user_role == \"HR Director\":\n",
        "                    print(f\"   âœ… Authorized - {user_role} can perform sensitive operations\")\n",
        "                    return {\"authorized\": True}\n",
        "                else:\n",
        "                    print(f\"   âŒ UNAUTHORIZED - {user_role} cannot perform this operation\")\n",
        "                    # Jump directly to end, skip LLM\n",
        "                    return {\n",
        "                        \"authorized\": False,\n",
        "                        \"messages\": [(\"assistant\", f\"âŒ Access Denied: Only HR Directors can perform salary updates. Your role: {user_role}\")],\n",
        "                        \"jump_to\": \"__end__\"  # Skip LLM and tools!\n",
        "                    }\n",
        "        \n",
        "        return {\"authorized\": True}\n",
        "\n",
        "# Create agent with authorization\n",
        "auth_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, update_salary],\n",
        "    middleware=[AuthorizationMiddleware(sensitive_tools=[\"update_salary\"])],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant. Help with employee queries.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Test 1: Unauthorized User (Regular Employee)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = auth_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 150000\"}],\n",
        "    \"current_user_id\": \"104\",\n",
        "    \"current_user_role\": \"Team Lead\"\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 2: Authorized User (HR Director)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = auth_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 150000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\nâœ… Authorization middleware protects sensitive operations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.3: Rate Limiting Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class RateLimitMiddleware(AgentMiddleware):\n",
        "    \"\"\"Limit number of requests per user per time window.\"\"\"\n",
        "    \n",
        "    def __init__(self, max_requests: int = 5, window_seconds: int = 60):\n",
        "        self.max_requests = max_requests\n",
        "        self.window_seconds = window_seconds\n",
        "        self.request_history = defaultdict(list)  # user_id -> [timestamps]\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Check rate limit before processing.\"\"\"\n",
        "        user_id = state.get(\"current_user_id\", \"anonymous\")\n",
        "        now = datetime.now()\n",
        "        \n",
        "        # Clean old requests outside the time window\n",
        "        cutoff = now - timedelta(seconds=self.window_seconds)\n",
        "        self.request_history[user_id] = [\n",
        "            ts for ts in self.request_history[user_id] if ts > cutoff\n",
        "        ]\n",
        "        \n",
        "        # Check if limit exceeded\n",
        "        current_count = len(self.request_history[user_id])\n",
        "        \n",
        "        print(f\"\\nâ±ï¸  [RATE LIMIT CHECK]\")\n",
        "        print(f\"   User: {user_id}\")\n",
        "        print(f\"   Requests in last {self.window_seconds}s: {current_count}/{self.max_requests}\")\n",
        "        \n",
        "        if current_count >= self.max_requests:\n",
        "            print(f\"   âŒ RATE LIMIT EXCEEDED\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", f\"â±ï¸ Rate limit exceeded. You have made {current_count} requests in the last {self.window_seconds} seconds. Maximum allowed: {self.max_requests}. Please try again later.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Add current request\n",
        "        self.request_history[user_id].append(now)\n",
        "        print(f\"   âœ… Request allowed ({current_count + 1}/{self.max_requests})\")\n",
        "        return {}\n",
        "\n",
        "# Create agent with rate limiting\n",
        "rate_limited_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[RateLimitMiddleware(max_requests=3, window_seconds=60)],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Rate Limiting (3 requests per 60 seconds)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make 4 requests quickly\n",
        "for i in range(4):\n",
        "    print(f\"\\n--- Request {i+1} ---\")\n",
        "    result = rate_limited_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Who is employee 10{i+1}?\"}],\n",
        "        \"current_user_id\": \"104\"\n",
        "    })\n",
        "    print(f\"Response: {result['messages'][-1].content[:100]}...\")\n",
        "\n",
        "print(\"\\nâœ… Rate limiting prevents abuse!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 2.4: Input Validation Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class InputValidationMiddleware(AgentMiddleware):\n",
        "    \"\"\"Validate and sanitize user inputs.\"\"\"\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Validate input before processing.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            return {}\n",
        "        \n",
        "        last_message = messages[-1]\n",
        "        content = last_message.content\n",
        "        \n",
        "        print(f\"\\nðŸ›¡ï¸  [INPUT VALIDATION]\")\n",
        "        \n",
        "        # Check for empty input\n",
        "        if not content or not content.strip():\n",
        "            print(\"   âŒ Empty input detected\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", \"Please provide a valid question or request.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Check for SQL injection attempts (basic)\n",
        "        sql_patterns = [r\"DROP\\s+TABLE\", r\"DELETE\\s+FROM\", r\"INSERT\\s+INTO\", r\"--\", r\";\"]\n",
        "        for pattern in sql_patterns:\n",
        "            if re.search(pattern, content, re.IGNORECASE):\n",
        "                print(f\"   âŒ Potential SQL injection detected: {pattern}\")\n",
        "                return {\n",
        "                    \"messages\": [(\"assistant\", \"âš ï¸ Invalid input detected. Please rephrase your request.\")],\n",
        "                    \"jump_to\": \"__end__\"\n",
        "                }\n",
        "        \n",
        "        # Check for excessive length\n",
        "        if len(content) > 1000:\n",
        "            print(f\"   âŒ Input too long: {len(content)} characters\")\n",
        "            return {\n",
        "                \"messages\": [(\"assistant\", \"Your message is too long. Please keep it under 1000 characters.\")],\n",
        "                \"jump_to\": \"__end__\"\n",
        "            }\n",
        "        \n",
        "        # Sanitize: remove special characters (keep basic punctuation)\n",
        "        sanitized = re.sub(r'[^a-zA-Z0-9\\s.,?!-]', '', content)\n",
        "        if sanitized != content:\n",
        "            print(f\"   ðŸ§¹ Input sanitized (removed special characters)\")\n",
        "            # Update the message with sanitized content\n",
        "            messages[-1].content = sanitized\n",
        "            return {\"messages\": messages}\n",
        "        \n",
        "        print(\"   âœ… Input valid\")\n",
        "        return {}\n",
        "\n",
        "# Create agent with input validation\n",
        "validated_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[InputValidationMiddleware()],\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Input Validation\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Valid input\n",
        "print(\"\\nTest 1: Valid input\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is employee 101?\"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content[:100]}\")\n",
        "\n",
        "# Test 2: SQL injection attempt\n",
        "print(\"\\nTest 2: SQL injection attempt\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"SELECT * FROM employees; DROP TABLE users;\"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 3: Empty input\n",
        "print(\"\\nTest 3: Empty input\")\n",
        "result = validated_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"   \"}]\n",
        "})\n",
        "print(f\"Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\nâœ… Input validation protects against malicious inputs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Dynamic Context with pre_model_hook\n",
        "\n",
        "**Pattern:** Inject context dynamically before LLM processing\n",
        "\n",
        "While LangChain 1.0's `create_agent` doesn't have `modify_model_request`, you can achieve similar functionality by:\n",
        "1. Using `pre_model_hook` to add context to state\n",
        "2. Using function-based prompts that read from state\n",
        "3. Adding system messages dynamically\n",
        "\n",
        "**Use for:**\n",
        "- User-aware responses\n",
        "- Dynamic context injection\n",
        "- Personalization\n",
        "- Session-specific instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 3.1: Dynamic Context Injection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentMiddleware, ModelRequest\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "class ContextInjectionMiddleware(AgentMiddleware):\n",
        "    \"\"\"Inject user context into the system prompt dynamically.\"\"\"\n",
        "    \n",
        "    def modify_model_request(self, state: AgentState, request: ModelRequest) -> ModelRequest:\n",
        "        \"\"\"Add employee context to system prompt.\"\"\"\n",
        "        user_id = state.get(\"current_user_id\", \"unknown\")\n",
        "        user_role = state.get(\"current_user_role\", \"unknown\")\n",
        "        \n",
        "        # Get employee details\n",
        "        emp_info = \"\"\n",
        "        if user_id in EMPLOYEES:\n",
        "            emp = EMPLOYEES[user_id]\n",
        "            emp_info = f\"Current User: {emp['name']} (ID: {user_id})\\nRole: {emp['role']}\\nDepartment: {emp['department']}\"\n",
        "        \n",
        "        # Inject context into system prompt\n",
        "        original_prompt = request.system_prompt or \"\"\n",
        "        enhanced_prompt = f\"\"\"{original_prompt}\n",
        "\n",
        "CURRENT USER CONTEXT:\n",
        "{emp_info}\n",
        "\n",
        "Always be aware of who you're talking to and personalize responses accordingly.\n",
        "\"\"\"\n",
        "        \n",
        "        print(f\"\\nðŸ’‰ [CONTEXT INJECTION]\")\n",
        "        print(f\"   Injected context for: {user_id} ({user_role})\")\n",
        "        \n",
        "        request.system_prompt = enhanced_prompt\n",
        "        return request\n",
        "\n",
        "# Create agent with context injection\n",
        "context_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[check_leave_balance],\n",
        "    middleware=[ContextInjectionMiddleware()],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are a helpful HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Context Injection\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = context_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have?\"}],\n",
        "    \"current_user_id\": \"101\",\n",
        "    \"current_user_role\": \"Senior Developer\"\n",
        "})\n",
        "\n",
        "print(f\"\\nResponse: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ… Agent knows who it's talking to without explicit mention!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 3.2: Dynamic Model Switching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model switching based on query complexity\n",
        "# Note: In LangChain 1.0, model is set at agent creation\n",
        "# Dynamic model switching requires custom graph implementation\n",
        "\n",
        "def detect_query_complexity(content: str) -> str:\n",
        "    \"\"\"Detect if query is simple or complex.\"\"\"\n",
        "    complex_keywords = [\"analyze\", \"compare\", \"evaluate\", \"recommend\", \"strategy\", \"plan\"]\n",
        "    return \"complex\" if any(keyword in content.lower() for keyword in complex_keywords) else \"simple\"\n",
        "\n",
        "def model_selection_hook(state: AgentState) -> dict:\n",
        "    \"\"\"Log which model would be ideal for this query.\"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "    if not messages:\n",
        "        return {}\n",
        "    \n",
        "    content = messages[-1].content\n",
        "    complexity = detect_query_complexity(content)\n",
        "    \n",
        "    print(f\"\\nðŸ”„ [MODEL SELECTION ANALYSIS]\")\n",
        "    print(f\"   Query complexity: {complexity}\")\n",
        "    if complexity == \"complex\":\n",
        "        print(f\"   Recommended: GPT-4 for complex analysis\")\n",
        "    else:\n",
        "        print(f\"   Recommended: GPT-3.5 for simple queries (cost optimization)\")\n",
        "    \n",
        "    return {}\n",
        "\n",
        "# Note: This demonstrates the concept. In production, you would:\n",
        "# 1. Use LangGraph to create custom routing logic\n",
        "# 2. Create separate agents for different models\n",
        "# 3. Route based on complexity analysis\n",
        "\n",
        "print(\"âœ… Model selection logic defined!\")\n",
        "print(\"ðŸ’¡ In production, use LangGraph conditional edges for true model switching\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: post_model_hook - Post-processing\n",
        "\n",
        "**Use post_model_hook for:**\n",
        "- Response validation\n",
        "- Content filtering\n",
        "- Logging responses\n",
        "- Token usage tracking\n",
        "- Error recovery\n",
        "- Approval workflows\n",
        "\n",
        "**Key Pattern:**\n",
        "```python\n",
        "def my_post_hook(state: AgentState) -> dict:\n",
        "    # Process the response\n",
        "    messages = state.get(\"messages\", [])\n",
        "    \n",
        "    # Log, validate, or modify\n",
        "    # ...\n",
        "    \n",
        "    return {}  # Or state updates\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.1: Response Logging and Audit Trail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AuditTrailMiddleware(AgentMiddleware):\n",
        "    \"\"\"Log all interactions for compliance and auditing.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.audit_log = []\n",
        "    \n",
        "    def before_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log request.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if messages:\n",
        "            self.request_timestamp = datetime.now()\n",
        "            self.request_content = messages[-1].content\n",
        "        return {}\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Log response and save audit entry.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if len(messages) >= 2:\n",
        "            response_content = messages[-1].content\n",
        "            \n",
        "            audit_entry = {\n",
        "                \"timestamp\": self.request_timestamp.isoformat(),\n",
        "                \"user_id\": state.get(\"current_user_id\", \"unknown\"),\n",
        "                \"request\": self.request_content,\n",
        "                \"response\": response_content[:100],  # Truncate for readability\n",
        "                \"tools_used\": [msg.name for msg in messages if hasattr(msg, 'name')]\n",
        "            }\n",
        "            \n",
        "            self.audit_log.append(audit_entry)\n",
        "            \n",
        "            print(f\"\\nðŸ“‹ [AUDIT LOG ENTRY CREATED]\")\n",
        "            print(f\"   Timestamp: {audit_entry['timestamp']}\")\n",
        "            print(f\"   User: {audit_entry['user_id']}\")\n",
        "            print(f\"   Request: {audit_entry['request'][:50]}...\")\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def get_audit_log(self):\n",
        "        \"\"\"Retrieve audit log.\"\"\"\n",
        "        return self.audit_log\n",
        "\n",
        "# Create agent with audit trail\n",
        "audit_middleware = AuditTrailMiddleware()\n",
        "audit_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance],\n",
        "    middleware=[audit_middleware],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Audit Trail\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make several requests\n",
        "requests = [\n",
        "    (\"Who is employee 101?\", \"101\"),\n",
        "    (\"Check leave balance for employee 102\", \"102\"),\n",
        "    (\"Tell me about employee 103\", \"103\")\n",
        "]\n",
        "\n",
        "for query, user_id in requests:\n",
        "    result = audit_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": query}],\n",
        "        \"current_user_id\": user_id\n",
        "    })\n",
        "\n",
        "# Display audit log\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPLETE AUDIT LOG\")\n",
        "print(\"=\" * 70)\n",
        "for i, entry in enumerate(get_audit_log(), 1):\n",
        "    print(f\"\\nEntry {i}:\")\n",
        "    print(json.dumps(entry, indent=2))\n",
        "\n",
        "print(\"\\nâœ… All interactions logged for compliance!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.2: Token Usage Tracking and Cost Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenTrackingMiddleware(AgentMiddleware):\n",
        "    \"\"\"Track token usage and estimated costs.\"\"\"\n",
        "    \n",
        "    def __init__(self, cost_per_1k_tokens: float = 0.002):\n",
        "        self.total_tokens = 0\n",
        "        self.total_cost = 0.0\n",
        "        self.cost_per_1k = cost_per_1k_tokens\n",
        "        self.usage_history = []\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Estimate token usage after LLM call.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        \n",
        "        # Rough estimation (in production, use actual token counts from API)\n",
        "        estimated_tokens = sum(len(msg.content.split()) * 1.3 for msg in messages)\n",
        "        estimated_tokens = int(estimated_tokens)\n",
        "        \n",
        "        cost = (estimated_tokens / 1000) * self.cost_per_1k\n",
        "        \n",
        "        self.total_tokens += estimated_tokens\n",
        "        self.total_cost += cost\n",
        "        \n",
        "        usage_entry = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"user_id\": state.get(\"current_user_id\", \"unknown\"),\n",
        "            \"tokens\": estimated_tokens,\n",
        "            \"cost\": f\"${cost:.4f}\"\n",
        "        }\n",
        "        self.usage_history.append(usage_entry)\n",
        "        \n",
        "        print(f\"\\nðŸ’° [TOKEN USAGE]\")\n",
        "        print(f\"   This call: ~{estimated_tokens} tokens (${cost:.4f})\")\n",
        "        print(f\"   Total: ~{self.total_tokens} tokens (${self.total_cost:.4f})\")\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def get_usage_report(self):\n",
        "        \"\"\"Generate usage report.\"\"\"\n",
        "        return {\n",
        "            \"total_tokens\": self.total_tokens,\n",
        "            \"total_cost\": f\"${self.total_cost:.4f}\",\n",
        "            \"history\": self.usage_history\n",
        "        }\n",
        "\n",
        "# Create agent with token tracking\n",
        "token_middleware = TokenTrackingMiddleware()\n",
        "cost_tracking_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info],\n",
        "    middleware=[token_middleware],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Token Usage Tracking\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Make several requests\n",
        "for i in range(3):\n",
        "    result = cost_tracking_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Tell me about employee 10{i+1}\"}],\n",
        "        \"current_user_id\": f\"10{i+1}\"\n",
        "    })\n",
        "\n",
        "# Display usage report\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"USAGE REPORT\")\n",
        "print(\"=\" * 70)\n",
        "report = get_usage_report()\n",
        "print(json.dumps(report, indent=2))\n",
        "\n",
        "print(\"\\nâœ… Token usage and costs tracked!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 4.3: Content Filtering and Safety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ContentFilterMiddleware(AgentMiddleware):\n",
        "    \"\"\"Filter responses for sensitive information.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Patterns to redact (for demo purposes)\n",
        "        self.sensitive_patterns = {\n",
        "            r'\\b\\d{10}\\b': '[PHONE_REDACTED]',  # Phone numbers\n",
        "            r'\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b': '[EMAIL_REDACTED]',  # Emails\n",
        "            r'\\b\\d{3}-\\d{2}-\\d{4}\\b': '[SSN_REDACTED]',  # SSN format\n",
        "        }\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Filter response for sensitive data.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            return {}\n",
        "        \n",
        "        last_message = messages[-1]\n",
        "        original_content = last_message.content\n",
        "        filtered_content = original_content\n",
        "        \n",
        "        # Apply filters\n",
        "        redacted = False\n",
        "        for pattern, replacement in self.sensitive_patterns.items():\n",
        "            matches = re.findall(pattern, filtered_content, re.IGNORECASE)\n",
        "            if matches:\n",
        "                filtered_content = re.sub(pattern, replacement, filtered_content, flags=re.IGNORECASE)\n",
        "                redacted = True\n",
        "        \n",
        "        if redacted:\n",
        "            print(f\"\\nðŸ›¡ï¸  [CONTENT FILTER]\")\n",
        "            print(f\"   âš ï¸  Sensitive information detected and redacted\")\n",
        "            last_message.content = filtered_content\n",
        "            return {\"messages\": messages}\n",
        "        \n",
        "        return {}\n",
        "\n",
        "# Create agent with content filtering\n",
        "filtered_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    middleware=[ContentFilterMiddleware()],\n",
        "    prompt=\"You are an HR assistant. When providing examples, use realistic sample data.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Content Filtering\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = filtered_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Can you give me an example employee contact? Use format: Name, email, phone\"}]\n",
        "})\n",
        "\n",
        "print(f\"\\nResponse: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ… Sensitive information automatically redacted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Chaining Multiple Hooks\n",
        "\n",
        "**Production Pattern:** Combine multiple operations into single hook functions.\n",
        "\n",
        "Since `create_agent` accepts one `pre_model_hook` and one `post_model_hook`, you need to chain operations:\n",
        "\n",
        "```python\n",
        "def combined_pre_hook(state: AgentState) -> dict:\n",
        "    # Run multiple checks in sequence\n",
        "    result = logging_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    result = auth_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # ... more hooks\n",
        "    return {}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 5.1: Production HR Agent with All Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chaining multiple hooks - combine them into single functions\n",
        "def combined_pre_hook(state: AgentState) -> dict:\n",
        "    \"\"\"Chain multiple pre-model hooks.\"\"\"\n",
        "    # 1. Logging\n",
        "    result = logging_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # 2. Input Validation\n",
        "    result = input_validation_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # 3. Authorization\n",
        "    result = authorization_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # 4. Rate Limiting\n",
        "    result = rate_limit_hook(state, max_requests=10, window_seconds=60)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # 5. Context Injection\n",
        "    result = context_injection_hook(state)\n",
        "    if result.get(\"jump_to\"): return result\n",
        "    \n",
        "    # 6. Audit (pre)\n",
        "    result = audit_pre_hook(state)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def combined_post_hook(state: AgentState) -> dict:\n",
        "    \"\"\"Chain multiple post-model hooks.\"\"\"\n",
        "    # 1. Audit (post)\n",
        "    result = audit_post_hook(state)\n",
        "    \n",
        "    # 2. Token Tracking\n",
        "    result = token_tracking_hook(state)\n",
        "    \n",
        "    # 3. Content Filtering\n",
        "    result = content_filter_hook(state)\n",
        "    if result.get(\"messages\"):\n",
        "        return result\n",
        "    \n",
        "    return {}\n",
        "\n",
        "# Create production agent with all hooks\n",
        "production_hr_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, check_leave_balance, update_salary],\n",
        "    pre_model_hook=combined_pre_hook,\n",
        "    post_model_hook=combined_post_hook,\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    checkpointer=InMemorySaver(),\n",
        "    prompt=\"\"\"You are a professional HR assistant for a large organization.\n",
        "    \n",
        "    Your responsibilities:\n",
        "    - Help employees with HR queries\n",
        "    - Check leave balances\n",
        "    - Provide employee information\n",
        "    - Handle sensitive operations with care\n",
        "    \n",
        "    Always be professional, helpful, and security-conscious.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Production HR agent created with multi-layered hook chain!\")\n",
        "print(\"\\nHook layers:\")\n",
        "print(\"  Pre-model: ðŸ“ Logging â†’ ðŸ›¡ï¸ Validation â†’ ðŸ” Auth â†’ â±ï¸ Rate Limit â†’ ðŸ’‰ Context â†’ ðŸ“‹ Audit\")\n",
        "print(\"  Post-model: ðŸ“‹ Audit â†’ ðŸ’° Token Tracking â†’ ðŸ›¡ï¸ Content Filter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 5.2: Test Production Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"production_test_1\"}}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PRODUCTION HR AGENT TEST\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test 1: Normal query (authorized user)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 1: Employee checking own leave balance\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"How many leave days do I have remaining?\"}],\n",
        "    \"current_user_id\": \"101\",\n",
        "    \"current_user_role\": \"Senior Developer\"\n",
        "}, config)\n",
        "print(f\"\\nðŸ‘¤ User: Priya Sharma (101)\")\n",
        "print(f\"ðŸ¤– Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 2: Unauthorized operation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 2: Unauthorized salary update attempt\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update my salary to 200000\"}],\n",
        "    \"current_user_id\": \"104\",\n",
        "    \"current_user_role\": \"Team Lead\"\n",
        "}, config)\n",
        "print(f\"\\nðŸ‘¤ User: Arjun Reddy (104)\")\n",
        "print(f\"ðŸ¤– Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test 3: Authorized operation\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Test 3: Authorized salary update (HR Director)\")\n",
        "print(\"=\" * 70)\n",
        "result = production_hr_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 180000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "}, config)\n",
        "print(f\"\\nðŸ‘¤ User: Anjali Patel (103)\")\n",
        "print(f\"ðŸ¤– Response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Display final reports\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"AUDIT & USAGE REPORTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nðŸ“‹ Audit Log:\")\n",
        "for i, entry in enumerate(get_audit_log()[-3:], 1):  # Show last 3 entries\n",
        "    print(f\"\\n  Entry {i}:\")\n",
        "    print(f\"    User: {entry['user_id']}\")\n",
        "    print(f\"    Request: {entry['request'][:60]}...\")\n",
        "    print(f\"    Time: {entry['timestamp']}\")\n",
        "\n",
        "print(\"\\nðŸ’° Token Usage:\")\n",
        "usage = get_usage_report()\n",
        "print(f\"  Total Tokens: {usage['total_tokens']}\")\n",
        "print(f\"  Total Cost: {usage['total_cost']}\")\n",
        "\n",
        "print(\"\\nâœ… Production agent with complete hook protection!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 6: Human-in-the-Loop with post_model_hook\n",
        "\n",
        "**Use Case:** Require human approval for critical operations.\n",
        "\n",
        "**Pattern:** Intercept tool calls in `post_model_hook` before they execute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 6.1: Approval Workflow Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ApprovalWorkflowMiddleware(AgentMiddleware):\n",
        "    \"\"\"Require approval for sensitive operations.\"\"\"\n",
        "    \n",
        "    def __init__(self, approval_required_tools: list[str]):\n",
        "        self.approval_required = approval_required_tools\n",
        "        self.pending_approvals = {}\n",
        "    \n",
        "    def after_model(self, state: AgentState) -> dict:\n",
        "        \"\"\"Check if tools require approval.\"\"\"\n",
        "        messages = state.get(\"messages\", [])\n",
        "        \n",
        "        # Check if any tool calls are pending\n",
        "        for msg in messages:\n",
        "            if hasattr(msg, 'tool_calls'):\n",
        "                for tool_call in msg.tool_calls:\n",
        "                    tool_name = tool_call.get('name', '')\n",
        "                    \n",
        "                    if tool_name in self.approval_required:\n",
        "                        approval_id = f\"approval_{len(self.pending_approvals)}\"\n",
        "                        \n",
        "                        self.pending_approvals[approval_id] = {\n",
        "                            \"tool\": tool_name,\n",
        "                            \"args\": tool_call.get('args', {}),\n",
        "                            \"status\": \"pending\",\n",
        "                            \"timestamp\": datetime.now().isoformat()\n",
        "                        }\n",
        "                        \n",
        "                        print(f\"\\nâœ‹ [APPROVAL REQUIRED]\")\n",
        "                        print(f\"   Tool: {tool_name}\")\n",
        "                        print(f\"   Args: {tool_call.get('args', {})}\")\n",
        "                        print(f\"   Approval ID: {approval_id}\")\n",
        "                        \n",
        "                        # In production, this would pause execution\n",
        "                        # and wait for human approval\n",
        "                        return {\n",
        "                            \"messages\": [(\"assistant\", f\"â¸ï¸  Operation requires approval. Approval ID: {approval_id}. Please have a manager review and approve this action.\")],\n",
        "                            \"jump_to\": \"__end__\"\n",
        "                        }\n",
        "        \n",
        "        return {}\n",
        "    \n",
        "    def approve(self, approval_id: str, approved: bool):\n",
        "        \"\"\"Approve or reject a pending operation.\"\"\"\n",
        "        if approval_id in self.pending_approvals:\n",
        "            self.pending_approvals[approval_id][\"status\"] = \"approved\" if approved else \"rejected\"\n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def get_pending_approvals(self):\n",
        "        return {k: v for k, v in self.pending_approvals.items() if v[\"status\"] == \"pending\"}\n",
        "\n",
        "# Create agent with approval workflow\n",
        "approval_mw = ApprovalWorkflowMiddleware(approval_required_tools=[\"update_salary\"])\n",
        "approval_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_employee_info, update_salary],\n",
        "    middleware=[approval_mw],\n",
        "    state_schema=AuthorizedAgentState,\n",
        "    prompt=\"You are an HR assistant.\"\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Testing Approval Workflow\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "result = approval_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Update salary for employee 101 to 200000\"}],\n",
        "    \"current_user_id\": \"103\",\n",
        "    \"current_user_role\": \"HR Director\"\n",
        "})\n",
        "\n",
        "print(f\"\\nAgent Response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\nðŸ“‹ Pending Approvals:\")\n",
        "for approval_id, details in get_pending_approvals().items():\n",
        "    print(f\"\\n  {approval_id}:\")\n",
        "    print(f\"    Tool: {details['tool']}\")\n",
        "    print(f\"    Args: {details['args']}\")\n",
        "    print(f\"    Status: {details['status']}\")\n",
        "\n",
        "print(\"\\nâœ… Sensitive operations require human approval!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary & Best Practices\n",
        "\n",
        "## Hook Execution in LangChain 1.0\n",
        "\n",
        "```\n",
        "User Input â†’ pre_model_hook â†’ LLM â†’ post_model_hook â†’ Tools â†’ Response\n",
        "             â†‘                        â†‘\n",
        "             Pre-processing           Post-processing\n",
        "```\n",
        "\n",
        "## When to Use Each Hook\n",
        "\n",
        "| Hook | Use For | Can Modify State | Can Jump |\n",
        "|------|---------|-----------------|----------|\n",
        "| **pre_model_hook** | Authorization, validation, logging, rate limiting | âœ… Yes | âœ… Yes |\n",
        "| **post_model_hook** | Response filtering, audit, metrics, content safety | âœ… Yes | âœ… Yes |\n",
        "\n",
        "## Production Hook Chain (Recommended Order)\n",
        "\n",
        "### Pre-Model Hooks:\n",
        "1. **Logging** - Log all incoming requests\n",
        "2. **Input Validation** - Sanitize and validate inputs\n",
        "3. **Rate Limiting** - Prevent abuse\n",
        "4. **Authorization** - Check permissions\n",
        "5. **Context Injection** - Add user context\n",
        "6. **Audit (Pre)** - Record request\n",
        "\n",
        "### Post-Model Hooks:\n",
        "1. **Audit (Post)** - Record response\n",
        "2. **Token Tracking** - Monitor usage and costs\n",
        "3. **Content Filtering** - Redact sensitive data\n",
        "4. **Approval Workflow** - Human-in-the-loop for critical ops\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "âœ… **Hooks provide powerful execution control**  \n",
        "âœ… **Chain multiple operations in single hook functions**  \n",
        "âœ… **Use pre_model_hook for pre-processing and authorization**  \n",
        "âœ… **Use post_model_hook for post-processing and auditing**  \n",
        "âœ… **Always log and audit in production**  \n",
        "âœ… **Implement rate limiting to prevent abuse**  \n",
        "âœ… **Track token usage for cost management**  \n",
        "âœ… **Handle `jump_to` for early exits**  \n",
        "\n",
        "## Important Notes for LangChain 1.0\n",
        "\n",
        "- `create_agent` accepts **one** `pre_model_hook` and **one** `post_model_hook`\n",
        "- To chain multiple operations, combine them into single hook functions\n",
        "- Check for `jump_to` in results to enable early exits\n",
        "- Hooks receive `AgentState` and return `dict` with state updates\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Implement custom hooks for your use case\n",
        "- Add persistent storage for audit logs\n",
        "- Integrate with external authentication systems\n",
        "- Build approval workflows with notification systems\n",
        "- Deploy with production monitoring and alerting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Exercises\n",
        "\n",
        "## Exercise 1: Department-Based Authorization\n",
        "\n",
        "Create middleware that:\n",
        "- Only allows HR department to view salary information\n",
        "- Only allows managers to approve leave requests\n",
        "- Logs unauthorized access attempts\n",
        "\n",
        "**Hint:** Use `before_model` hook with user role checking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "def department_auth_hook(state: AgentState) -> dict:\n",
        "    \"\"\"TODO: Implement department-based authorization.\"\"\"\n",
        "    # TODO: Check user department and role\n",
        "    # TODO: Verify permissions for specific operations\n",
        "    # TODO: Log unauthorized attempts\n",
        "    pass\n",
        "\n",
        "# TODO: Create tools for salary info and leave approval\n",
        "# TODO: Test with different user roles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Smart Caching Middleware\n",
        "\n",
        "Create middleware that:\n",
        "- Caches responses for identical queries\n",
        "- Invalidates cache after 5 minutes\n",
        "- Logs cache hits/misses\n",
        "- Calculates cache hit rate\n",
        "\n",
        "**Hint:** Use `before_model` to check cache, `after_model` to store responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "cache_data = {\n",
        "    'cache': {},  # query -> (response, timestamp)\n",
        "    'hits': 0,\n",
        "    'misses': 0\n",
        "}\n",
        "\n",
        "def caching_pre_hook(state: AgentState, ttl_seconds: int = 300) -> dict:\n",
        "    \"\"\"TODO: Check cache before LLM call.\"\"\"\n",
        "    # TODO: Hash the query\n",
        "    # TODO: Check if cached and not expired\n",
        "    # TODO: If cache hit, return cached response and jump to end\n",
        "    # TODO: Track cache hits\n",
        "    pass\n",
        "\n",
        "def caching_post_hook(state: AgentState, ttl_seconds: int = 300) -> dict:\n",
        "    \"\"\"TODO: Store response in cache.\"\"\"\n",
        "    # TODO: Store response with timestamp\n",
        "    # TODO: Track cache misses\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Multi-Language Support\n",
        "\n",
        "Create middleware that:\n",
        "- Detects user's preferred language from state\n",
        "- Modifies system prompt to include language instruction\n",
        "- Translates common HR terms\n",
        "\n",
        "**Hint:** Use `modify_model_request` hook.\n",
        "\n",
        "**Languages to support:** English, Hindi, Tamil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "def multi_language_hook(state: AgentState) -> dict:\n",
        "    \"\"\"TODO: Add multi-language support.\"\"\"\n",
        "    # TODO: Get user's preferred language from state\n",
        "    # TODO: Add language-specific instructions to messages\n",
        "    # TODO: Include translations for common HR terms\n",
        "    pass\n",
        "\n",
        "# Note: In LangChain 1.0, modify the messages in state\n",
        "# or add a system message with language instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Compliance Reporting\n",
        "\n",
        "Create middleware that generates compliance reports:\n",
        "- Track all data access by employee\n",
        "- Log sensitive operations (salary updates, leave approvals)\n",
        "- Generate daily summary reports\n",
        "- Alert on suspicious patterns (e.g., excessive queries)\n",
        "\n",
        "**Hint:** Combine `before_model` and `after_model` hooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n",
        "compliance_data = {\n",
        "    'access_log': [],\n",
        "    'sensitive_ops': []\n",
        "}\n",
        "\n",
        "def compliance_pre_hook(state: AgentState) -> dict:\n",
        "    \"\"\"TODO: Track data access attempts.\"\"\"\n",
        "    # TODO: Log who accessed what data\n",
        "    # TODO: Record timestamp and user info\n",
        "    # TODO: Detect suspicious patterns (e.g., excessive queries)\n",
        "    pass\n",
        "\n",
        "def compliance_post_hook(state: AgentState) -> dict:\n",
        "    \"\"\"TODO: Log sensitive operations.\"\"\"\n",
        "    # TODO: Identify sensitive operations (salary, personal data)\n",
        "    # TODO: Record operation details\n",
        "    # TODO: Generate alerts for suspicious activity\n",
        "    pass\n",
        "\n",
        "def generate_daily_report():\n",
        "    \"\"\"TODO: Generate compliance report.\"\"\"\n",
        "    # TODO: Summarize access patterns\n",
        "    # TODO: List sensitive operations\n",
        "    # TODO: Highlight any anomalies\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒŸ Bonus Challenge: Advanced Approval System\n",
        "\n",
        "Create a complete approval workflow:\n",
        "- Different approval levels (Manager â†’ Director â†’ C-Level)\n",
        "- Email notifications for pending approvals\n",
        "- Time-based auto-rejection (if not approved in 24hrs)\n",
        "- Approval history and audit trail\n",
        "- Web dashboard to view and approve requests\n",
        "\n",
        "**This is open-ended - be creative!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here - this is a complex, production-ready system!\n",
        "# Consider using:\n",
        "# - Database for persistent storage\n",
        "# - Message queue for notifications\n",
        "# - Scheduled jobs for auto-rejection\n",
        "# - REST API for approval interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Conclusion\n",
        "\n",
        "**Congratulations! You've mastered Agent Hooks in LangChain 1.0!**\n",
        "\n",
        "You now know how to:\n",
        "- âœ… Control agent execution with pre_model_hook and post_model_hook\n",
        "- âœ… Implement authorization and access control\n",
        "- âœ… Add rate limiting and abuse prevention\n",
        "- âœ… Track usage and manage costs\n",
        "- âœ… Create audit trails for compliance\n",
        "- âœ… Build human-in-the-loop workflows\n",
        "- âœ… Chain multiple operations for production systems\n",
        "\n",
        "**Remember:** Hooks are essential for production agents. Always implement proper:\n",
        "- ðŸ” Authorization\n",
        "- ðŸ“‹ Audit logging\n",
        "- â±ï¸  Rate limiting\n",
        "- ðŸ’° Cost tracking\n",
        "- ðŸ›¡ï¸  Security controls\n",
        "\n",
        "---\n",
        "**Next Module:** Advanced Agent Patterns and Multi-Agent Systems\n",
        "\n",
        "**References:**\n",
        "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
        "- [LangChain Agents Guide](https://python.langchain.com/docs/concepts/agents/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
