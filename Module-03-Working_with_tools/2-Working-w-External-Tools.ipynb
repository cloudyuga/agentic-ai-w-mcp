{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 4: External Tools & Integrations with LangChain 1.0\n",
        "\n",
        "**Building on Previous Modules:**\n",
        "- Module 1: Built basic agents\n",
        "- Module 2: Learned LangGraph workflows\n",
        "- Module 3: Mastered @tool decorator\n",
        "- Module 4: **Connect to the real world with external integrations!**\n",
        "\n",
        "**What you'll learn:**\n",
        "- üìä Load data from CSV files (employee records)\n",
        "- üìÑ Process PDF documents (HR policies, handbooks)\n",
        "- üîç Perform web searches (external information)\n",
        "- ü§ñ Build intelligent document Q&A systems\n",
        "- üîß Combine multiple data sources in one agent\n",
        "\n",
        "**Real HR Use Case:**\n",
        "Build an intelligent HR assistant that can:\n",
        "- Query employee database (CSV)\n",
        "- Answer policy questions (PDF)\n",
        "- Find external HR best practices (Web Search)\n",
        "- Provide comprehensive, multi-source answers\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install LangChain 1.0 and integration packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph langchain-community\n",
        "!pip install pypdf  # For PDF processing\n",
        "!pip install faiss-cpu  # For vector storage\n",
        "!pip install duckduckgo-search  # For web search (free, no API key needed!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Configure API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "print(\"‚úÖ API Keys configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 1: CSV Loader - Employee Database üìä\n",
        "\n",
        "**Objective:** Load and query employee data from CSV files.\n",
        "\n",
        "**Why CSV Loaders?**\n",
        "- Most HR systems export to CSV\n",
        "- Easy to update and maintain\n",
        "- Perfect for structured employee data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Create Sample Employee CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Create sample employee data matching our HR use case\n",
        "employee_data = [\n",
        "    [\"employee_id\", \"name\", \"department\", \"position\", \"email\", \"phone\", \"hire_date\", \"salary\", \"leave_balance\"],\n",
        "    [\"101\", \"Priya Sharma\", \"Engineering\", \"Senior Developer\", \"priya.sharma@company.com\", \"+91-9876543210\", \"2020-03-15\", \"‚Çπ12,00,000\", \"12\"],\n",
        "    [\"102\", \"Rahul Verma\", \"Engineering\", \"Manager\", \"rahul.verma@company.com\", \"+91-9876543211\", \"2018-06-20\", \"‚Çπ18,00,000\", \"8\"],\n",
        "    [\"103\", \"Anjali Patel\", \"HR\", \"Director\", \"anjali.patel@company.com\", \"+91-9876543212\", \"2015-01-10\", \"‚Çπ25,00,000\", \"15\"],\n",
        "    [\"104\", \"Arjun Reddy\", \"Sales\", \"Team Lead\", \"arjun.reddy@company.com\", \"+91-9876543213\", \"2019-09-05\", \"‚Çπ15,00,000\", \"10\"],\n",
        "    [\"105\", \"Sneha Gupta\", \"Marketing\", \"Specialist\", \"sneha.gupta@company.com\", \"+91-9876543214\", \"2021-11-22\", \"‚Çπ10,00,000\", \"5\"],\n",
        "    [\"106\", \"Karan Singh\", \"Engineering\", \"Junior Developer\", \"karan.singh@company.com\", \"+91-9876543215\", \"2023-02-14\", \"‚Çπ8,00,000\", \"20\"],\n",
        "    [\"107\", \"Pooja Reddy\", \"HR\", \"Recruiter\", \"pooja.reddy@company.com\", \"+91-9876543216\", \"2022-07-01\", \"‚Çπ9,00,000\", \"18\"],\n",
        "    [\"108\", \"Vikram Patel\", \"Sales\", \"Executive\", \"vikram.patel@company.com\", \"+91-9876543217\", \"2020-12-10\", \"‚Çπ11,00,000\", \"14\"],\n",
        "]\n",
        "\n",
        "# Write to CSV file\n",
        "with open('employees.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(employee_data)\n",
        "\n",
        "print(\"‚úÖ Employee CSV created!\")\n",
        "print(f\"Total employees: {len(employee_data) - 1}\")\n",
        "print(\"\\nFile: employees.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Load CSV with LangChain CSVLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "# Load the CSV file\n",
        "loader = CSVLoader(\n",
        "    file_path='employees.csv',\n",
        "    source_column='employee_id',  # Use employee_id as the source\n",
        "    encoding='utf-8'\n",
        ")\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(documents)} employee records\\n\")\n",
        "print(\"Sample Document:\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Content:\\n{documents[0].page_content}\")\n",
        "print(f\"\\nMetadata: {documents[0].metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Create a @tool for CSV Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "import csv\n",
        "\n",
        "@tool\n",
        "def search_employee_database(query: Annotated[str, \"Search query for employee information (name, ID, department, etc.)\"]) -> str:\n",
        "    \"\"\"Search the employee database by name, ID, department, or position.\n",
        "    Returns matching employee information.\"\"\"\n",
        "    \n",
        "    query_lower = query.lower()\n",
        "    results = []\n",
        "    \n",
        "    with open('employees.csv', 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            # Search across multiple fields\n",
        "            searchable_text = ' '.join([\n",
        "                row.get('employee_id', ''),\n",
        "                row.get('name', ''),\n",
        "                row.get('department', ''),\n",
        "                row.get('position', '')\n",
        "            ]).lower()\n",
        "            \n",
        "            if query_lower in searchable_text:\n",
        "                results.append(\n",
        "                    f\"ID: {row['employee_id']} | {row['name']} | \"\n",
        "                    f\"{row['department']} - {row['position']} | \"\n",
        "                    f\"Leave: {row['leave_balance']} days | \"\n",
        "                    f\"Email: {row['email']}\"\n",
        "                )\n",
        "    \n",
        "    if results:\n",
        "        return \"\\n\".join(results)\n",
        "    return f\"No employees found matching '{query}'\"\n",
        "\n",
        "# Test the tool\n",
        "print(\"Testing Employee Search Tool:\")\n",
        "print(\"=\" * 70)\n",
        "result = search_employee_database.invoke({\"query\": \"Engineering\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 2: PDF Loader - HR Policy Documents üìÑ\n",
        "\n",
        "**Objective:** Process PDF documents and make them queryable.\n",
        "\n",
        "**Why PDF Loaders?**\n",
        "- Company policies are usually in PDF\n",
        "- Employee handbooks, contracts\n",
        "- Need to answer questions from these documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Create Sample HR Policy PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# Install reportlab if needed\n",
        "!pip install -q reportlab\n",
        "\n",
        "# Create HR Policy PDF\n",
        "doc = SimpleDocTemplate(\"hr_policy.pdf\", pagesize=letter)\n",
        "styles = getSampleStyleSheet()\n",
        "story = []\n",
        "\n",
        "# Title\n",
        "story.append(Paragraph(\"COMPANY HR POLICIES\", styles['Title']))\n",
        "story.append(Spacer(1, 12))\n",
        "\n",
        "# Policy content\n",
        "policies = [\n",
        "    (\"Leave Policy\", \"Employees are entitled to 20 days of paid leave per year. Leave must be approved by the immediate supervisor at least 2 weeks in advance for planned absences. Sick leave requires medical documentation for absences exceeding 3 consecutive days. Unused leave can be carried forward up to 5 days to the next year.\"),\n",
        "    (\"Work From Home Policy\", \"Employees can work from home up to 2 days per week with manager approval. Remote work requires stable internet connection and dedicated workspace. Core working hours (10 AM - 4 PM) must be maintained. All communication tools must be active during working hours.\"),\n",
        "    (\"Performance Review\", \"Performance reviews are conducted bi-annually in June and December. Reviews assess goal achievement, skill development, and team contribution. Salary increments are based on performance ratings. Employees can request additional feedback sessions with managers at any time.\"),\n",
        "    (\"Benefits\", \"All full-time employees receive health insurance, life insurance, and provident fund benefits. Health insurance covers employee and immediate family. Annual health check-ups are provided. Education reimbursement up to ‚Çπ50,000 per year for job-related courses.\"),\n",
        "    (\"Code of Conduct\", \"Employees must maintain professional behavior and respect colleagues. Discrimination or harassment of any kind is strictly prohibited. Company resources should be used responsibly. Confidential information must not be shared externally.\"),\n",
        "]\n",
        "\n",
        "for title, content in policies:\n",
        "    story.append(Paragraph(f\"<b>{title}</b>\", styles['Heading2']))\n",
        "    story.append(Spacer(1, 6))\n",
        "    story.append(Paragraph(content, styles['BodyText']))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "doc.build(story)\n",
        "print(\"‚úÖ HR Policy PDF created: hr_policy.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Load and Process PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load PDF\n",
        "pdf_loader = PyPDFLoader(\"hr_policy.pdf\")\n",
        "pdf_documents = pdf_loader.load()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(pdf_documents)} pages from PDF\\n\")\n",
        "print(\"First page content:\")\n",
        "print(\"=\" * 70)\n",
        "print(pdf_documents[0].page_content[:500])\n",
        "\n",
        "# Split into chunks for better retrieval\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "pdf_chunks = text_splitter.split_documents(pdf_documents)\n",
        "print(f\"\\n‚úÖ Split into {len(pdf_chunks)} chunks for processing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Create Vector Store for PDF Q&A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Create embeddings and vector store\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(pdf_chunks, embeddings)\n",
        "\n",
        "print(\"‚úÖ Vector store created from HR policy PDF\")\n",
        "print(f\"Indexed {len(pdf_chunks)} text chunks\")\n",
        "\n",
        "# Test retrieval\n",
        "query = \"What is the leave policy?\"\n",
        "results = vectorstore.similarity_search(query, k=2)\n",
        "\n",
        "print(f\"\\nTest Query: '{query}'\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Top Result:\")\n",
        "print(results[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Create @tool for Policy Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def query_hr_policies(question: Annotated[str, \"Question about company HR policies\"]) -> str:\n",
        "    \"\"\"Answer questions about company HR policies including leave, work from home, \n",
        "    performance reviews, benefits, and code of conduct.\"\"\"\n",
        "    \n",
        "    # Retrieve relevant policy sections\n",
        "    relevant_docs = vectorstore.similarity_search(question, k=3)\n",
        "    \n",
        "    # Combine context\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "    \n",
        "    # Use LLM to answer based on context\n",
        "    from langchain_openai import ChatOpenAI\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "    \n",
        "    prompt = f\"\"\"Based on the following HR policy information, answer the question.\n",
        "\n",
        "Policy Information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer concisely based only on the policy information provided:\"\"\"\n",
        "    \n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "# Test the tool\n",
        "print(\"Testing HR Policy Query Tool:\")\n",
        "print(\"=\" * 70)\n",
        "result = query_hr_policies.invoke({\"question\": \"How many work from home days are allowed?\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 3: Web Search Integration üîç\n",
        "\n",
        "**Objective:** Add web search capability for external information.\n",
        "\n",
        "**Why Web Search?**\n",
        "- Find latest HR best practices\n",
        "- Research industry standards\n",
        "- Get current information not in company docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Set up DuckDuckGo Search (Free!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Create search tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Test it\n",
        "print(\"Testing Web Search:\")\n",
        "print(\"=\" * 70)\n",
        "result = search.run(\"best HR practices for remote work 2025\")\n",
        "print(result[:500])  # First 500 chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Create Custom Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_hr_best_practices(topic: Annotated[str, \"HR topic to search for (e.g., 'remote work policies', 'employee benefits')\"]) -> str:\n",
        "    \"\"\"Search the web for HR best practices and industry standards on a specific topic.\n",
        "    Useful when company policies don't have information or when you need external references.\"\"\"\n",
        "    \n",
        "    search_tool = DuckDuckGoSearchRun()\n",
        "    query = f\"HR best practices {topic} 2025\"\n",
        "    \n",
        "    try:\n",
        "        results = search_tool.run(query)\n",
        "        return f\"Web search results for '{topic}':\\n\\n{results[:1000]}\"  # Limit to 1000 chars\n",
        "    except Exception as e:\n",
        "        return f\"Search unavailable: {str(e)}\"\n",
        "\n",
        "# Test\n",
        "print(\"Testing HR Best Practices Search:\")\n",
        "print(\"=\" * 70)\n",
        "result = search_hr_best_practices.invoke({\"topic\": \"employee wellness programs\"})\n",
        "print(result[:600])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 4: Building the Complete HR Assistant ü§ñ\n",
        "\n",
        "**Objective:** Combine all tools into one intelligent HR agent.\n",
        "\n",
        "**The agent can:**\n",
        "- ‚úÖ Search employee database (CSV)\n",
        "- ‚úÖ Answer policy questions (PDF)\n",
        "- ‚úÖ Find external best practices (Web)\n",
        "- ‚úÖ Provide comprehensive, multi-source answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Multi-Source HR Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Collect all our tools\n",
        "hr_tools = [\n",
        "    search_employee_database,\n",
        "    query_hr_policies,\n",
        "    search_hr_best_practices\n",
        "]\n",
        "\n",
        "# Create the agent\n",
        "hr_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=hr_tools,\n",
        "    prompt=\"\"\"You are an intelligent HR assistant with access to:\n",
        "    1. Employee database (search_employee_database)\n",
        "    2. Company HR policies (query_hr_policies)\n",
        "    3. External HR best practices (search_hr_best_practices)\n",
        "    \n",
        "    When answering questions:\n",
        "    - First check if you need employee-specific information\n",
        "    - Then consult company policies for internal guidelines\n",
        "    - Use web search only for external best practices or topics not covered internally\n",
        "    - Provide comprehensive answers citing your sources\n",
        "    \n",
        "    Be helpful, professional, and cite which source you're using.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Comprehensive HR Agent created!\")\n",
        "print(f\"\\nAvailable tools: {len(hr_tools)}\")\n",
        "for tool in hr_tools:\n",
        "    print(f\"  - {tool.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Complete System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_hr_agent(question: str):\n",
        "    \"\"\"Helper function to ask the HR agent a question.\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    result = hr_agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n{result['messages'][-1].content}\")\n",
        "    print(f\"\\n{'='*70}\")\n",
        "\n",
        "# Test 1: Employee lookup\n",
        "ask_hr_agent(\"Who are the employees in the Engineering department and how much leave do they have?\")\n",
        "\n",
        "# Test 2: Policy question\n",
        "ask_hr_agent(\"What is our company's work from home policy?\")\n",
        "\n",
        "# Test 3: Combined query\n",
        "ask_hr_agent(\"How many leave days does Priya Sharma have? Is this in line with our company policy?\")\n",
        "\n",
        "# Test 4: External best practices\n",
        "ask_hr_agent(\"What are the current best practices for hybrid work policies in 2025?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Lab 5: Advanced Integration - Combining with LangGraph üîß\n",
        "\n",
        "**Objective:** Build a workflow that uses multiple document sources strategically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class HRQueryState(TypedDict):\n",
        "    \"\"\"State for HR query workflow.\"\"\"\n",
        "    query: str\n",
        "    employee_info: str\n",
        "    policy_info: str\n",
        "    external_info: str\n",
        "    final_answer: str\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Define workflow nodes\n",
        "def check_employee_data(state: HRQueryState):\n",
        "    \"\"\"Check if query needs employee data.\"\"\"\n",
        "    query = state['query'].lower()\n",
        "    needs_employee_data = any(keyword in query for keyword in \n",
        "                             ['employee', 'priya', 'rahul', 'anjali', 'who', 'staff'])\n",
        "    \n",
        "    if needs_employee_data:\n",
        "        result = search_employee_database.invoke({\"query\": state['query']})\n",
        "        return {\"employee_info\": result}\n",
        "    return {\"employee_info\": \"Not needed\"}\n",
        "\n",
        "def check_policies(state: HRQueryState):\n",
        "    \"\"\"Check company policies.\"\"\"\n",
        "    query = state['query'].lower()\n",
        "    needs_policy = any(keyword in query for keyword in \n",
        "                      ['policy', 'leave', 'work from home', 'benefits', 'review'])\n",
        "    \n",
        "    if needs_policy:\n",
        "        result = query_hr_policies.invoke({\"question\": state['query']})\n",
        "        return {\"policy_info\": result}\n",
        "    return {\"policy_info\": \"Not needed\"}\n",
        "\n",
        "def check_external(state: HRQueryState):\n",
        "    \"\"\"Check external best practices if needed.\"\"\"\n",
        "    query = state['query'].lower()\n",
        "    needs_external = any(keyword in query for keyword in \n",
        "                        ['best practice', 'industry', 'standard', 'current', '2025'])\n",
        "    \n",
        "    if needs_external:\n",
        "        result = search_hr_best_practices.invoke({\"topic\": state['query']})\n",
        "        return {\"external_info\": result[:500]}  # Limit length\n",
        "    return {\"external_info\": \"Not needed\"}\n",
        "\n",
        "def synthesize_answer(state: HRQueryState):\n",
        "    \"\"\"Combine all information into final answer.\"\"\"\n",
        "    from langchain_openai import ChatOpenAI\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "    \n",
        "    prompt = f\"\"\"Based on the following information, answer the user's question comprehensively.\n",
        "\n",
        "User Question: {state['query']}\n",
        "\n",
        "Employee Information: {state.get('employee_info', 'None')}\n",
        "\n",
        "Company Policy: {state.get('policy_info', 'None')}\n",
        "\n",
        "External Best Practices: {state.get('external_info', 'None')}\n",
        "\n",
        "Provide a clear, comprehensive answer citing relevant sources:\"\"\"\n",
        "    \n",
        "    response = llm.invoke(prompt)\n",
        "    return {\n",
        "        \"final_answer\": response.content,\n",
        "        \"messages\": [(\"assistant\", response.content)]\n",
        "    }\n",
        "\n",
        "# Build workflow\n",
        "workflow = StateGraph(HRQueryState)\n",
        "workflow.add_node(\"check_employee\", check_employee_data)\n",
        "workflow.add_node(\"check_policy\", check_policies)\n",
        "workflow.add_node(\"check_external\", check_external)\n",
        "workflow.add_node(\"synthesize\", synthesize_answer)\n",
        "\n",
        "workflow.add_edge(START, \"check_employee\")\n",
        "workflow.add_edge(\"check_employee\", \"check_policy\")\n",
        "workflow.add_edge(\"check_policy\", \"check_external\")\n",
        "workflow.add_edge(\"check_external\", \"synthesize\")\n",
        "workflow.add_edge(\"synthesize\", END)\n",
        "\n",
        "hr_workflow = workflow.compile()\n",
        "print(\"‚úÖ HR Workflow created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the workflow\n",
        "test_query = \"How many leave days does Rahul Verma have? Is this aligned with company policy and industry standards?\"\n",
        "\n",
        "result = hr_workflow.invoke({\n",
        "    \"query\": test_query,\n",
        "    \"employee_info\": \"\",\n",
        "    \"policy_info\": \"\",\n",
        "    \"external_info\": \"\",\n",
        "    \"final_answer\": \"\",\n",
        "    \"messages\": []\n",
        "})\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nFinal Answer:\\n{result['final_answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Summary & Key Learnings\n",
        "\n",
        "## What You Built:\n",
        "\n",
        "1. **CSV Loader** üìä\n",
        "   - Loaded employee database\n",
        "   - Created searchable employee records\n",
        "   - Built @tool for employee queries\n",
        "\n",
        "2. **PDF Loader** üìÑ\n",
        "   - Processed HR policy documents\n",
        "   - Created vector store for Q&A\n",
        "   - Built @tool for policy questions\n",
        "\n",
        "3. **Web Search** üîç\n",
        "   - Integrated DuckDuckGo search\n",
        "   - Created tool for external best practices\n",
        "   - No API key needed!\n",
        "\n",
        "4. **Complete HR Agent** ü§ñ\n",
        "   - Combined all data sources\n",
        "   - Intelligent tool selection\n",
        "   - Multi-source answers\n",
        "\n",
        "5. **LangGraph Workflow** üîß\n",
        "   - Strategic data retrieval\n",
        "   - Parallel processing\n",
        "   - Comprehensive synthesis\n",
        "\n",
        "## Integration Patterns:\n",
        "\n",
        "| Data Source | Loader | Use Case | Best For |\n",
        "|-------------|--------|----------|----------|\n",
        "| CSV | CSVLoader | Structured data | Employee records, sales data |\n",
        "| PDF | PyPDFLoader | Documents | Policies, contracts, reports |\n",
        "| Web | DuckDuckGoSearch | External info | Best practices, news |\n",
        "| Google Drive | GoogleDriveLoader | Cloud docs | Shared documents |\n",
        "\n",
        "## Best Practices:\n",
        "\n",
        "1. **Choose the Right Loader**\n",
        "   - CSV for structured tabular data\n",
        "   - PDF for formatted documents\n",
        "   - Web search for current external information\n",
        "\n",
        "2. **Optimize Vector Stores**\n",
        "   - Chunk documents appropriately (300-500 chars)\n",
        "   - Use overlap for context preservation\n",
        "   - Index strategically\n",
        "\n",
        "3. **Tool Design**\n",
        "   - Clear, specific purposes\n",
        "   - Good docstrings for LLM understanding\n",
        "   - Handle errors gracefully\n",
        "\n",
        "4. **Multi-Source Strategy**\n",
        "   - Internal data first (CSV, PDF)\n",
        "   - External when needed (Web)\n",
        "   - Synthesize comprehensively\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "- Explore more loaders: Google Docs, Notion, Confluence\n",
        "- Add more advanced retrieval (semantic search)\n",
        "- Implement caching for performance\n",
        "- Build specialized agents for different departments\n",
        "- Deploy as a production service\n",
        "\n",
        "---\n",
        "\n",
        "**More Integrations to Explore:**\n",
        "- Slack integration for team communication\n",
        "- Google Drive for document access\n",
        "- Notion for knowledge bases\n",
        "- SQL databases for live data\n",
        "- APIs for real-time information\n",
        "\n",
        "Check the [LangChain Integrations](https://docs.langchain.com/oss/python/integrations/providers/all_providers) for 200+ more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercises\n",
        "\n",
        "## Exercise 1: Add More Employee Data\n",
        "Create a second CSV with department information (budget, headcount, manager) and create a tool to query it.\n",
        "\n",
        "## Exercise 2: PDF Processing\n",
        "Create an employee handbook PDF and add a tool to search through it.\n",
        "\n",
        "## Exercise 3: Multi-Document Q&A\n",
        "Build a system that can answer questions requiring information from both CSV and PDF.\n",
        "\n",
        "## Exercise 4: Advanced Search\n",
        "Implement a tool that searches the web for competitive salary information for specific roles.\n",
        "\n",
        "## Bonus: Build a Complete HR Portal\n",
        "Combine all learnings from Modules 1-4 to build a comprehensive HR system with:\n",
        "- Employee management (CSV)\n",
        "- Policy Q&A (PDF)\n",
        "- External benchmarking (Web)\n",
        "- Workflow automation (LangGraph)\n",
        "- Professional tools (@tool decorator)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
