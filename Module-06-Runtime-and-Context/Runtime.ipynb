{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYrESCzDlHXc"
      },
      "source": [
        "# Module 4.2: Runtime Basics in LangGraph\n",
        "\n",
        "**Prerequisites:**\n",
        "- Module 4.1: Short-term memory (conversation context)\n",
        "\n",
        "**What you'll learn:**\n",
        "- üéØ What is Runtime?\n",
        "- üìù Context: Passing information to agents\n",
        "- üîß ToolRuntime: Accessing context in tools\n",
        "- üé® Dynamic prompts based on context\n",
        "- üîå Middleware: Pre/post model hooks\n",
        "- üíº Production patterns\n",
        "\n",
        "**Real HR Use Case:**\n",
        "Build an HR assistant that:\n",
        "- Knows which user is asking (user context)\n",
        "- Has access to company info (org context)\n",
        "- Adapts responses based on user role\n",
        "- Logs requests for audit trails\n",
        "\n",
        "**Why Runtime Matters:**\n",
        "Runtime provides the **environment** your agent runs in - like knowing:\n",
        "- Who is asking the question?\n",
        "- What organization do they belong to?\n",
        "- What database should I query?\n",
        "- What API keys should I use?\n",
        "\n",
        "**Time:** 2-3 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4GC925dlHXe"
      },
      "source": [
        "## Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8zBuY_dplHXf",
        "outputId": "693a8056-b6fa-48e7-a1cf-410e12faa66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (1.0.0a1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0a1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0a1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.35)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langgraph-checkpoint-sqlite in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: aiosqlite>=0.20 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=3 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint-sqlite) (3.0.0)\n",
            "Requirement already satisfied: sqlite-vec>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.12/dist-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.15.0)\n",
            "Requirement already satisfied: langchain-core>=0.2.38 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.11.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.4.35)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (8.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<4.0.0,>=3->langgraph-checkpoint-sqlite) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain 1.0 and required packages\n",
        "!pip install --pre -U langchain langchain-openai langgraph langchain-community\n",
        "!pip install langgraph-checkpoint-sqlite  # For SQLite persistence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3V0WDlHlHXf"
      },
      "source": [
        "## Setup: Configure API Keys & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q9GBRqRLlHXg",
        "outputId": "8d00f275-5de4-404e-e490-8bd42595423f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Common imports\n",
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent, AgentState\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool, InjectedToolArg\n",
        "from typing import Annotated\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "from langchain.agents.middleware import (\n",
        "    dynamic_prompt,\n",
        "    before_model,\n",
        "    after_model,\n",
        "    ModelRequest\n",
        ")\n",
        "from langgraph.runtime import Runtime\n",
        "import json\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BlW3vkrlHXg"
      },
      "source": [
        "---\n",
        "# Part 1: Understanding Runtime & Context üéØ\n",
        "\n",
        "## What is Runtime?\n",
        "\n",
        "**Runtime** is the execution environment where your agent runs. It provides:\n",
        "- **Context**: Static information available during execution\n",
        "- **Store**: Long-term memory (covered in next module)\n",
        "- **Stream Writer**: Custom streaming updates\n",
        "\n",
        "## What is Context?\n",
        "\n",
        "**Context** is information that **doesn't change during a conversation** but is essential for the agent to work:\n",
        "\n",
        "```\n",
        "Example without Context:\n",
        "User: \"Show my leave balance\"\n",
        "Agent: \"I don't know who you are!\" ‚ùå\n",
        "\n",
        "Example with Context:\n",
        "Context: {user_id: \"101\", name: \"Priya Sharma\", dept: \"Engineering\"}\n",
        "User: \"Show my leave balance\"\n",
        "Agent: \"Priya, you have 12 days remaining\" ‚úÖ\n",
        "```\n",
        "\n",
        "## Context vs Messages\n",
        "\n",
        "| Messages | Context |\n",
        "|----------|--------|\n",
        "| Changes during conversation | Static during conversation |\n",
        "| User: \"Hello\", Agent: \"Hi!\" | user_id, org_id, api_keys |\n",
        "| Short-term memory | Configuration |\n",
        "| \"What did I just say?\" | \"Who am I?\" |\n",
        "\n",
        "## üîë Critical Understanding\n",
        "\n",
        "**The LLM does NOT automatically see context!** Context is only accessible to:\n",
        "- ‚úÖ **Tools** - via `runtime.context`\n",
        "- ‚úÖ **Dynamic Prompts** - via `request.runtime.context`\n",
        "- ‚úÖ **Middleware Hooks** - via `runtime.context`\n",
        "\n",
        "You must **explicitly inject** context information where needed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B65FStsOlHXg"
      },
      "source": [
        "---\n",
        "# Part 2: Basic Context Usage üìù\n",
        "\n",
        "## Lab 1.1: Define Context Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zp_kYFkulHXg",
        "outputId": "67bedbee-7256-4e5b-d709-c9c8fd9a1db2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 1.1: Define Context Schema\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Defined HRContext schema\n",
            "\n",
            "Example context for Priya:\n",
            "  User: Priya Sharma\n",
            "  Department: Engineering\n",
            "  Employee ID: EMP-101\n",
            "  Organization: acme_corp\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 1.1: Define Context Schema\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Define what information is available in context\n",
        "@dataclass\n",
        "class HRContext:\n",
        "    \"\"\"Context for HR assistant - information about current user\"\"\"\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    department: str\n",
        "    employee_id: str\n",
        "    organization_id: str\n",
        "\n",
        "# Create sample context for testing\n",
        "priya_context = HRContext(\n",
        "    user_id=\"user_101\",\n",
        "    user_name=\"Priya Sharma\",\n",
        "    department=\"Engineering\",\n",
        "    employee_id=\"EMP-101\",\n",
        "    organization_id=\"acme_corp\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Defined HRContext schema\")\n",
        "print(f\"\\nExample context for Priya:\")\n",
        "print(f\"  User: {priya_context.user_name}\")\n",
        "print(f\"  Department: {priya_context.department}\")\n",
        "print(f\"  Employee ID: {priya_context.employee_id}\")\n",
        "print(f\"  Organization: {priya_context.organization_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-KhHbslHXh"
      },
      "source": [
        "## Lab 1.2: Agent with Context via Dynamic Prompt\n",
        "\n",
        "**Important:** The LLM doesn't automatically see the context object. Context is only accessible to:\n",
        "- ‚úÖ Tools (via `runtime.context`)\n",
        "- ‚úÖ Dynamic prompts (via `request.runtime.context`)\n",
        "- ‚úÖ Middleware hooks (via `runtime.context`)\n",
        "\n",
        "So we need a **dynamic prompt** to inject context info into the system message:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yIUTmczKlHXh",
        "outputId": "82777fd7-5238-4f0f-e93b-191f4fc1d655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 1.2: Agent with Context via Dynamic Prompt\n",
            "======================================================================\n",
            "\n",
            "User question: What's my name?\n",
            "Agent response: Your name is Priya Sharma. How can I assist you today?\n",
            "\n",
            "User question: What department do I work in?\n",
            "Agent response: Hi Priya Sharma! You work in the Engineering department. If you need any further assistance or have questions, feel free to ask!\n",
            "\n",
            "‚úÖ Agent knows user from context via dynamic prompt!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 1.2: Agent with Context via Dynamic Prompt\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Dynamic prompt to inject context into system message\n",
        "@dynamic_prompt\n",
        "def inject_user_info(request: ModelRequest) -> str:\n",
        "    \"\"\"Inject user information from context into system prompt.\"\"\"\n",
        "    user_name = request.runtime.context.user_name\n",
        "    department = request.runtime.context.department\n",
        "    employee_id = request.runtime.context.employee_id\n",
        "\n",
        "    return f\"\"\"You are an HR assistant.\n",
        "\n",
        "Current user information:\n",
        "- Name: {user_name}\n",
        "- Department: {department}\n",
        "- Employee ID: {employee_id}\n",
        "\n",
        "Address the user by their name and provide personalized assistance.\"\"\"\n",
        "\n",
        "# Create a simple agent with context schema\n",
        "simple_agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    context_schema=HRContext,  # Tell agent about context structure\n",
        "    middleware=[inject_user_info]  # Use dynamic prompt to inject context\n",
        ")\n",
        "\n",
        "# Invoke with Priya's context\n",
        "result = simple_agent.invoke(\n",
        "    {\"messages\": \"What's my name?\"},\n",
        "    context=priya_context  # Pass context!\n",
        ")\n",
        "\n",
        "print(\"User question: What's my name?\")\n",
        "print(f\"Agent response: {result['messages'][-1].content}\")\n",
        "\n",
        "# Try another question\n",
        "result = simple_agent.invoke(\n",
        "    {\"messages\": \"What department do I work in?\"},\n",
        "    context=priya_context\n",
        ")\n",
        "print(\"\\nUser question: What department do I work in?\")\n",
        "print(f\"Agent response: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Agent knows user from context via dynamic prompt!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTlUWO86lHXh"
      },
      "source": [
        "---\n",
        "# Part 3: Accessing Context in Tools üîß\n",
        "\n",
        "## Lab 2.1: Tool with Context Access\n",
        "\n",
        "Tools can directly access context using `runtime.context`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CIFThyeTlHXh",
        "outputId": "8e7e4fff-1bb7-4628-83b3-b23525d96c57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 2.1: Tool with Context Access via Dynamic Prompt\n",
            "======================================================================\n",
            "\n",
            "Priya asks: What department do I work in?\n",
            "Agent: You work in the Engineering department.\n",
            "\n",
            "Rahul asks: What's my employee ID?\n",
            "Agent: Your employee ID is EMP-102.\n",
            "\n",
            "‚úÖ Same agent, different contexts - perfectly personalized!\n",
            "\n",
            "Note: The agent answers directly from context via dynamic prompt.\n",
            "Tools are available but not needed for simple context queries.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 2.1: Tool with Context Access via Dynamic Prompt\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Simple tools without runtime injection\n",
        "@tool\n",
        "def get_department_info() -> str:\n",
        "    \"\"\"Get the current user's department information.\n",
        "    This tool returns the user's department based on who is logged in.\"\"\"\n",
        "    return \"department_info\"\n",
        "\n",
        "@tool\n",
        "def get_employee_id_info() -> str:\n",
        "    \"\"\"Get the current user's employee ID.\n",
        "    This tool returns the employee ID based on who is logged in.\"\"\"\n",
        "    return \"employee_id_info\"\n",
        "\n",
        "# Dynamic prompt that injects context AND explains tools\n",
        "@dynamic_prompt\n",
        "def context_aware_prompt(request: ModelRequest) -> str:\n",
        "    user_name = request.runtime.context.user_name\n",
        "    department = request.runtime.context.department\n",
        "    employee_id = request.runtime.context.employee_id\n",
        "\n",
        "    return f\"\"\"You are an HR assistant.\n",
        "\n",
        "Current user information:\n",
        "- Name: {user_name}\n",
        "- Department: {department}\n",
        "- Employee ID: {employee_id}\n",
        "\n",
        "IMPORTANT: When the user asks about their department or employee ID:\n",
        "- Answer directly using the information above\n",
        "- You do NOT need to call any tools\n",
        "- Simply tell them their department is \"{department}\" and their employee ID is \"{employee_id}\"\n",
        "\n",
        "Be helpful and personal.\"\"\"\n",
        "\n",
        "# Create agent\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[get_department_info, get_employee_id_info],\n",
        "    context_schema=HRContext,\n",
        "    middleware=[context_aware_prompt]\n",
        ")\n",
        "\n",
        "# Test with Priya\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"What department do I work in?\"},\n",
        "    context=priya_context\n",
        ")\n",
        "print(\"Priya asks: What department do I work in?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test with different user\n",
        "rahul_context = HRContext(\n",
        "    user_id=\"user_102\",\n",
        "    user_name=\"Rahul Verma\",\n",
        "    department=\"Marketing\",\n",
        "    employee_id=\"EMP-102\",\n",
        "    organization_id=\"acme_corp\"\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"What's my employee ID?\"},\n",
        "    context=rahul_context\n",
        ")\n",
        "print(\"\\nRahul asks: What's my employee ID?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Same agent, different contexts - perfectly personalized!\")\n",
        "print(\"\\nNote: The agent answers directly from context via dynamic prompt.\")\n",
        "print(\"Tools are available but not needed for simple context queries.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsOi-Lm0lHXh"
      },
      "source": [
        "## Lab 2.2: Tools That Use Context Information\n",
        "\n",
        "For operations that need context (like database queries), pass user_id as a parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HWNpzwoElHXh",
        "outputId": "722a915c-85fc-446a-d5e3-b15ccd456c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 2.2: Tools with User Parameters\n",
            "======================================================================\n",
            "\n",
            "  [Simulated] Querying database for user_101...\n",
            "Query 1: What's my leave balance?\n",
            "Agent: Your leave balance is 12 days.\n",
            "\n",
            "Query 2: How many people are in my department?\n",
            "Agent: There are 45 people in your department, Engineering.\n",
            "\n",
            "‚úÖ Tools called with correct user-specific parameters!\n",
            "\n",
            "Key Pattern: Dynamic prompt tells LLM which parameters to use.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 2.2: Tools with User Parameters\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Extended context with DB and API info\n",
        "@dataclass\n",
        "class ExtendedContext:\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    department: str\n",
        "    database_url: str  # Database connection info\n",
        "    api_key: str  # API key for external services\n",
        "\n",
        "# Tools that take user_id as explicit parameter\n",
        "@tool\n",
        "def query_leave_balance(user_id: str) -> str:\n",
        "    \"\"\"Query user's leave balance from database.\n",
        "\n",
        "    Args:\n",
        "        user_id: The user ID to query (e.g., 'user_101')\n",
        "    \"\"\"\n",
        "    # In production, this would use context.database_url\n",
        "    # For now, simulate database query\n",
        "    print(f\"  [Simulated] Querying database for {user_id}...\")\n",
        "\n",
        "    # Mock data\n",
        "    leave_data = {\n",
        "        \"user_101\": 12,\n",
        "        \"user_102\": 8,\n",
        "    }\n",
        "\n",
        "    balance = leave_data.get(user_id, 0)\n",
        "    return f\"Leave balance for {user_id}: {balance} days\"\n",
        "\n",
        "@tool\n",
        "def get_team_size(department: str) -> str:\n",
        "    \"\"\"Get the number of people in a department.\n",
        "\n",
        "    Args:\n",
        "        department: Department name (e.g., 'Engineering', 'Marketing')\n",
        "    \"\"\"\n",
        "    dept_sizes = {\n",
        "        \"Engineering\": 45,\n",
        "        \"Marketing\": 20,\n",
        "        \"HR\": 10\n",
        "    }\n",
        "\n",
        "    size = dept_sizes.get(department, 0)\n",
        "    return f\"The {department} department has {size} people.\"\n",
        "\n",
        "# Dynamic prompt provides context to LLM\n",
        "@dynamic_prompt\n",
        "def context_with_instructions(request: ModelRequest) -> str:\n",
        "    user_id = request.runtime.context.user_id\n",
        "    user_name = request.runtime.context.user_name\n",
        "    department = request.runtime.context.department\n",
        "\n",
        "    return f\"\"\"You are an HR assistant.\n",
        "\n",
        "Current user:\n",
        "- Name: {user_name}\n",
        "- User ID: {user_id}\n",
        "- Department: {department}\n",
        "\n",
        "When user asks about THEIR leave balance, call query_leave_balance with user_id=\"{user_id}\"\n",
        "When user asks about THEIR department size, call get_team_size with department=\"{department}\"\n",
        "\n",
        "Always use the current user's information from above.\"\"\"\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[query_leave_balance, get_team_size],\n",
        "    context_schema=ExtendedContext,\n",
        "    middleware=[context_with_instructions]\n",
        ")\n",
        "\n",
        "# Create context with DB and API info\n",
        "priya_extended = ExtendedContext(\n",
        "    user_id=\"user_101\",\n",
        "    user_name=\"Priya Sharma\",\n",
        "    department=\"Engineering\",\n",
        "    database_url=\"postgresql://hr-db.acme.com:5432/employees\",\n",
        "    api_key=\"sk-acme-abc123xyz\"\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"What's my leave balance?\"},\n",
        "    context=priya_extended\n",
        ")\n",
        "print(\"Query 1: What's my leave balance?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"How many people are in my department?\"},\n",
        "    context=priya_extended\n",
        ")\n",
        "print(\"\\nQuery 2: How many people are in my department?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Tools called with correct user-specific parameters!\")\n",
        "print(\"\\nKey Pattern: Dynamic prompt tells LLM which parameters to use.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY_pbs0MlHXi"
      },
      "source": [
        "---\n",
        "# Part 4: Dynamic Prompts üé®\n",
        "\n",
        "## Lab 3.1: Personalized System Prompts Based on Role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vey5UUwolHXi",
        "outputId": "f2e47a2b-aa01-4800-8e59-82f0cae01065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 3.1: Dynamic System Prompts\n",
            "======================================================================\n",
            "\n",
            "Employee (Priya) asks: How do I apply for leave?\n",
            "Agent: Hi Priya! Applying for leave is typically a straightforward process. Here‚Äôs how you can do it:\n",
            "\n",
            "1. **Check Your Company Policy:** First, review your company‚Äôs leave policy. It should outline how to apply for leave, the types of leave available, and any notice periods required.\n",
            "\n",
            "2. **Notify Your Manager:** It‚Äôs a good idea to inform your supervisor or manager about your planned leave as soon as you can. You can do this through a quick email or a conversation.\n",
            "\n",
            "3. **Complete the Leave Application Form:** Most companies have a specific form for leave applications. You can usually find this on the company intranet or HR portal. Fill it out with the necessary details, including the type of leave, dates, and any supporting information.\n",
            "\n",
            "4. **Submit Your Application:** Once the form is completed, submit it according to your company‚Äôs process. This might be via email, a shared drive, or directly to HR.\n",
            "\n",
            "5. **Wait for Approval:** After submission, await confirmation of your leave from your manager or HR. They may get back to you with questions or approvals.\n",
            "\n",
            "6. **Plan for Your Absence:** Make sure to prepare for your absence by updating any colleagues who may need to cover for you during that time.\n",
            "\n",
            "If you have any questions about the specific process at your company or if you need the leave form, feel free to ask!\n",
            "\n",
            "Executive (Mr. Kapoor) asks: How do I apply for leave?\n",
            "Agent: To apply for leave, please follow these steps:\n",
            "\n",
            "1. **Review Company Leave Policy**: Familiarize yourself with the company‚Äôs leave policy outlined in the employee handbook to ensure compliance with procedures and approval processes.\n",
            "\n",
            "2. **Prepare a Leave Request**: Draft a formal leave request that includes:\n",
            "   - Dates of absence\n",
            "   - Reason for the leave (if applicable)\n",
            "   - Contact information during your absence (if necessary)\n",
            "\n",
            "3. **Submit Your Request**: Send your leave request to your immediate supervisor or designated HR personnel via email or the company‚Äôs leave management system. Ensure you submit your request well in advance to accommodate scheduling needs.\n",
            "\n",
            "4. **Follow Up**: If you do not receive a response within a reasonable timeframe, follow up to confirm receipt and discuss any necessary next steps.\n",
            "\n",
            "5. **Document Approval**: Once approved, keep a copy of the leave approval for your records.\n",
            "\n",
            "If you require further assistance or guidance on specific leave types, please let me know.\n",
            "\n",
            "‚úÖ Same question, different tones based on user role!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 3.1: Dynamic System Prompts\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_name: str\n",
        "    department: str\n",
        "    role: str  # 'employee', 'manager', 'executive'\n",
        "\n",
        "# Dynamic prompt that changes based on context\n",
        "@dynamic_prompt\n",
        "def personalized_greeting(request: ModelRequest) -> str:\n",
        "    \"\"\"Create personalized greeting based on user role.\"\"\"\n",
        "    user_name = request.runtime.context.user_name\n",
        "    role = request.runtime.context.role\n",
        "    department = request.runtime.context.department\n",
        "\n",
        "    if role == \"executive\":\n",
        "        return f\"\"\"You are a professional HR assistant serving {user_name}, an executive.\n",
        "Be formal, concise, and provide strategic insights.\"\"\"\n",
        "    elif role == \"manager\":\n",
        "        return f\"\"\"You are an HR assistant helping {user_name}, a manager in {department}.\n",
        "Be helpful and provide team management insights.\"\"\"\n",
        "    else:\n",
        "        return f\"\"\"You are a friendly HR assistant helping {user_name} from {department}.\n",
        "Be approachable and provide clear guidance.\"\"\"\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    context_schema=UserContext,\n",
        "    middleware=[personalized_greeting]  # Add dynamic prompt as middleware\n",
        ")\n",
        "\n",
        "# Test with employee\n",
        "employee_context = UserContext(\n",
        "    user_name=\"Priya Sharma\",\n",
        "    department=\"Engineering\",\n",
        "    role=\"employee\"\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"How do I apply for leave?\"},\n",
        "    context=employee_context\n",
        ")\n",
        "print(\"Employee (Priya) asks: How do I apply for leave?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "# Test with executive\n",
        "executive_context = UserContext(\n",
        "    user_name=\"Mr. Kapoor\",\n",
        "    department=\"Executive Office\",\n",
        "    role=\"executive\"\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"How do I apply for leave?\"},\n",
        "    context=executive_context\n",
        ")\n",
        "print(\"\\nExecutive (Mr. Kapoor) asks: How do I apply for leave?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n‚úÖ Same question, different tones based on user role!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RLWjDZdlHXi"
      },
      "source": [
        "---\n",
        "# Part 5: Middleware - Request/Response Hooks üîå\n",
        "\n",
        "## Lab 4.1: Request Logging Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FTTsn6rKlHXi",
        "outputId": "fd850c01-91a1-4224-df46-e3f1f2304ff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 4.1: Request Logging Hook\n",
            "======================================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìù AUDIT LOG - Request\n",
            "============================================================\n",
            "User: Priya Sharma (user_101)\n",
            "Organization: acme_corp\n",
            "Session: session_2025_001\n",
            "Question: What are the leave policies?\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚úÖ AUDIT LOG - Response\n",
            "============================================================\n",
            "Response generated for: Priya Sharma\n",
            "Status: Success\n",
            "============================================================\n",
            "\n",
            "Agent response:\n",
            "Leave policies can vary widely depending on the company, location, and specific employment agreements. However, here are some common types of leave policies that many organizations include:\n",
            "\n",
            "1. **Annual Leave/Vacation Leave:**\n",
            "   - Employees earn a certain number of vacation days based on their tenure, company policy, or labor laws.\n",
            "   - Policies on carryover of unused vacation days may vary.\n",
            "\n",
            "2. **Sick Leave:**\n",
            "   - Employees are provided a set number of days to use when they are ill or need to care for a sick family member.\n",
            "   - Some companies require documentation after a specific number of consecutive sick days.\n",
            "\n",
            "3. **Personal Leave:**\n",
            "   - This type of leave allows employees to take time off for personal matters not covered by other leave types.\n",
            "   - Policies may specify how personal leave can be requested and used.\n",
            "\n",
            "4. **Maternity/Paternity Leave:**\n",
            "   - Leave provided to employees who have given birth or are adopting a child.\n",
            "   - The duration and pay during this leave can vary significantly based on country laws and company policy.\n",
            "\n",
            "5. **Family and Medical Leave (FMLA):**\n",
            "   - In the U.S., the Family and Medical Leave Act entitles eligible employees to take up to 12 weeks of unpaid leave for certain family and medical reasons.\n",
            "   - Employers may provide paid leave, but it‚Äôs not mandatory under FMLA.\n",
            "\n",
            "6. **Bereavement Leave:**\n",
            "   - Time off granted to employees following the death of a loved one.\n",
            "   - The length of the leave may depend on the relationship to the deceased.\n",
            "\n",
            "7. **Jury Duty Leave:**\n",
            "   - Employers typically provide leave for employees summoned for jury duty, with policies on whether this is paid or unpaid.\n",
            "\n",
            "8. **Leave of Absence:**\n",
            "   - Employees may request a leave of absence for various reasons, including personal issues, medical conditions, or educational purposes.\n",
            "   - The terms of these leaves, including pay and duration, vary widely.\n",
            "\n",
            "9. **Public Service Leave:**\n",
            "   - Some organizations provide time off for employees who serve in public or community service roles, such as military duty or volunteering.\n",
            "\n",
            "10. **Flexible Leave Policies:**\n",
            "    - Some companies offer flexible leave policies where employees can take time off based on their needs, often integrating vacation, sick, and personal days.\n",
            "\n",
            "It is advisable to refer to the specific handbook or official documents from your organization for precise details, as well as any relevant local or national labor laws that may apply.\n",
            "\n",
            "‚úÖ All requests and responses are logged for compliance!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 4.1: Request Logging Hook\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "@dataclass\n",
        "class AuditContext:\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    organization_id: str\n",
        "    session_id: str\n",
        "\n",
        "# Before model hook - logs every request\n",
        "@before_model\n",
        "def audit_request(state: AgentState, runtime: Runtime[AuditContext]) -> dict | None:\n",
        "    \"\"\"Log request details for audit trail.\"\"\"\n",
        "    user_name = runtime.context.user_name\n",
        "    user_id = runtime.context.user_id\n",
        "    org_id = runtime.context.organization_id\n",
        "    session_id = runtime.context.session_id\n",
        "\n",
        "    messages = state.get('messages', [])\n",
        "    last_message = messages[-1].content if messages else \"N/A\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìù AUDIT LOG - Request\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"User: {user_name} ({user_id})\")\n",
        "    print(f\"Organization: {org_id}\")\n",
        "    print(f\"Session: {session_id}\")\n",
        "    print(f\"Question: {last_message[:100]}...\" if len(last_message) > 100 else f\"Question: {last_message}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# After model hook - logs response\n",
        "@after_model\n",
        "def audit_response(state: AgentState, runtime: Runtime[AuditContext]) -> dict | None:\n",
        "    \"\"\"Log response details for audit trail.\"\"\"\n",
        "    user_name = runtime.context.user_name\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"‚úÖ AUDIT LOG - Response\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Response generated for: {user_name}\")\n",
        "    print(f\"Status: Success\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return None\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    context_schema=AuditContext,\n",
        "    middleware=[audit_request, audit_response],  # Add both hooks\n",
        "    system_prompt=\"You are a helpful HR assistant.\"\n",
        ")\n",
        "\n",
        "audit_context = AuditContext(\n",
        "    user_id=\"user_101\",\n",
        "    user_name=\"Priya Sharma\",\n",
        "    organization_id=\"acme_corp\",\n",
        "    session_id=\"session_2025_001\"\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"What are the leave policies?\"},\n",
        "    context=audit_context\n",
        ")\n",
        "\n",
        "print(\"Agent response:\")\n",
        "print(result['messages'][-1].content)\n",
        "print(\"\\n‚úÖ All requests and responses are logged for compliance!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5huebJoGlHXj"
      },
      "source": [
        "## Lab 4.2: Access Control Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7O6zTrwqlHXj",
        "outputId": "4e442e54-7fe4-4d0d-b34e-1f614a85abb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Lab 4.2: Access Control Hook\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Access granted for Priya Sharma\n",
            "Allowed query: How do I apply for leave?\n",
            "Agent: To apply for leave, you typically need to follow these steps:\n",
            "\n",
            "1. **Check Company Policy**: Review your employee handbook or company intranet for specific policies regarding leave requests. This may include how much notice you need to give and what types of leave are available.\n",
            "\n",
            "2. **Notice period**: Determine the appropriate notice period for the leave type you are requesting (e.g., vacation, sick leave, personal leave).\n",
            "\n",
            "3. **Complete a Leave Request Form**: If your company uses a specific form for leave requests, fill it out completely. This may be available online or through your HR department.\n",
            "\n",
            "4. **Provide Necessary Documentation**: For certain types of leave, such as medical leave, you may need to provide supporting documentation.\n",
            "\n",
            "5. **Submit Your Request**: Send your leave request form to your direct supervisor or the HR department, depending on your company‚Äôs process.\n",
            "\n",
            "6. **Follow Up**: If you don‚Äôt receive a response within a reasonable time frame, follow up to ensure your request was received and is being processed.\n",
            "\n",
            "7. **Plan for Coverage**: If your leave is approved, discuss how your responsibilities will be managed in your absence.\n",
            "\n",
            "If you have any specific questions about your company‚Äôs leave process or need further assistance, please let me know!\n",
            "\n",
            "Trying restricted query: What's my salary?\n",
            "‚ùå Access Denied: Priya Sharma does not have permission to view salary information.\n",
            "\n",
            "‚úÖ Access control enforced through middleware!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Lab 4.2: Access Control Hook\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "@dataclass\n",
        "class SecurityContext:\n",
        "    user_id: str\n",
        "    user_name: str\n",
        "    permissions: list  # List of allowed operations\n",
        "\n",
        "@before_model\n",
        "def check_permissions(state: AgentState, runtime: Runtime[SecurityContext]) -> dict | None:\n",
        "    \"\"\"Check if user has required permissions.\"\"\"\n",
        "    user_name = runtime.context.user_name\n",
        "    permissions = runtime.context.permissions\n",
        "\n",
        "    messages = state.get('messages', [])\n",
        "    if messages:\n",
        "        question = messages[-1].content.lower()\n",
        "\n",
        "        # Check for restricted operations\n",
        "        if 'salary' in question and 'view_salary' not in permissions:\n",
        "            raise Exception(f\"Access Denied: {user_name} does not have permission to view salary information.\")\n",
        "\n",
        "        if 'delete' in question and 'admin' not in permissions:\n",
        "            raise Exception(f\"Access Denied: {user_name} does not have admin permissions.\")\n",
        "\n",
        "    print(f\"‚úÖ Access granted for {user_name}\")\n",
        "    return None\n",
        "\n",
        "agent = create_agent(\n",
        "    model=\"openai:gpt-4o-mini\",\n",
        "    tools=[],\n",
        "    context_schema=SecurityContext,\n",
        "    middleware=[check_permissions],\n",
        "    system_prompt=\"You are an HR assistant. Answer user questions.\"\n",
        ")\n",
        "\n",
        "# User with limited permissions\n",
        "employee_sec_context = SecurityContext(\n",
        "    user_id=\"user_101\",\n",
        "    user_name=\"Priya Sharma\",\n",
        "    permissions=[\"view_profile\", \"apply_leave\"]\n",
        ")\n",
        "\n",
        "# Allowed question\n",
        "result = agent.invoke(\n",
        "    {\"messages\": \"How do I apply for leave?\"},\n",
        "    context=employee_sec_context\n",
        ")\n",
        "print(\"Allowed query: How do I apply for leave?\")\n",
        "print(f\"Agent: {result['messages'][-1].content}\")\n",
        "\n",
        "# Try restricted question\n",
        "print(\"\\nTrying restricted query: What's my salary?\")\n",
        "try:\n",
        "    result = agent.invoke(\n",
        "        {\"messages\": \"What's my salary?\"},\n",
        "        context=employee_sec_context\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Access control enforced through middleware!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAnE4wxQlHXj"
      },
      "source": [
        "---\n",
        "# Summary & Key Takeaways\n",
        "\n",
        "## What We Learned\n",
        "\n",
        "### 1. **Runtime & Context**\n",
        "```python\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_id: str\n",
        "    database_url: str\n",
        "\n",
        "agent = create_agent(\n",
        "    context_schema=Context,\n",
        "    ...\n",
        ")\n",
        "\n",
        "agent.invoke({...}, context=Context(...))\n",
        "```\n",
        "\n",
        "### 2. **Tools with Context-Aware Parameters**\n",
        "```python\n",
        "# Tools take explicit parameters\n",
        "@tool\n",
        "def get_user_data(user_id: str) -> str:\n",
        "    return f\"Data for {user_id}\"\n",
        "\n",
        "# Dynamic prompt tells LLM which values to use\n",
        "@dynamic_prompt\n",
        "def inject_context(request: ModelRequest) -> str:\n",
        "    user_id = request.runtime.context.user_id\n",
        "    return f\"Current user ID is {user_id}. Use this when calling tools.\"\n",
        "```\n",
        "\n",
        "### 3. **Dynamic Prompts**\n",
        "```python\n",
        "@dynamic_prompt\n",
        "def my_prompt(request: ModelRequest) -> str:\n",
        "    name = request.runtime.context.user_name\n",
        "    return f\"You are helping {name}\"\n",
        "```\n",
        "\n",
        "### 4. **Middleware Hooks**\n",
        "```python\n",
        "@before_model\n",
        "def log_request(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
        "    # Pre-processing\n",
        "    return None\n",
        "\n",
        "@after_model\n",
        "def log_response(state: AgentState, runtime: Runtime[Context]) -> dict | None:\n",
        "    # Post-processing\n",
        "    return None\n",
        "```\n",
        "\n",
        "## üîë Critical Understanding\n",
        "\n",
        "**The LLM does NOT automatically see context!**\n",
        "\n",
        "Context must be explicitly injected:\n",
        "- ‚úÖ **In Tools** - `runtime.context.field_name`\n",
        "- ‚úÖ **In Dynamic Prompts** - `request.runtime.context.field_name`\n",
        "- ‚úÖ **In Middleware** - `runtime.context.field_name`\n",
        "\n",
        "## Context vs Messages vs Store\n",
        "\n",
        "| Feature | Context | Messages | Store (Next Module) |\n",
        "|---------|---------|----------|--------------------|\n",
        "| **What** | Static config | Conversation | Long-term memory |\n",
        "| **When** | Per invocation | During chat | Across sessions |\n",
        "| **Example** | user_id, api_key | \"Hello!\", \"Hi!\" | Preferences, history |\n",
        "| **Scope** | Single invocation | Single thread | All threads |\n",
        "| **Access** | Tools, prompts, hooks | Always visible | Store API |\n",
        "\n",
        "## Production Checklist\n",
        "\n",
        "‚úÖ **Define clear context schema** - What info does agent need?  \n",
        "‚úÖ **Use dataclasses** - Type safety and IDE support  \n",
        "‚úÖ **Inject via dynamic prompts** - For LLM to \"see\" context  \n",
        "‚úÖ **Access in tools** - `runtime.context.field_name`  \n",
        "‚úÖ **Dynamic prompts** - Personalize based on user role  \n",
        "‚úÖ **Audit logging** - Use before/after hooks  \n",
        "‚úÖ **Access control** - Check permissions in hooks  \n",
        "‚úÖ **Combine with checkpointer** - Short-term + Context  \n",
        "\n",
        "## Common Patterns\n",
        "\n",
        "### Multi-Tenant\n",
        "```python\n",
        "@dataclass\n",
        "class TenantContext:\n",
        "    user_id: str\n",
        "    organization_id: str  # Separate data per org\n",
        "    database_url: str  # Org-specific DB\n",
        "```\n",
        "\n",
        "### Role-Based Behavior\n",
        "```python\n",
        "@dynamic_prompt\n",
        "def role_prompt(request: ModelRequest) -> str:\n",
        "    role = request.runtime.context.role\n",
        "    if role == \"admin\":\n",
        "        return \"You have admin access...\"\n",
        "    return \"You have user access...\"\n",
        "```\n",
        "\n",
        "### Audit Trail\n",
        "```python\n",
        "@before_model\n",
        "def audit(state, runtime):\n",
        "    log_to_db(\n",
        "        user=runtime.context.user_id,\n",
        "        query=state['messages'][-1].content,\n",
        "        timestamp=now()\n",
        "    )\n",
        "```\n",
        "\n",
        "## Next Module: Long-Term Memory (Store)\n",
        "\n",
        "Now that you understand **Context** (static configuration), the next module will cover **Store** (dynamic, persistent memory):\n",
        "\n",
        "- Storing user preferences across sessions\n",
        "- Learning from past interactions\n",
        "- Building knowledge over time\n",
        "- Using `InjectedStore` (similar to `InjectedToolArg`)\n",
        "\n",
        "**Key Difference:**\n",
        "- **Context**: \"Who is asking?\" (static, per-invocation)\n",
        "- **Store**: \"What do I remember?\" (dynamic, cross-session)\n",
        "\n",
        "---\n",
        "\n",
        "**Remember:** Runtime provides the environment your agent needs to work effectively!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW_Ad24RlHXj"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "## Exercise 1: Multi-Department Agent\n",
        "Create an agent that:\n",
        "- Has different tools for different departments\n",
        "- Engineering: code deployment tools\n",
        "- HR: employee management tools\n",
        "- Marketing: campaign tools\n",
        "\n",
        "## Exercise 2: Compliance Logger\n",
        "Build a compliance system that:\n",
        "- Logs all financial queries\n",
        "- Requires approval for sensitive operations\n",
        "- Generates audit reports\n",
        "\n",
        "## Exercise 3: Multi-Language Support\n",
        "Create an agent that:\n",
        "- Detects user language from context\n",
        "- Responds in user's preferred language\n",
        "- Uses appropriate cultural references\n",
        "\n",
        "## Exercise 4: Rate Limiting\n",
        "Implement rate limiting using middleware:\n",
        "- Track requests per user\n",
        "- Enforce daily limits\n",
        "- Provide clear error messages\n",
        "\n",
        "## Exercise 5: Context Evolution\n",
        "Design a system where:\n",
        "- Context changes based on conversation\n",
        "- User gets promoted ‚Üí role changes\n",
        "- Department transfer ‚Üí permissions update"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}