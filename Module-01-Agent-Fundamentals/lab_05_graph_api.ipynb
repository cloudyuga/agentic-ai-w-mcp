{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a474c24"
      },
      "source": [
        "%pip install langgraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
        "import time\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "def chatbot_responder(state: ChatState):\n",
        "    print(\"--- Executing Node: chatbot_responder ---\")\n",
        "    time.sleep(1)\n",
        "    last_message = state['messages'][-1].content\n",
        "    if \"hello\" in last_message.lower():\n",
        "        response = AIMessage(content=\"Hello! How can I help you today?\")\n",
        "    elif \"langgraph\" in last_message.lower():\n",
        "        response = AIMessage(content=\"LangGraph is a library for building stateful, multi-actor applications with LLMs.\")\n",
        "    else:\n",
        "        response = AIMessage(content=\"I'm not sure how to respond to that. Please ask about 'hello' or 'LangGraph'.\")\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "workflow = StateGraph(ChatState)\n",
        "workflow.add_node(\"chatbot\", chatbot_responder)\n",
        "workflow.set_entry_point(\"chatbot\")\n",
        "workflow.set_finish_point(\"chatbot\")\n",
        "\n",
        "# Add a checkpointer for state persistence\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"GRAPH API - STREAMING DEMO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"user-thread-1\"}}\n",
        "initial_input = {\"messages\": [HumanMessage(content=\"Hello there!\")]}\n",
        "\n",
        "print(f\"\\n---> Invoking with initial input: {initial_input['messages'][0].content}\\n\")\n",
        "\n",
        "for event in app.stream(initial_input, config=config, stream_mode=\"values\"):\n",
        "    print(f\"Event Received: {event}\")\n",
        "    print(\"-\" * 20)\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\n---> Checking current state of the graph thread:\\n\")\n",
        "current_state = app.get_state(config)\n",
        "print(f\"Current State: {current_state}\")\n",
        "\n",
        "print(\"\\n---> Invoking with a second input to the same thread:\\n\")\n",
        "second_input = {\"messages\": [HumanMessage(content=\"Tell me about LangGraph.\")]}\n",
        "\n",
        "for event in app.stream(second_input, config=config, stream_mode=\"values\"):\n",
        "    print(f\"Event Received: {event}\")\n",
        "    print(\"-\" * 20)\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"\\n---> Checking final state of the graph thread:\\n\")\n",
        "final_state = app.get_state(config)\n",
        "print(f\"Final State: {final_state}\")\n",
        "print(\"=\"*50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "GRAPH API - STREAMING DEMO\n",
            "==================================================\n",
            "\n",
            "---> Invoking with initial input: Hello there!\n",
            "\n",
            "Event Received: {'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab')]}\n",
            "--------------------\n",
            "--- Executing Node: chatbot_responder ---\n",
            "Event Received: {'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, id='5f76467e-d490-4fe7-a468-c58dd03ed210')]}\n",
            "--------------------\n",
            "\n",
            "---> Checking current state of the graph thread:\n",
            "\n",
            "Current State: StateSnapshot(values={'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, id='5f76467e-d490-4fe7-a468-c58dd03ed210')]}, next=(), config={'configurable': {'thread_id': 'user-thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f09db41-b318-6255-8001-59db4529b4ba'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-30T04:15:32.438866+00:00', parent_config={'configurable': {'thread_id': 'user-thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f09db41-a000-6711-8000-585bc3dd262a'}}, tasks=(), interrupts=())\n",
            "\n",
            "---> Invoking with a second input to the same thread:\n",
            "\n",
            "Event Received: {'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, id='5f76467e-d490-4fe7-a468-c58dd03ed210'), HumanMessage(content='Tell me about LangGraph.', additional_kwargs={}, response_metadata={}, id='e5dd4196-c124-4a67-9fad-8b7d87fcdb1e')]}\n",
            "--------------------\n",
            "--- Executing Node: chatbot_responder ---\n",
            "Event Received: {'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, id='5f76467e-d490-4fe7-a468-c58dd03ed210'), HumanMessage(content='Tell me about LangGraph.', additional_kwargs={}, response_metadata={}, id='e5dd4196-c124-4a67-9fad-8b7d87fcdb1e'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='4bbf93e6-dc11-4cbb-b0dc-ef2b272eb52f')]}\n",
            "--------------------\n",
            "\n",
            "---> Checking final state of the graph thread:\n",
            "\n",
            "Final State: StateSnapshot(values={'messages': [HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={}, id='de9aebb5-16a6-46b3-b7be-cc4e616df4ab'), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, id='5f76467e-d490-4fe7-a468-c58dd03ed210'), HumanMessage(content='Tell me about LangGraph.', additional_kwargs={}, response_metadata={}, id='e5dd4196-c124-4a67-9fad-8b7d87fcdb1e'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='4bbf93e6-dc11-4cbb-b0dc-ef2b272eb52f')]}, next=(), config={'configurable': {'thread_id': 'user-thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f09db41-cfc4-6418-8004-0b384d2dd9e2'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-09-30T04:15:35.445372+00:00', parent_config={'configurable': {'thread_id': 'user-thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f09db41-bcac-60a3-8003-1a053b3a8c89'}}, tasks=(), interrupts=())\n",
            "==================================================\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXCNgfW4z1px",
        "outputId": "ebd693da-e39b-43ba-9779-91cc94cc82ab"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
